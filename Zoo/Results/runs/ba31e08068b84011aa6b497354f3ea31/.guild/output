INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 136.42it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:15, 126.42it/s]Padding data:   2%|▏         | 41/2042 [00:00<00:16, 124.35it/s]Padding data:   3%|▎         | 54/2042 [00:00<00:16, 120.68it/s]Padding data:   3%|▎         | 67/2042 [00:00<00:16, 121.25it/s]Padding data:   4%|▍         | 80/2042 [00:00<00:16, 118.26it/s]Padding data:   5%|▍         | 93/2042 [00:00<00:16, 121.48it/s]Padding data:   5%|▌         | 106/2042 [00:00<00:15, 121.72it/s]Padding data:   6%|▌         | 119/2042 [00:00<00:15, 120.59it/s]Padding data:   6%|▋         | 132/2042 [00:01<00:16, 118.43it/s]Padding data:   7%|▋         | 145/2042 [00:01<00:15, 121.17it/s]Padding data:   8%|▊         | 158/2042 [00:01<00:15, 121.45it/s]Padding data:   8%|▊         | 171/2042 [00:01<00:15, 121.87it/s]Padding data:   9%|▉         | 184/2042 [00:01<00:15, 123.25it/s]Padding data:  10%|▉         | 197/2042 [00:01<00:15, 122.97it/s]Padding data:  10%|█         | 210/2042 [00:01<00:14, 123.18it/s]Padding data:  11%|█         | 223/2042 [00:01<00:15, 120.50it/s]Padding data:  12%|█▏        | 237/2042 [00:01<00:14, 125.24it/s]Padding data:  12%|█▏        | 251/2042 [00:02<00:13, 128.35it/s]Padding data:  13%|█▎        | 265/2042 [00:02<00:13, 131.07it/s]Padding data:  14%|█▎        | 280/2042 [00:02<00:13, 133.87it/s]Padding data:  14%|█▍        | 295/2042 [00:02<00:12, 137.57it/s]Padding data:  15%|█▌        | 310/2042 [00:02<00:12, 140.92it/s]Padding data:  16%|█▌        | 325/2042 [00:02<00:12, 140.07it/s]Padding data:  17%|█▋        | 340/2042 [00:02<00:12, 136.92it/s]Padding data:  17%|█▋        | 354/2042 [00:02<00:12, 135.39it/s]Padding data:  18%|█▊        | 368/2042 [00:02<00:12, 135.86it/s]Padding data:  19%|█▊        | 382/2042 [00:02<00:12, 134.14it/s]Padding data:  19%|█▉        | 396/2042 [00:03<00:12, 135.36it/s]Padding data:  20%|██        | 410/2042 [00:03<00:12, 135.87it/s]Padding data:  21%|██        | 424/2042 [00:03<00:12, 132.24it/s]Padding data:  21%|██▏       | 438/2042 [00:03<00:12, 130.64it/s]Padding data:  22%|██▏       | 452/2042 [00:03<00:12, 131.78it/s]Padding data:  23%|██▎       | 466/2042 [00:03<00:12, 129.85it/s]Padding data:  24%|██▎       | 481/2042 [00:03<00:11, 134.09it/s]Padding data:  24%|██▍       | 496/2042 [00:03<00:11, 136.66it/s]Padding data:  25%|██▌       | 511/2042 [00:03<00:11, 138.86it/s]Padding data:  26%|██▌       | 525/2042 [00:04<00:11, 137.54it/s]Padding data:  26%|██▋       | 539/2042 [00:04<00:11, 135.05it/s]Padding data:  27%|██▋       | 553/2042 [00:04<00:10, 135.72it/s]Padding data:  28%|██▊       | 567/2042 [00:04<00:10, 134.48it/s]Padding data:  28%|██▊       | 581/2042 [00:04<00:11, 130.82it/s]Padding data:  29%|██▉       | 595/2042 [00:04<00:10, 132.95it/s]Padding data:  30%|██▉       | 609/2042 [00:04<00:11, 127.91it/s]Padding data:  31%|███       | 623/2042 [00:04<00:11, 128.78it/s]Padding data:  31%|███       | 636/2042 [00:04<00:11, 127.00it/s]Padding data:  32%|███▏      | 650/2042 [00:05<00:10, 129.78it/s]Padding data:  33%|███▎      | 664/2042 [00:05<00:11, 125.25it/s]Padding data:  33%|███▎      | 678/2042 [00:05<00:10, 127.39it/s]Padding data:  34%|███▍      | 691/2042 [00:05<00:10, 125.25it/s]Padding data:  35%|███▍      | 705/2042 [00:05<00:10, 126.80it/s]Padding data:  35%|███▌      | 718/2042 [00:05<00:10, 121.39it/s]Padding data:  36%|███▌      | 731/2042 [00:05<00:10, 123.06it/s]Padding data:  37%|███▋      | 746/2042 [00:05<00:10, 128.70it/s]Padding data:  37%|███▋      | 761/2042 [00:05<00:09, 132.37it/s]Padding data:  38%|███▊      | 775/2042 [00:05<00:09, 133.67it/s]Padding data:  39%|███▊      | 789/2042 [00:06<00:09, 134.20it/s]Padding data:  39%|███▉      | 804/2042 [00:06<00:09, 137.26it/s]Padding data:  40%|████      | 818/2042 [00:06<00:08, 137.94it/s]Padding data:  41%|████      | 833/2042 [00:06<00:08, 140.79it/s]Padding data:  42%|████▏     | 848/2042 [00:06<00:08, 136.94it/s]Padding data:  42%|████▏     | 863/2042 [00:06<00:08, 138.44it/s]Padding data:  43%|████▎     | 877/2042 [00:06<00:08, 137.96it/s]Padding data:  44%|████▎     | 891/2042 [00:06<00:08, 137.49it/s]Padding data:  44%|████▍     | 905/2042 [00:06<00:08, 137.87it/s]Padding data:  45%|████▌     | 920/2042 [00:07<00:08, 139.13it/s]Padding data:  46%|████▌     | 934/2042 [00:07<00:07, 138.68it/s]Padding data:  46%|████▋     | 948/2042 [00:07<00:07, 138.12it/s]Padding data:  47%|████▋     | 962/2042 [00:07<00:07, 137.88it/s]Padding data:  48%|████▊     | 977/2042 [00:07<00:07, 138.20it/s]Padding data:  49%|████▊     | 992/2042 [00:07<00:07, 140.21it/s]Padding data:  49%|████▉     | 1007/2042 [00:07<00:07, 136.82it/s]Padding data:  50%|█████     | 1021/2042 [00:07<00:07, 136.97it/s]Padding data:  51%|█████     | 1035/2042 [00:07<00:07, 133.92it/s]Padding data:  51%|█████▏    | 1049/2042 [00:07<00:07, 134.75it/s]Padding data:  52%|█████▏    | 1063/2042 [00:08<00:07, 132.42it/s]Padding data:  53%|█████▎    | 1077/2042 [00:08<00:07, 131.97it/s]Padding data:  53%|█████▎    | 1092/2042 [00:08<00:06, 136.22it/s]Padding data:  54%|█████▍    | 1107/2042 [00:08<00:06, 138.44it/s]Padding data:  55%|█████▍    | 1122/2042 [00:08<00:06, 140.04it/s]Padding data:  56%|█████▌    | 1137/2042 [00:08<00:06, 141.47it/s]Padding data:  56%|█████▋    | 1152/2042 [00:08<00:06, 142.60it/s]Padding data:  57%|█████▋    | 1167/2042 [00:08<00:06, 143.28it/s]Padding data:  58%|█████▊    | 1182/2042 [00:08<00:06, 143.28it/s]Padding data:  59%|█████▊    | 1197/2042 [00:09<00:06, 140.29it/s]Padding data:  59%|█████▉    | 1212/2042 [00:09<00:05, 139.41it/s]Padding data:  60%|██████    | 1227/2042 [00:09<00:05, 140.23it/s]Padding data:  61%|██████    | 1242/2042 [00:09<00:05, 140.15it/s]Padding data:  62%|██████▏   | 1257/2042 [00:09<00:05, 140.95it/s]Padding data:  62%|██████▏   | 1272/2042 [00:09<00:05, 142.46it/s]Padding data:  63%|██████▎   | 1287/2042 [00:09<00:05, 142.47it/s]Padding data:  64%|██████▍   | 1302/2042 [00:09<00:05, 143.87it/s]Padding data:  64%|██████▍   | 1317/2042 [00:09<00:05, 140.33it/s]Padding data:  65%|██████▌   | 1332/2042 [00:09<00:05, 141.21it/s]Padding data:  66%|██████▌   | 1347/2042 [00:10<00:04, 140.52it/s]Padding data:  67%|██████▋   | 1363/2042 [00:10<00:04, 142.86it/s]Padding data:  67%|██████▋   | 1378/2042 [00:10<00:04, 139.03it/s]Padding data:  68%|██████▊   | 1393/2042 [00:10<00:04, 140.77it/s]Padding data:  69%|██████▉   | 1408/2042 [00:10<00:04, 141.70it/s]Padding data:  70%|██████▉   | 1423/2042 [00:10<00:04, 140.06it/s]Padding data:  70%|███████   | 1438/2042 [00:10<00:04, 139.94it/s]Padding data:  71%|███████   | 1454/2042 [00:10<00:04, 145.52it/s]Padding data:  72%|███████▏  | 1469/2042 [00:10<00:04, 141.10it/s]Padding data:  73%|███████▎  | 1485/2042 [00:11<00:03, 144.64it/s]Padding data:  73%|███████▎  | 1500/2042 [00:11<00:03, 145.63it/s]Padding data:  74%|███████▍  | 1515/2042 [00:11<00:03, 138.73it/s]Padding data:  75%|███████▍  | 1529/2042 [00:11<00:03, 138.69it/s]Padding data:  76%|███████▌  | 1544/2042 [00:11<00:03, 141.31it/s]Padding data:  76%|███████▋  | 1559/2042 [00:11<00:03, 138.62it/s]Padding data:  77%|███████▋  | 1575/2042 [00:11<00:03, 141.32it/s]Padding data:  78%|███████▊  | 1590/2042 [00:11<00:03, 142.60it/s]Padding data:  79%|███████▊  | 1605/2042 [00:11<00:03, 139.16it/s]Padding data:  79%|███████▉  | 1619/2042 [00:12<00:03, 135.43it/s]Padding data:  80%|████████  | 1635/2042 [00:12<00:02, 140.52it/s]Padding data:  81%|████████  | 1650/2042 [00:12<00:02, 141.77it/s]Padding data:  82%|████████▏ | 1666/2042 [00:12<00:02, 145.48it/s]Padding data:  82%|████████▏ | 1681/2042 [00:12<00:02, 143.72it/s]Padding data:  83%|████████▎ | 1696/2042 [00:12<00:02, 144.30it/s]Padding data:  84%|████████▍ | 1711/2042 [00:12<00:02, 144.60it/s]Padding data:  85%|████████▍ | 1726/2042 [00:12<00:02, 142.92it/s]Padding data:  85%|████████▌ | 1741/2042 [00:12<00:02, 138.38it/s]Padding data:  86%|████████▌ | 1755/2042 [00:12<00:02, 138.68it/s]Padding data:  87%|████████▋ | 1769/2042 [00:13<00:01, 137.66it/s]Padding data:  87%|████████▋ | 1783/2042 [00:13<00:01, 135.41it/s]Padding data:  88%|████████▊ | 1797/2042 [00:13<00:01, 134.35it/s]Padding data:  89%|████████▊ | 1811/2042 [00:13<00:01, 134.44it/s]Padding data:  89%|████████▉ | 1825/2042 [00:13<00:01, 135.29it/s]Padding data:  90%|█████████ | 1839/2042 [00:13<00:01, 133.41it/s]Padding data:  91%|█████████ | 1854/2042 [00:13<00:01, 136.21it/s]Padding data:  92%|█████████▏| 1869/2042 [00:13<00:01, 139.27it/s]Padding data:  92%|█████████▏| 1883/2042 [00:13<00:01, 137.14it/s]Padding data:  93%|█████████▎| 1898/2042 [00:14<00:01, 140.49it/s]Padding data:  94%|█████████▎| 1913/2042 [00:14<00:00, 142.43it/s]Padding data:  94%|█████████▍| 1928/2042 [00:14<00:00, 143.37it/s]Padding data:  95%|█████████▌| 1943/2042 [00:14<00:00, 144.89it/s]Padding data:  96%|█████████▌| 1958/2042 [00:14<00:00, 145.45it/s]Padding data:  97%|█████████▋| 1973/2042 [00:14<00:00, 144.44it/s]Padding data:  97%|█████████▋| 1988/2042 [00:14<00:00, 141.51it/s]Padding data:  98%|█████████▊| 2003/2042 [00:14<00:00, 137.86it/s]Padding data:  99%|█████████▉| 2018/2042 [00:14<00:00, 139.53it/s]Padding data: 100%|█████████▉| 2032/2042 [00:14<00:00, 139.07it/s]Padding data: 100%|██████████| 2042/2042 [00:15<00:00, 135.60it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 400, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 400, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 400, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 400, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 400, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 400, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 400, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 400, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 400, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 400, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 400, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 400, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 400, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 400, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 400, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 400, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 400, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 400, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 400, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 400, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 400, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 400, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 400, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 400, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 400, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 400, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 400, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 400, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 400, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 400, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 1014s - loss: 0.6259
Epoch 2/100
4382/4382 - 978s - loss: 0.6125
Epoch 3/100
4382/4382 - 983s - loss: 0.6055
Epoch 4/100
4382/4382 - 987s - loss: 0.6015
Epoch 5/100
4382/4382 - 988s - loss: 0.5948
Epoch 6/100
4382/4382 - 985s - loss: 0.5894
Epoch 7/100
4382/4382 - 986s - loss: 0.5850
Epoch 8/100
4382/4382 - 984s - loss: 0.5795
Epoch 9/100
4382/4382 - 985s - loss: 0.5756
Epoch 10/100
4382/4382 - 985s - loss: 0.5692
Epoch 11/100
4382/4382 - 985s - loss: 0.5629
Epoch 12/100
4382/4382 - 985s - loss: 0.5592
Epoch 13/100
4382/4382 - 984s - loss: 0.5565
Epoch 14/100
4382/4382 - 985s - loss: 0.5470
Epoch 15/100
4382/4382 - 985s - loss: 0.5442
Epoch 16/100
4382/4382 - 986s - loss: 0.5422
Epoch 17/100
4382/4382 - 985s - loss: 0.5371
Epoch 18/100
4382/4382 - 984s - loss: 0.5327
Epoch 19/100
4382/4382 - 984s - loss: 0.5250
Epoch 20/100
4382/4382 - 986s - loss: 0.5188
Epoch 21/100
4382/4382 - 984s - loss: 0.5159
Epoch 22/100
4382/4382 - 986s - loss: 0.5128
Epoch 23/100
4382/4382 - 986s - loss: 0.5032
Epoch 24/100
4382/4382 - 986s - loss: 0.4973
Epoch 25/100
4382/4382 - 985s - loss: 0.4934
Epoch 26/100
4382/4382 - 986s - loss: 0.4874
Epoch 27/100
4382/4382 - 986s - loss: 0.4813
Epoch 28/100
4382/4382 - 987s - loss: 0.4840
Epoch 29/100
4382/4382 - 986s - loss: 0.4730
Epoch 30/100
4382/4382 - 987s - loss: 0.4667
Epoch 31/100
4382/4382 - 986s - loss: 0.4635
Epoch 32/100
4382/4382 - 986s - loss: 0.4563
Epoch 33/100
4382/4382 - 987s - loss: 0.4510
Epoch 34/100
4382/4382 - 988s - loss: 0.4435
Epoch 35/100
4382/4382 - 989s - loss: 0.4368
Epoch 36/100
4382/4382 - 989s - loss: 0.4274
Epoch 37/100
4382/4382 - 990s - loss: 0.4284
Epoch 38/100
4382/4382 - 990s - loss: 0.4211
Epoch 39/100
4382/4382 - 990s - loss: 0.4113
Epoch 40/100
4382/4382 - 989s - loss: 0.4070
Epoch 41/100
4382/4382 - 989s - loss: 0.3998
Epoch 42/100
4382/4382 - 990s - loss: 0.3958
Epoch 43/100
4382/4382 - 990s - loss: 0.3928
Epoch 44/100
4382/4382 - 988s - loss: 0.3887
Epoch 45/100
4382/4382 - 990s - loss: 0.3868
Epoch 46/100
4382/4382 - 988s - loss: 0.3778
Epoch 47/100
4382/4382 - 981s - loss: 0.3774
Epoch 48/100
4382/4382 - 1002s - loss: 0.3740
Epoch 49/100
4382/4382 - 1000s - loss: 0.3660
Epoch 50/100
4382/4382 - 999s - loss: 0.3657
Epoch 51/100
4382/4382 - 1001s - loss: 0.3618
Epoch 52/100
4382/4382 - 1001s - loss: 0.3556
Epoch 53/100
4382/4382 - 1001s - loss: 0.3530
Epoch 54/100
4382/4382 - 1000s - loss: 0.3530
Epoch 55/100
4382/4382 - 1002s - loss: 0.3457
Epoch 56/100
4382/4382 - 1001s - loss: 0.3414
Epoch 57/100
4382/4382 - 1002s - loss: 0.3366
Epoch 58/100
4382/4382 - 1002s - loss: 0.3279
Epoch 59/100
4382/4382 - 1000s - loss: 0.3282
Epoch 60/100
4382/4382 - 1001s - loss: 0.3232
Epoch 61/100
4382/4382 - 1000s - loss: 0.3234
Epoch 62/100
4382/4382 - 1001s - loss: 0.3150
Epoch 63/100
4382/4382 - 1000s - loss: 0.3211
Epoch 64/100
4382/4382 - 999s - loss: 0.3083
Epoch 65/100
4382/4382 - 1000s - loss: 0.3082
Epoch 66/100
4382/4382 - 1000s - loss: 0.2995
Epoch 67/100
4382/4382 - 998s - loss: 0.2958
Epoch 68/100
4382/4382 - 1000s - loss: 0.2971
Epoch 69/100
4382/4382 - 999s - loss: 0.2922
Epoch 70/100
4382/4382 - 1000s - loss: 0.2853
Epoch 71/100
4382/4382 - 999s - loss: 0.2873
Epoch 72/100
4382/4382 - 1000s - loss: 0.2796
Epoch 73/100
4382/4382 - 1001s - loss: 0.2829
Epoch 74/100
4382/4382 - 1002s - loss: 0.2721
Epoch 75/100
4382/4382 - 1000s - loss: 0.2675
Epoch 76/100
4382/4382 - 1000s - loss: 0.2678
Epoch 77/100
4382/4382 - 1001s - loss: 0.2647
Epoch 78/100
4382/4382 - 1002s - loss: 0.2641
Epoch 79/100
4382/4382 - 1000s - loss: 0.2582
Epoch 80/100
4382/4382 - 1000s - loss: 0.2622
Epoch 81/100
4382/4382 - 1000s - loss: 0.2672
Epoch 82/100
4382/4382 - 1004s - loss: 0.2551
Epoch 83/100
4382/4382 - 1001s - loss: 0.2534
Epoch 84/100
4382/4382 - 1000s - loss: 0.2485
Epoch 85/100
4382/4382 - 998s - loss: 0.2522
Epoch 86/100
4382/4382 - 997s - loss: 0.2421
Epoch 87/100
4382/4382 - 998s - loss: 0.2403
Epoch 88/100
4382/4382 - 995s - loss: 0.2346
Epoch 89/100
4382/4382 - 998s - loss: 0.2382
Epoch 90/100
4382/4382 - 1000s - loss: 0.2297
Epoch 91/100
4382/4382 - 1000s - loss: 0.2282
Epoch 92/100
4382/4382 - 995s - loss: 0.2207
Epoch 93/100
4382/4382 - 996s - loss: 0.2124
Epoch 94/100
4382/4382 - 997s - loss: 0.2194
Epoch 95/100
4382/4382 - 999s - loss: 0.2198
Epoch 96/100
4382/4382 - 997s - loss: 0.2093
Epoch 97/100
4382/4382 - 1000s - loss: 0.2104
Epoch 98/100
4382/4382 - 997s - loss: 0.2019
Epoch 99/100
4382/4382 - 998s - loss: 0.2030
Epoch 100/100
4382/4382 - 999s - loss: 0.2057
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.48902553903846524
Test f1_avg: 0.4787151563387155
