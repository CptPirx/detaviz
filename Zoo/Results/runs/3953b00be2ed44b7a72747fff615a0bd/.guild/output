INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 135.51it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:17, 116.22it/s]Padding data:   2%|▏         | 40/2042 [00:00<00:19, 103.49it/s]Padding data:   2%|▏         | 51/2042 [00:00<00:19, 103.85it/s]Padding data:   3%|▎         | 63/2042 [00:00<00:18, 107.40it/s]Padding data:   4%|▎         | 75/2042 [00:00<00:17, 110.00it/s]Padding data:   4%|▍         | 89/2042 [00:00<00:16, 116.72it/s]Padding data:   5%|▍         | 101/2042 [00:00<00:16, 117.45it/s]Padding data:   6%|▌         | 115/2042 [00:01<00:15, 120.88it/s]Padding data:   6%|▋         | 128/2042 [00:01<00:16, 119.55it/s]Padding data:   7%|▋         | 140/2042 [00:01<00:16, 118.76it/s]Padding data:   7%|▋         | 152/2042 [00:01<00:15, 118.33it/s]Padding data:   8%|▊         | 165/2042 [00:01<00:15, 119.23it/s]Padding data:   9%|▉         | 179/2042 [00:01<00:15, 123.55it/s]Padding data:   9%|▉         | 192/2042 [00:01<00:15, 119.76it/s]Padding data:  10%|█         | 205/2042 [00:01<00:15, 119.86it/s]Padding data:  11%|█         | 218/2042 [00:01<00:15, 119.03it/s]Padding data:  11%|█▏        | 231/2042 [00:01<00:15, 120.45it/s]Padding data:  12%|█▏        | 245/2042 [00:02<00:14, 125.23it/s]Padding data:  13%|█▎        | 259/2042 [00:02<00:13, 127.68it/s]Padding data:  13%|█▎        | 273/2042 [00:02<00:13, 131.18it/s]Padding data:  14%|█▍        | 287/2042 [00:02<00:13, 132.94it/s]Padding data:  15%|█▍        | 301/2042 [00:02<00:13, 132.99it/s]Padding data:  15%|█▌        | 316/2042 [00:02<00:12, 135.56it/s]Padding data:  16%|█▌        | 331/2042 [00:02<00:12, 137.43it/s]Padding data:  17%|█▋        | 345/2042 [00:02<00:12, 135.39it/s]Padding data:  18%|█▊        | 359/2042 [00:02<00:12, 133.15it/s]Padding data:  18%|█▊        | 373/2042 [00:03<00:12, 131.98it/s]Padding data:  19%|█▉        | 387/2042 [00:03<00:12, 129.75it/s]Padding data:  20%|█▉        | 401/2042 [00:03<00:12, 131.29it/s]Padding data:  20%|██        | 415/2042 [00:03<00:12, 133.72it/s]Padding data:  21%|██        | 429/2042 [00:03<00:12, 126.70it/s]Padding data:  22%|██▏       | 443/2042 [00:03<00:12, 128.50it/s]Padding data:  22%|██▏       | 456/2042 [00:03<00:12, 126.37it/s]Padding data:  23%|██▎       | 469/2042 [00:03<00:12, 125.80it/s]Padding data:  24%|██▎       | 483/2042 [00:03<00:12, 128.30it/s]Padding data:  24%|██▍       | 497/2042 [00:03<00:11, 129.83it/s]Padding data:  25%|██▌       | 511/2042 [00:04<00:11, 130.35it/s]Padding data:  26%|██▌       | 525/2042 [00:04<00:11, 129.42it/s]Padding data:  26%|██▋       | 539/2042 [00:04<00:11, 131.16it/s]Padding data:  27%|██▋       | 553/2042 [00:04<00:11, 133.70it/s]Padding data:  28%|██▊       | 567/2042 [00:04<00:11, 132.29it/s]Padding data:  28%|██▊       | 581/2042 [00:04<00:11, 128.11it/s]Padding data:  29%|██▉       | 594/2042 [00:04<00:11, 123.62it/s]Padding data:  30%|██▉       | 607/2042 [00:04<00:12, 114.54it/s]Padding data:  30%|███       | 620/2042 [00:04<00:12, 117.10it/s]Padding data:  31%|███       | 633/2042 [00:05<00:11, 118.24it/s]Padding data:  32%|███▏      | 647/2042 [00:05<00:11, 122.64it/s]Padding data:  32%|███▏      | 660/2042 [00:05<00:11, 124.22it/s]Padding data:  33%|███▎      | 673/2042 [00:05<00:11, 122.20it/s]Padding data:  34%|███▎      | 687/2042 [00:05<00:10, 126.64it/s]Padding data:  34%|███▍      | 700/2042 [00:05<00:10, 123.90it/s]Padding data:  35%|███▍      | 713/2042 [00:05<00:10, 125.55it/s]Padding data:  36%|███▌      | 726/2042 [00:05<00:10, 121.94it/s]Padding data:  36%|███▌      | 740/2042 [00:05<00:10, 126.14it/s]Padding data:  37%|███▋      | 754/2042 [00:06<00:09, 128.95it/s]Padding data:  38%|███▊      | 768/2042 [00:06<00:09, 131.69it/s]Padding data:  38%|███▊      | 783/2042 [00:06<00:09, 134.78it/s]Padding data:  39%|███▉      | 798/2042 [00:06<00:09, 138.05it/s]Padding data:  40%|███▉      | 813/2042 [00:06<00:08, 139.18it/s]Padding data:  40%|████      | 827/2042 [00:06<00:08, 138.60it/s]Padding data:  41%|████      | 841/2042 [00:06<00:08, 138.75it/s]Padding data:  42%|████▏     | 855/2042 [00:06<00:08, 135.58it/s]Padding data:  43%|████▎     | 869/2042 [00:06<00:08, 136.34it/s]Padding data:  43%|████▎     | 883/2042 [00:06<00:08, 136.22it/s]Padding data:  44%|████▍     | 897/2042 [00:07<00:08, 135.85it/s]Padding data:  45%|████▍     | 911/2042 [00:07<00:08, 133.84it/s]Padding data:  45%|████▌     | 926/2042 [00:07<00:08, 135.92it/s]Padding data:  46%|████▌     | 940/2042 [00:07<00:08, 134.59it/s]Padding data:  47%|████▋     | 954/2042 [00:07<00:08, 135.50it/s]Padding data:  47%|████▋     | 968/2042 [00:07<00:07, 135.02it/s]Padding data:  48%|████▊     | 982/2042 [00:07<00:07, 135.01it/s]Padding data:  49%|████▉     | 997/2042 [00:07<00:07, 137.23it/s]Padding data:  50%|████▉     | 1011/2042 [00:07<00:07, 133.74it/s]Padding data:  50%|█████     | 1025/2042 [00:08<00:07, 135.43it/s]Padding data:  51%|█████     | 1039/2042 [00:08<00:07, 129.74it/s]Padding data:  52%|█████▏    | 1053/2042 [00:08<00:07, 129.13it/s]Padding data:  52%|█████▏    | 1066/2042 [00:08<00:07, 123.35it/s]Padding data:  53%|█████▎    | 1079/2042 [00:08<00:07, 124.98it/s]Padding data:  54%|█████▎    | 1093/2042 [00:08<00:07, 128.95it/s]Padding data:  54%|█████▍    | 1108/2042 [00:08<00:07, 132.82it/s]Padding data:  55%|█████▍    | 1122/2042 [00:08<00:06, 133.12it/s]Padding data:  56%|█████▌    | 1137/2042 [00:08<00:06, 135.58it/s]Padding data:  56%|█████▋    | 1151/2042 [00:08<00:06, 136.18it/s]Padding data:  57%|█████▋    | 1166/2042 [00:09<00:06, 137.77it/s]Padding data:  58%|█████▊    | 1180/2042 [00:09<00:06, 137.98it/s]Padding data:  58%|█████▊    | 1194/2042 [00:09<00:06, 135.14it/s]Padding data:  59%|█████▉    | 1208/2042 [00:09<00:06, 135.39it/s]Padding data:  60%|█████▉    | 1222/2042 [00:09<00:06, 131.51it/s]Padding data:  61%|██████    | 1236/2042 [00:09<00:06, 131.14it/s]Padding data:  61%|██████    | 1250/2042 [00:09<00:06, 129.92it/s]Padding data:  62%|██████▏   | 1264/2042 [00:09<00:06, 129.63it/s]Padding data:  63%|██████▎   | 1277/2042 [00:09<00:06, 126.60it/s]Padding data:  63%|██████▎   | 1290/2042 [00:10<00:05, 127.55it/s]Padding data:  64%|██████▍   | 1304/2042 [00:10<00:05, 128.24it/s]Padding data:  64%|██████▍   | 1317/2042 [00:10<00:05, 128.73it/s]Padding data:  65%|██████▌   | 1331/2042 [00:10<00:05, 130.15it/s]Padding data:  66%|██████▌   | 1345/2042 [00:10<00:05, 127.28it/s]Padding data:  67%|██████▋   | 1358/2042 [00:10<00:05, 123.27it/s]Padding data:  67%|██████▋   | 1371/2042 [00:10<00:05, 117.93it/s]Padding data:  68%|██████▊   | 1384/2042 [00:10<00:05, 119.09it/s]Padding data:  68%|██████▊   | 1396/2042 [00:10<00:05, 111.50it/s]Padding data:  69%|██████▉   | 1408/2042 [00:11<00:05, 109.71it/s]Padding data:  70%|██████▉   | 1420/2042 [00:11<00:05, 107.54it/s]Padding data:  70%|███████   | 1433/2042 [00:11<00:05, 110.80it/s]Padding data:  71%|███████   | 1448/2042 [00:11<00:04, 120.24it/s]Padding data:  72%|███████▏  | 1461/2042 [00:11<00:04, 121.88it/s]Padding data:  72%|███████▏  | 1475/2042 [00:11<00:04, 126.78it/s]Padding data:  73%|███████▎  | 1489/2042 [00:11<00:04, 129.57it/s]Padding data:  74%|███████▎  | 1503/2042 [00:11<00:04, 131.77it/s]Padding data:  74%|███████▍  | 1517/2042 [00:11<00:04, 131.00it/s]Padding data:  75%|███████▍  | 1531/2042 [00:12<00:03, 131.45it/s]Padding data:  76%|███████▌  | 1546/2042 [00:12<00:03, 136.05it/s]Padding data:  76%|███████▋  | 1560/2042 [00:12<00:03, 133.23it/s]Padding data:  77%|███████▋  | 1575/2042 [00:12<00:03, 137.80it/s]Padding data:  78%|███████▊  | 1590/2042 [00:12<00:03, 140.68it/s]Padding data:  79%|███████▊  | 1605/2042 [00:12<00:03, 137.63it/s]Padding data:  79%|███████▉  | 1619/2042 [00:12<00:03, 134.74it/s]Padding data:  80%|████████  | 1634/2042 [00:12<00:02, 136.14it/s]Padding data:  81%|████████  | 1648/2042 [00:12<00:02, 136.50it/s]Padding data:  81%|████████▏ | 1663/2042 [00:12<00:02, 138.20it/s]Padding data:  82%|████████▏ | 1677/2042 [00:13<00:02, 136.39it/s]Padding data:  83%|████████▎ | 1691/2042 [00:13<00:02, 135.65it/s]Padding data:  83%|████████▎ | 1705/2042 [00:13<00:02, 126.25it/s]Padding data:  84%|████████▍ | 1718/2042 [00:13<00:02, 120.20it/s]Padding data:  85%|████████▍ | 1731/2042 [00:13<00:02, 111.93it/s]Padding data:  85%|████████▌ | 1744/2042 [00:13<00:02, 115.97it/s]Padding data:  86%|████████▌ | 1757/2042 [00:13<00:02, 119.07it/s]Padding data:  87%|████████▋ | 1771/2042 [00:13<00:02, 122.01it/s]Padding data:  87%|████████▋ | 1784/2042 [00:13<00:02, 122.60it/s]Padding data:  88%|████████▊ | 1797/2042 [00:14<00:02, 121.39it/s]Padding data:  89%|████████▊ | 1810/2042 [00:14<00:01, 122.96it/s]Padding data:  89%|████████▉ | 1824/2042 [00:14<00:01, 125.23it/s]Padding data:  90%|████████▉ | 1837/2042 [00:14<00:01, 123.73it/s]Padding data:  91%|█████████ | 1850/2042 [00:14<00:01, 124.16it/s]Padding data:  91%|█████████▏| 1864/2042 [00:14<00:01, 126.66it/s]Padding data:  92%|█████████▏| 1878/2042 [00:14<00:01, 128.06it/s]Padding data:  93%|█████████▎| 1892/2042 [00:14<00:01, 129.39it/s]Padding data:  93%|█████████▎| 1905/2042 [00:14<00:01, 128.35it/s]Padding data:  94%|█████████▍| 1919/2042 [00:15<00:00, 131.01it/s]Padding data:  95%|█████████▍| 1933/2042 [00:15<00:00, 129.43it/s]Padding data:  95%|█████████▌| 1947/2042 [00:15<00:00, 129.93it/s]Padding data:  96%|█████████▌| 1961/2042 [00:15<00:00, 132.26it/s]Padding data:  97%|█████████▋| 1975/2042 [00:15<00:00, 130.60it/s]Padding data:  97%|█████████▋| 1989/2042 [00:15<00:00, 129.74it/s]Padding data:  98%|█████████▊| 2002/2042 [00:15<00:00, 127.91it/s]Padding data:  99%|█████████▊| 2015/2042 [00:15<00:00, 122.83it/s]Padding data:  99%|█████████▉| 2028/2042 [00:15<00:00, 115.35it/s]Padding data: 100%|█████████▉| 2040/2042 [00:16<00:00, 110.25it/s]Padding data: 100%|██████████| 2042/2042 [00:16<00:00, 127.07it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 300, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 300, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 300, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 300, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 300, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 300, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 300, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 300, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 300, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 300, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 300, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 300, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 300, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 300, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 300, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 300, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 300, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 300, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 300, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 300, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 300, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 300, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 300, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 300, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 300, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 300, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 300, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 300, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 300, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 300, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 300, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 300, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 300, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 300, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 300, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 300, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 789s - loss: 0.6320
Epoch 2/100
4382/4382 - 768s - loss: 0.6149
Epoch 3/100
4382/4382 - 769s - loss: 0.6120
Epoch 4/100
4382/4382 - 770s - loss: 0.6085
Epoch 5/100
4382/4382 - 768s - loss: 0.6029
Epoch 6/100
4382/4382 - 769s - loss: 0.5965
Epoch 7/100
4382/4382 - 771s - loss: 0.5916
Epoch 8/100
4382/4382 - 763s - loss: 0.5868
Epoch 9/100
4382/4382 - 762s - loss: 0.5815
Epoch 10/100
4382/4382 - 766s - loss: 0.5770
Epoch 11/100
4382/4382 - 768s - loss: 0.5696
Epoch 12/100
4382/4382 - 768s - loss: 0.5627
Epoch 13/100
4382/4382 - 765s - loss: 0.5621
Epoch 14/100
4382/4382 - 763s - loss: 0.5552
Epoch 15/100
4382/4382 - 758s - loss: 0.5518
Epoch 16/100
4382/4382 - 748s - loss: 0.5446
Epoch 17/100
4382/4382 - 726s - loss: 0.5411
Epoch 18/100
4382/4382 - 724s - loss: 0.5352
Epoch 19/100
4382/4382 - 728s - loss: 0.5292
Epoch 20/100
4382/4382 - 729s - loss: 0.5266
Epoch 21/100
4382/4382 - 729s - loss: 0.5183
Epoch 22/100
4382/4382 - 730s - loss: 0.5128
Epoch 23/100
4382/4382 - 727s - loss: 0.5107
Epoch 24/100
4382/4382 - 728s - loss: 0.5067
Epoch 25/100
4382/4382 - 729s - loss: 0.4989
Epoch 26/100
4382/4382 - 733s - loss: 0.4934
Epoch 27/100
4382/4382 - 727s - loss: 0.4896
Epoch 28/100
4382/4382 - 726s - loss: 0.4836
Epoch 29/100
4382/4382 - 733s - loss: 0.4816
Epoch 30/100
4382/4382 - 734s - loss: 0.4744
Epoch 31/100
4382/4382 - 735s - loss: 0.4682
Epoch 32/100
4382/4382 - 734s - loss: 0.4674
Epoch 33/100
4382/4382 - 737s - loss: 0.4597
Epoch 34/100
4382/4382 - 734s - loss: 0.4553
Epoch 35/100
4382/4382 - 725s - loss: 0.4455
Epoch 36/100
4382/4382 - 731s - loss: 0.4438
Epoch 37/100
4382/4382 - 738s - loss: 0.4361
Epoch 38/100
4382/4382 - 734s - loss: 0.4340
Epoch 39/100
4382/4382 - 727s - loss: 0.4299
Epoch 40/100
4382/4382 - 725s - loss: 0.4205
Epoch 41/100
4382/4382 - 727s - loss: 0.4136
Epoch 42/100
4382/4382 - 726s - loss: 0.4152
Epoch 43/100
4382/4382 - 729s - loss: 0.4089
Epoch 44/100
4382/4382 - 728s - loss: 0.4037
Epoch 45/100
4382/4382 - 752s - loss: 0.3990
Epoch 46/100
4382/4382 - 754s - loss: 0.3914
Epoch 47/100
4382/4382 - 753s - loss: 0.3907
Epoch 48/100
4382/4382 - 752s - loss: 0.3830
Epoch 49/100
4382/4382 - 749s - loss: 0.3775
Epoch 50/100
4382/4382 - 745s - loss: 0.3712
Epoch 51/100
4382/4382 - 745s - loss: 0.3662
Epoch 52/100
4382/4382 - 746s - loss: 0.3636
Epoch 53/100
4382/4382 - 754s - loss: 0.3535
Epoch 54/100
4382/4382 - 754s - loss: 0.3520
Epoch 55/100
4382/4382 - 754s - loss: 0.3424
Epoch 56/100
4382/4382 - 759s - loss: 0.3468
Epoch 57/100
4382/4382 - 760s - loss: 0.3489
Epoch 58/100
4382/4382 - 764s - loss: 0.3437
Epoch 59/100
4382/4382 - 761s - loss: 0.3332
Epoch 60/100
4382/4382 - 760s - loss: 0.3309
Epoch 61/100
4382/4382 - 756s - loss: 0.3253
Epoch 62/100
4382/4382 - 757s - loss: 0.3255
Epoch 63/100
4382/4382 - 757s - loss: 0.3249
Epoch 64/100
4382/4382 - 763s - loss: 0.3119
Epoch 65/100
4382/4382 - 762s - loss: 0.3099
Epoch 66/100
4382/4382 - 762s - loss: 0.3180
Epoch 67/100
4382/4382 - 762s - loss: 0.2994
Epoch 68/100
4382/4382 - 762s - loss: 0.2951
Epoch 69/100
4382/4382 - 762s - loss: 0.2922
Epoch 70/100
4382/4382 - 761s - loss: 0.2959
Epoch 71/100
4382/4382 - 762s - loss: 0.2975
Epoch 72/100
4382/4382 - 763s - loss: 0.2866
Epoch 73/100
4382/4382 - 762s - loss: 0.2868
Epoch 74/100
4382/4382 - 760s - loss: 0.2862
Epoch 75/100
4382/4382 - 762s - loss: 0.2859
Epoch 76/100
4382/4382 - 761s - loss: 0.2856
Epoch 77/100
4382/4382 - 762s - loss: 0.2753
Epoch 78/100
4382/4382 - 762s - loss: 0.2791
Epoch 79/100
4382/4382 - 763s - loss: 0.2765
Epoch 80/100
4382/4382 - 767s - loss: 0.2638
Epoch 81/100
4382/4382 - 768s - loss: 0.2714
Epoch 82/100
4382/4382 - 769s - loss: 0.2721
Epoch 83/100
4382/4382 - 762s - loss: 0.2660
Epoch 84/100
4382/4382 - 761s - loss: 0.2718

Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 85/100
4382/4382 - 762s - loss: 0.2361
Epoch 86/100
4382/4382 - 761s - loss: 0.2266
Epoch 87/100
4382/4382 - 763s - loss: 0.2151
Epoch 88/100
4382/4382 - 765s - loss: 0.2152
Epoch 89/100
4382/4382 - 765s - loss: 0.2108
Epoch 90/100
4382/4382 - 766s - loss: 0.2040
Epoch 91/100
4382/4382 - 764s - loss: 0.2049
Epoch 92/100
4382/4382 - 764s - loss: 0.2002
Epoch 93/100
4382/4382 - 763s - loss: 0.1959
Epoch 94/100
4382/4382 - 766s - loss: 0.1902
Epoch 95/100
4382/4382 - 772s - loss: 0.1896
Epoch 96/100
4382/4382 - 776s - loss: 0.1862
Epoch 97/100
4382/4382 - 767s - loss: 0.1808
Epoch 98/100
4382/4382 - 769s - loss: 0.1774
Epoch 99/100
4382/4382 - 769s - loss: 0.1753
Epoch 100/100
4382/4382 - 769s - loss: 0.1752
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.5274006478065327
Test f1_avg: 0.5459441470520194
