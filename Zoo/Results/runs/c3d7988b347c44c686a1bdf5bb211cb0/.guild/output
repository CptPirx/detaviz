INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 138.75it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:15, 129.59it/s]Padding data:   2%|▏         | 41/2042 [00:00<00:15, 127.57it/s]Padding data:   3%|▎         | 54/2042 [00:00<00:16, 121.85it/s]Padding data:   3%|▎         | 67/2042 [00:00<00:16, 122.85it/s]Padding data:   4%|▍         | 80/2042 [00:00<00:16, 121.34it/s]Padding data:   5%|▍         | 94/2042 [00:00<00:15, 125.48it/s]Padding data:   5%|▌         | 107/2042 [00:00<00:15, 125.62it/s]Padding data:   6%|▌         | 120/2042 [00:00<00:15, 123.91it/s]Padding data:   7%|▋         | 133/2042 [00:01<00:15, 121.66it/s]Padding data:   7%|▋         | 147/2042 [00:01<00:15, 125.92it/s]Padding data:   8%|▊         | 160/2042 [00:01<00:15, 124.52it/s]Padding data:   9%|▊         | 174/2042 [00:01<00:14, 127.73it/s]Padding data:   9%|▉         | 187/2042 [00:01<00:14, 125.36it/s]Padding data:  10%|▉         | 200/2042 [00:01<00:14, 124.51it/s]Padding data:  10%|█         | 213/2042 [00:01<00:14, 123.26it/s]Padding data:  11%|█         | 226/2042 [00:01<00:14, 122.25it/s]Padding data:  12%|█▏        | 240/2042 [00:01<00:14, 125.91it/s]Padding data:  12%|█▏        | 253/2042 [00:02<00:14, 121.32it/s]Padding data:  13%|█▎        | 266/2042 [00:02<00:14, 120.23it/s]Padding data:  14%|█▎        | 279/2042 [00:02<00:14, 122.20it/s]Padding data:  14%|█▍        | 293/2042 [00:02<00:13, 126.77it/s]Padding data:  15%|█▌        | 307/2042 [00:02<00:13, 128.76it/s]Padding data:  16%|█▌        | 321/2042 [00:02<00:13, 131.47it/s]Padding data:  16%|█▋        | 335/2042 [00:02<00:12, 131.84it/s]Padding data:  17%|█▋        | 349/2042 [00:02<00:13, 129.77it/s]Padding data:  18%|█▊        | 363/2042 [00:02<00:12, 131.47it/s]Padding data:  18%|█▊        | 377/2042 [00:02<00:12, 129.61it/s]Padding data:  19%|█▉        | 391/2042 [00:03<00:12, 131.50it/s]Padding data:  20%|█▉        | 406/2042 [00:03<00:12, 134.54it/s]Padding data:  21%|██        | 420/2042 [00:03<00:12, 134.85it/s]Padding data:  21%|██▏       | 434/2042 [00:03<00:12, 127.94it/s]Padding data:  22%|██▏       | 448/2042 [00:03<00:12, 130.00it/s]Padding data:  23%|██▎       | 462/2042 [00:03<00:12, 123.70it/s]Padding data:  23%|██▎       | 476/2042 [00:03<00:12, 127.77it/s]Padding data:  24%|██▍       | 489/2042 [00:03<00:12, 127.73it/s]Padding data:  25%|██▍       | 503/2042 [00:03<00:11, 130.16it/s]Padding data:  25%|██▌       | 517/2042 [00:04<00:11, 127.56it/s]Padding data:  26%|██▌       | 531/2042 [00:04<00:11, 129.83it/s]Padding data:  27%|██▋       | 545/2042 [00:04<00:11, 130.72it/s]Padding data:  27%|██▋       | 559/2042 [00:04<00:11, 132.25it/s]Padding data:  28%|██▊       | 573/2042 [00:04<00:11, 131.55it/s]Padding data:  29%|██▊       | 587/2042 [00:04<00:11, 129.96it/s]Padding data:  29%|██▉       | 601/2042 [00:04<00:11, 130.76it/s]Padding data:  30%|███       | 615/2042 [00:04<00:11, 129.43it/s]Padding data:  31%|███       | 628/2042 [00:04<00:11, 127.02it/s]Padding data:  31%|███▏      | 641/2042 [00:05<00:11, 125.13it/s]Padding data:  32%|███▏      | 655/2042 [00:05<00:10, 128.82it/s]Padding data:  33%|███▎      | 668/2042 [00:05<00:10, 128.11it/s]Padding data:  33%|███▎      | 683/2042 [00:05<00:10, 132.23it/s]Padding data:  34%|███▍      | 697/2042 [00:05<00:10, 130.14it/s]Padding data:  35%|███▍      | 711/2042 [00:05<00:10, 130.53it/s]Padding data:  36%|███▌      | 725/2042 [00:05<00:10, 128.20it/s]Padding data:  36%|███▌      | 739/2042 [00:05<00:10, 130.04it/s]Padding data:  37%|███▋      | 754/2042 [00:05<00:09, 133.02it/s]Padding data:  38%|███▊      | 768/2042 [00:05<00:09, 134.25it/s]Padding data:  38%|███▊      | 783/2042 [00:06<00:09, 135.84it/s]Padding data:  39%|███▉      | 797/2042 [00:06<00:09, 136.36it/s]Padding data:  40%|███▉      | 812/2042 [00:06<00:08, 139.41it/s]Padding data:  40%|████      | 827/2042 [00:06<00:08, 140.42it/s]Padding data:  41%|████      | 842/2042 [00:06<00:08, 140.23it/s]Padding data:  42%|████▏     | 857/2042 [00:06<00:08, 140.60it/s]Padding data:  43%|████▎     | 872/2042 [00:06<00:08, 140.76it/s]Padding data:  43%|████▎     | 887/2042 [00:06<00:08, 141.56it/s]Padding data:  44%|████▍     | 902/2042 [00:06<00:08, 142.08it/s]Padding data:  45%|████▍     | 917/2042 [00:07<00:08, 139.44it/s]Padding data:  46%|████▌     | 932/2042 [00:07<00:07, 139.82it/s]Padding data:  46%|████▋     | 946/2042 [00:07<00:07, 138.18it/s]Padding data:  47%|████▋     | 961/2042 [00:07<00:07, 139.51it/s]Padding data:  48%|████▊     | 976/2042 [00:07<00:07, 141.92it/s]Padding data:  49%|████▊     | 991/2042 [00:07<00:07, 143.20it/s]Padding data:  49%|████▉     | 1006/2042 [00:07<00:07, 142.02it/s]Padding data:  50%|█████     | 1021/2042 [00:07<00:07, 142.06it/s]Padding data:  51%|█████     | 1036/2042 [00:07<00:07, 136.48it/s]Padding data:  51%|█████▏    | 1050/2042 [00:08<00:07, 134.27it/s]Padding data:  52%|█████▏    | 1064/2042 [00:08<00:07, 131.06it/s]Padding data:  53%|█████▎    | 1078/2042 [00:08<00:07, 129.22it/s]Padding data:  54%|█████▎    | 1093/2042 [00:08<00:07, 132.36it/s]Padding data:  54%|█████▍    | 1107/2042 [00:08<00:07, 132.75it/s]Padding data:  55%|█████▍    | 1122/2042 [00:08<00:06, 135.24it/s]Padding data:  56%|█████▌    | 1137/2042 [00:08<00:06, 137.73it/s]Padding data:  56%|█████▋    | 1152/2042 [00:08<00:06, 139.31it/s]Padding data:  57%|█████▋    | 1166/2042 [00:08<00:06, 139.39it/s]Padding data:  58%|█████▊    | 1181/2042 [00:08<00:06, 139.52it/s]Padding data:  59%|█████▊    | 1195/2042 [00:09<00:06, 136.58it/s]Padding data:  59%|█████▉    | 1209/2042 [00:09<00:06, 137.30it/s]Padding data:  60%|█████▉    | 1223/2042 [00:09<00:06, 135.94it/s]Padding data:  61%|██████    | 1237/2042 [00:09<00:06, 132.83it/s]Padding data:  61%|██████▏   | 1251/2042 [00:09<00:05, 133.28it/s]Padding data:  62%|██████▏   | 1265/2042 [00:09<00:05, 133.05it/s]Padding data:  63%|██████▎   | 1279/2042 [00:09<00:05, 133.20it/s]Padding data:  63%|██████▎   | 1293/2042 [00:09<00:05, 133.62it/s]Padding data:  64%|██████▍   | 1307/2042 [00:09<00:05, 133.55it/s]Padding data:  65%|██████▍   | 1321/2042 [00:10<00:05, 134.56it/s]Padding data:  65%|██████▌   | 1335/2042 [00:10<00:05, 124.68it/s]Padding data:  66%|██████▌   | 1348/2042 [00:10<00:05, 121.09it/s]Padding data:  67%|██████▋   | 1361/2042 [00:10<00:05, 118.18it/s]Padding data:  67%|██████▋   | 1373/2042 [00:10<00:05, 116.15it/s]Padding data:  68%|██████▊   | 1388/2042 [00:10<00:05, 124.06it/s]Padding data:  69%|██████▊   | 1401/2042 [00:10<00:05, 121.63it/s]Padding data:  69%|██████▉   | 1415/2042 [00:10<00:05, 125.23it/s]Padding data:  70%|██████▉   | 1428/2042 [00:10<00:04, 124.49it/s]Padding data:  71%|███████   | 1442/2042 [00:11<00:04, 128.82it/s]Padding data:  71%|███████▏  | 1456/2042 [00:11<00:04, 130.34it/s]Padding data:  72%|███████▏  | 1470/2042 [00:11<00:04, 130.14it/s]Padding data:  73%|███████▎  | 1485/2042 [00:11<00:04, 132.98it/s]Padding data:  73%|███████▎  | 1499/2042 [00:11<00:04, 134.11it/s]Padding data:  74%|███████▍  | 1513/2042 [00:11<00:04, 131.96it/s]Padding data:  75%|███████▍  | 1527/2042 [00:11<00:03, 128.85it/s]Padding data:  76%|███████▌  | 1542/2042 [00:11<00:03, 134.39it/s]Padding data:  76%|███████▌  | 1556/2042 [00:11<00:03, 130.08it/s]Padding data:  77%|███████▋  | 1571/2042 [00:11<00:03, 135.08it/s]Padding data:  78%|███████▊  | 1585/2042 [00:12<00:03, 132.39it/s]Padding data:  78%|███████▊  | 1599/2042 [00:12<00:03, 134.09it/s]Padding data:  79%|███████▉  | 1613/2042 [00:12<00:03, 130.44it/s]Padding data:  80%|███████▉  | 1627/2042 [00:12<00:03, 132.24it/s]Padding data:  80%|████████  | 1641/2042 [00:12<00:03, 133.46it/s]Padding data:  81%|████████  | 1656/2042 [00:12<00:02, 136.16it/s]Padding data:  82%|████████▏ | 1670/2042 [00:12<00:02, 137.03it/s]Padding data:  82%|████████▏ | 1684/2042 [00:12<00:02, 135.68it/s]Padding data:  83%|████████▎ | 1698/2042 [00:12<00:02, 134.90it/s]Padding data:  84%|████████▍ | 1713/2042 [00:13<00:02, 138.15it/s]Padding data:  85%|████████▍ | 1727/2042 [00:13<00:02, 134.29it/s]Padding data:  85%|████████▌ | 1741/2042 [00:13<00:02, 131.69it/s]Padding data:  86%|████████▌ | 1755/2042 [00:13<00:02, 131.05it/s]Padding data:  87%|████████▋ | 1769/2042 [00:13<00:02, 128.61it/s]Padding data:  87%|████████▋ | 1782/2042 [00:13<00:02, 128.18it/s]Padding data:  88%|████████▊ | 1795/2042 [00:13<00:01, 125.42it/s]Padding data:  89%|████████▊ | 1808/2042 [00:13<00:01, 126.28it/s]Padding data:  89%|████████▉ | 1821/2042 [00:13<00:01, 124.67it/s]Padding data:  90%|████████▉ | 1834/2042 [00:14<00:01, 123.41it/s]Padding data:  90%|█████████ | 1847/2042 [00:14<00:01, 120.80it/s]Padding data:  91%|█████████ | 1862/2042 [00:14<00:01, 126.92it/s]Padding data:  92%|█████████▏| 1875/2042 [00:14<00:01, 127.12it/s]Padding data:  93%|█████████▎| 1889/2042 [00:14<00:01, 129.16it/s]Padding data:  93%|█████████▎| 1902/2042 [00:14<00:01, 128.55it/s]Padding data:  94%|█████████▍| 1916/2042 [00:14<00:00, 130.99it/s]Padding data:  95%|█████████▍| 1930/2042 [00:14<00:00, 131.12it/s]Padding data:  95%|█████████▌| 1944/2042 [00:14<00:00, 133.50it/s]Padding data:  96%|█████████▌| 1958/2042 [00:14<00:00, 134.49it/s]Padding data:  97%|█████████▋| 1972/2042 [00:15<00:00, 134.06it/s]Padding data:  97%|█████████▋| 1986/2042 [00:15<00:00, 132.80it/s]Padding data:  98%|█████████▊| 2000/2042 [00:15<00:00, 131.06it/s]Padding data:  99%|█████████▊| 2014/2042 [00:15<00:00, 132.45it/s]Padding data:  99%|█████████▉| 2028/2042 [00:15<00:00, 133.83it/s]Padding data: 100%|██████████| 2042/2042 [00:15<00:00, 132.09it/s]Padding data: 100%|██████████| 2042/2042 [00:15<00:00, 131.02it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 300, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 300, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 300, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 300, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 300, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 300, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 300, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 300, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 300, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 300, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 300, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 300, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 300, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 300, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 300, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 300, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 300, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 300, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 300, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 300, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 300, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 300, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 300, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 300, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 300, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 300, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 300, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 300, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 300, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 300, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 300, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 300, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 300, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 300, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 300, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 300, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 794s - loss: 0.6300
Epoch 2/100
4382/4382 - 767s - loss: 0.6151
Epoch 3/100
4382/4382 - 768s - loss: 0.6119
Epoch 4/100
4382/4382 - 766s - loss: 0.6069
Epoch 5/100
4382/4382 - 766s - loss: 0.6031
Epoch 6/100
4382/4382 - 768s - loss: 0.6000
Epoch 7/100
4382/4382 - 765s - loss: 0.5924
Epoch 8/100
4382/4382 - 760s - loss: 0.5881
Epoch 9/100
4382/4382 - 736s - loss: 0.5844
Epoch 10/100
4382/4382 - 740s - loss: 0.5756
Epoch 11/100
4382/4382 - 731s - loss: 0.5709
Epoch 12/100
4382/4382 - 734s - loss: 0.5674
Epoch 13/100
4382/4382 - 738s - loss: 0.5611
Epoch 14/100
4382/4382 - 741s - loss: 0.5549
Epoch 15/100
4382/4382 - 740s - loss: 0.5475
Epoch 16/100
4382/4382 - 736s - loss: 0.5402
Epoch 17/100
4382/4382 - 734s - loss: 0.5336
Epoch 18/100
4382/4382 - 731s - loss: 0.5241
Epoch 19/100
4382/4382 - 741s - loss: 0.5206
Epoch 20/100
4382/4382 - 741s - loss: 0.5156
Epoch 21/100
4382/4382 - 739s - loss: 0.5071
Epoch 22/100
4382/4382 - 737s - loss: 0.5023
Epoch 23/100
4382/4382 - 734s - loss: 0.5002
Epoch 24/100
4382/4382 - 738s - loss: 0.4926
Epoch 25/100
4382/4382 - 733s - loss: 0.4817
Epoch 26/100
4382/4382 - 753s - loss: 0.4781
Epoch 27/100
4382/4382 - 742s - loss: 0.4698
Epoch 28/100
4382/4382 - 743s - loss: 0.4656
Epoch 29/100
4382/4382 - 743s - loss: 0.4552
Epoch 30/100
4382/4382 - 742s - loss: 0.4425
Epoch 31/100
4382/4382 - 743s - loss: 0.4344
Epoch 32/100
4382/4382 - 741s - loss: 0.4348
Epoch 33/100
4382/4382 - 742s - loss: 0.4276
Epoch 34/100
4382/4382 - 768s - loss: 0.4182
Epoch 35/100
4382/4382 - 773s - loss: 0.4083
Epoch 36/100
4382/4382 - 773s - loss: 0.4044
Epoch 37/100
4382/4382 - 774s - loss: 0.4033
Epoch 38/100
4382/4382 - 773s - loss: 0.3987
Epoch 39/100
4382/4382 - 772s - loss: 0.3881
Epoch 40/100
4382/4382 - 774s - loss: 0.3851
Epoch 41/100
4382/4382 - 773s - loss: 0.3859
Epoch 42/100
4382/4382 - 771s - loss: 0.3767
Epoch 43/100
4382/4382 - 776s - loss: 0.3702
Epoch 44/100
4382/4382 - 777s - loss: 0.3684
Epoch 45/100
4382/4382 - 777s - loss: 0.3583
Epoch 46/100
4382/4382 - 777s - loss: 0.3542
Epoch 47/100
4382/4382 - 776s - loss: 0.3579
Epoch 48/100
4382/4382 - 777s - loss: 0.3459
Epoch 49/100
4382/4382 - 776s - loss: 0.3438
Epoch 50/100
4382/4382 - 775s - loss: 0.3386
Epoch 51/100
4382/4382 - 775s - loss: 0.3281
Epoch 52/100
4382/4382 - 770s - loss: 0.3304
Epoch 53/100
4382/4382 - 776s - loss: 0.3246
Epoch 54/100
4382/4382 - 768s - loss: 0.3258
Epoch 55/100
4382/4382 - 775s - loss: 0.3191
Epoch 56/100
4382/4382 - 775s - loss: 0.3110
Epoch 57/100
4382/4382 - 775s - loss: 0.3148
Epoch 58/100
4382/4382 - 776s - loss: 0.3066
Epoch 59/100
4382/4382 - 774s - loss: 0.3034
Epoch 60/100
4382/4382 - 775s - loss: 0.3002
Epoch 61/100
4382/4382 - 774s - loss: 0.2953
Epoch 62/100
4382/4382 - 773s - loss: 0.2891
Epoch 63/100
4382/4382 - 775s - loss: 0.2910
Epoch 64/100
4382/4382 - 775s - loss: 0.2838
Epoch 65/100
4382/4382 - 775s - loss: 0.2816
Epoch 66/100
4382/4382 - 775s - loss: 0.2852
Epoch 67/100
4382/4382 - 775s - loss: 0.2803
Epoch 68/100
4382/4382 - 774s - loss: 0.2799
Epoch 69/100
4382/4382 - 768s - loss: 0.2703
Epoch 70/100
4382/4382 - 768s - loss: 0.2709
Epoch 71/100
4382/4382 - 769s - loss: 0.2713
Epoch 72/100
4382/4382 - 766s - loss: 0.2637
Epoch 73/100
4382/4382 - 767s - loss: 0.2651
Epoch 74/100
4382/4382 - 771s - loss: 0.2601
Epoch 75/100
4382/4382 - 775s - loss: 0.2560
Epoch 76/100
4382/4382 - 777s - loss: 0.2532
Epoch 77/100
4382/4382 - 775s - loss: 0.2561
Epoch 78/100
4382/4382 - 775s - loss: 0.2461
Epoch 79/100
4382/4382 - 775s - loss: 0.2544
Epoch 80/100
4382/4382 - 776s - loss: 0.2379
Epoch 81/100
4382/4382 - 769s - loss: 0.2415
Epoch 82/100
4382/4382 - 770s - loss: 0.2402
Epoch 83/100
4382/4382 - 768s - loss: 0.2324
Epoch 84/100
4382/4382 - 772s - loss: 0.2308
Epoch 85/100
4382/4382 - 774s - loss: 0.2243
Epoch 86/100
4382/4382 - 768s - loss: 0.2239
Epoch 87/100
4382/4382 - 770s - loss: 0.2200
Epoch 88/100
4382/4382 - 769s - loss: 0.2186
Epoch 89/100
4382/4382 - 768s - loss: 0.2176
Epoch 90/100
4382/4382 - 769s - loss: 0.2154
Epoch 91/100
4382/4382 - 769s - loss: 0.2123
Epoch 92/100
4382/4382 - 769s - loss: 0.2155
Epoch 93/100
4382/4382 - 760s - loss: 0.2132
Epoch 94/100
4382/4382 - 758s - loss: 0.2014
Epoch 95/100
4382/4382 - 758s - loss: 0.2027
Epoch 96/100
4382/4382 - 768s - loss: 0.1984
Epoch 97/100
4382/4382 - 769s - loss: 0.2060
Epoch 98/100
4382/4382 - 765s - loss: 0.1937
Epoch 99/100
4382/4382 - 766s - loss: 0.2015
Epoch 100/100
4382/4382 - 770s - loss: 0.1925
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.44152484265117875
Test f1_avg: 0.4313362226884069
