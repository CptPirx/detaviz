INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 138.87it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:16, 123.12it/s]Padding data:   2%|▏         | 41/2042 [00:00<00:16, 119.13it/s]Padding data:   3%|▎         | 53/2042 [00:00<00:17, 111.47it/s]Padding data:   3%|▎         | 65/2042 [00:00<00:19, 102.80it/s]Padding data:   4%|▎         | 76/2042 [00:00<00:19, 102.05it/s]Padding data:   4%|▍         | 90/2042 [00:00<00:17, 111.49it/s]Padding data:   5%|▍         | 102/2042 [00:00<00:17, 113.65it/s]Padding data:   6%|▌         | 115/2042 [00:01<00:16, 117.55it/s]Padding data:   6%|▌         | 127/2042 [00:01<00:16, 116.94it/s]Padding data:   7%|▋         | 139/2042 [00:01<00:16, 117.22it/s]Padding data:   7%|▋         | 152/2042 [00:01<00:15, 119.07it/s]Padding data:   8%|▊         | 165/2042 [00:01<00:15, 119.81it/s]Padding data:   9%|▉         | 179/2042 [00:01<00:15, 123.91it/s]Padding data:   9%|▉         | 192/2042 [00:01<00:15, 120.37it/s]Padding data:  10%|█         | 205/2042 [00:01<00:15, 122.23it/s]Padding data:  11%|█         | 218/2042 [00:01<00:15, 120.31it/s]Padding data:  11%|█▏        | 231/2042 [00:01<00:15, 118.26it/s]Padding data:  12%|█▏        | 243/2042 [00:02<00:15, 116.14it/s]Padding data:  13%|█▎        | 256/2042 [00:02<00:15, 118.30it/s]Padding data:  13%|█▎        | 271/2042 [00:02<00:14, 125.71it/s]Padding data:  14%|█▍        | 286/2042 [00:02<00:13, 130.23it/s]Padding data:  15%|█▍        | 301/2042 [00:02<00:12, 134.36it/s]Padding data:  15%|█▌        | 316/2042 [00:02<00:12, 138.56it/s]Padding data:  16%|█▌        | 331/2042 [00:02<00:12, 141.54it/s]Padding data:  17%|█▋        | 346/2042 [00:02<00:12, 140.92it/s]Padding data:  18%|█▊        | 361/2042 [00:02<00:11, 141.65it/s]Padding data:  18%|█▊        | 376/2042 [00:03<00:11, 141.37it/s]Padding data:  19%|█▉        | 391/2042 [00:03<00:11, 140.68it/s]Padding data:  20%|█▉        | 406/2042 [00:03<00:11, 142.63it/s]Padding data:  21%|██        | 421/2042 [00:03<00:11, 140.06it/s]Padding data:  21%|██▏       | 436/2042 [00:03<00:11, 136.21it/s]Padding data:  22%|██▏       | 450/2042 [00:03<00:11, 137.27it/s]Padding data:  23%|██▎       | 464/2042 [00:03<00:11, 133.26it/s]Padding data:  23%|██▎       | 479/2042 [00:03<00:11, 137.31it/s]Padding data:  24%|██▍       | 494/2042 [00:03<00:11, 138.81it/s]Padding data:  25%|██▍       | 509/2042 [00:03<00:10, 140.77it/s]Padding data:  26%|██▌       | 524/2042 [00:04<00:10, 139.12it/s]Padding data:  26%|██▋       | 539/2042 [00:04<00:10, 140.30it/s]Padding data:  27%|██▋       | 554/2042 [00:04<00:10, 141.96it/s]Padding data:  28%|██▊       | 569/2042 [00:04<00:10, 141.12it/s]Padding data:  29%|██▊       | 584/2042 [00:04<00:10, 136.84it/s]Padding data:  29%|██▉       | 599/2042 [00:04<00:10, 137.35it/s]Padding data:  30%|███       | 613/2042 [00:04<00:10, 135.85it/s]Padding data:  31%|███       | 627/2042 [00:04<00:10, 130.05it/s]Padding data:  31%|███▏      | 641/2042 [00:04<00:10, 129.25it/s]Padding data:  32%|███▏      | 655/2042 [00:05<00:10, 131.95it/s]Padding data:  33%|███▎      | 669/2042 [00:05<00:10, 130.39it/s]Padding data:  33%|███▎      | 684/2042 [00:05<00:10, 133.67it/s]Padding data:  34%|███▍      | 698/2042 [00:05<00:10, 130.96it/s]Padding data:  35%|███▍      | 712/2042 [00:05<00:10, 131.11it/s]Padding data:  36%|███▌      | 726/2042 [00:05<00:10, 128.22it/s]Padding data:  36%|███▌      | 740/2042 [00:05<00:10, 129.86it/s]Padding data:  37%|███▋      | 755/2042 [00:05<00:09, 132.84it/s]Padding data:  38%|███▊      | 770/2042 [00:05<00:09, 135.33it/s]Padding data:  38%|███▊      | 784/2042 [00:06<00:09, 135.44it/s]Padding data:  39%|███▉      | 799/2042 [00:06<00:09, 137.58it/s]Padding data:  40%|███▉      | 814/2042 [00:06<00:08, 140.24it/s]Padding data:  41%|████      | 829/2042 [00:06<00:08, 140.83it/s]Padding data:  41%|████▏     | 844/2042 [00:06<00:08, 139.93it/s]Padding data:  42%|████▏     | 859/2042 [00:06<00:08, 140.13it/s]Padding data:  43%|████▎     | 874/2042 [00:06<00:08, 139.90it/s]Padding data:  44%|████▎     | 889/2042 [00:06<00:08, 140.45it/s]Padding data:  44%|████▍     | 904/2042 [00:06<00:08, 141.63it/s]Padding data:  45%|████▌     | 919/2042 [00:06<00:07, 142.90it/s]Padding data:  46%|████▌     | 934/2042 [00:07<00:07, 142.64it/s]Padding data:  46%|████▋     | 949/2042 [00:07<00:07, 144.11it/s]Padding data:  47%|████▋     | 964/2042 [00:07<00:07, 142.48it/s]Padding data:  48%|████▊     | 979/2042 [00:07<00:07, 143.68it/s]Padding data:  49%|████▊     | 995/2042 [00:07<00:07, 145.94it/s]Padding data:  49%|████▉     | 1010/2042 [00:07<00:07, 143.35it/s]Padding data:  50%|█████     | 1025/2042 [00:07<00:07, 142.47it/s]Padding data:  51%|█████     | 1040/2042 [00:07<00:07, 138.87it/s]Padding data:  52%|█████▏    | 1054/2042 [00:07<00:07, 137.48it/s]Padding data:  52%|█████▏    | 1068/2042 [00:08<00:07, 133.65it/s]Padding data:  53%|█████▎    | 1083/2042 [00:08<00:06, 137.51it/s]Padding data:  54%|█████▍    | 1098/2042 [00:08<00:06, 138.30it/s]Padding data:  55%|█████▍    | 1114/2042 [00:08<00:06, 142.11it/s]Padding data:  55%|█████▌    | 1129/2042 [00:08<00:06, 142.20it/s]Padding data:  56%|█████▌    | 1144/2042 [00:08<00:06, 142.96it/s]Padding data:  57%|█████▋    | 1159/2042 [00:08<00:06, 143.92it/s]Padding data:  58%|█████▊    | 1175/2042 [00:08<00:05, 147.27it/s]Padding data:  58%|█████▊    | 1190/2042 [00:08<00:05, 143.74it/s]Padding data:  59%|█████▉    | 1205/2042 [00:09<00:05, 144.40it/s]Padding data:  60%|█████▉    | 1220/2042 [00:09<00:05, 143.31it/s]Padding data:  60%|██████    | 1235/2042 [00:09<00:05, 143.60it/s]Padding data:  61%|██████    | 1250/2042 [00:09<00:05, 144.19it/s]Padding data:  62%|██████▏   | 1265/2042 [00:09<00:05, 144.73it/s]Padding data:  63%|██████▎   | 1280/2042 [00:09<00:05, 144.74it/s]Padding data:  63%|██████▎   | 1295/2042 [00:09<00:05, 145.48it/s]Padding data:  64%|██████▍   | 1310/2042 [00:09<00:05, 144.40it/s]Padding data:  65%|██████▍   | 1325/2042 [00:09<00:04, 145.42it/s]Padding data:  66%|██████▌   | 1340/2042 [00:09<00:04, 145.89it/s]Padding data:  66%|██████▋   | 1356/2042 [00:10<00:04, 149.13it/s]Padding data:  67%|██████▋   | 1371/2042 [00:10<00:04, 143.39it/s]Padding data:  68%|██████▊   | 1387/2042 [00:10<00:04, 145.90it/s]Padding data:  69%|██████▊   | 1402/2042 [00:10<00:04, 142.20it/s]Padding data:  69%|██████▉   | 1417/2042 [00:10<00:04, 142.61it/s]Padding data:  70%|███████   | 1432/2042 [00:10<00:04, 139.29it/s]Padding data:  71%|███████   | 1448/2042 [00:10<00:04, 143.86it/s]Padding data:  72%|███████▏  | 1463/2042 [00:10<00:04, 140.21it/s]Padding data:  72%|███████▏  | 1479/2042 [00:10<00:03, 143.11it/s]Padding data:  73%|███████▎  | 1494/2042 [00:11<00:03, 140.18it/s]Padding data:  74%|███████▍  | 1509/2042 [00:11<00:03, 141.99it/s]Padding data:  75%|███████▍  | 1524/2042 [00:11<00:03, 139.32it/s]Padding data:  75%|███████▌  | 1540/2042 [00:11<00:03, 143.20it/s]Padding data:  76%|███████▌  | 1555/2042 [00:11<00:03, 140.87it/s]Padding data:  77%|███████▋  | 1571/2042 [00:11<00:03, 145.12it/s]Padding data:  78%|███████▊  | 1586/2042 [00:11<00:03, 144.71it/s]Padding data:  78%|███████▊  | 1601/2042 [00:11<00:03, 143.44it/s]Padding data:  79%|███████▉  | 1616/2042 [00:11<00:03, 141.25it/s]Padding data:  80%|███████▉  | 1632/2042 [00:11<00:02, 144.94it/s]Padding data:  81%|████████  | 1647/2042 [00:12<00:02, 145.44it/s]Padding data:  81%|████████▏ | 1663/2042 [00:12<00:02, 148.28it/s]Padding data:  82%|████████▏ | 1678/2042 [00:12<00:02, 147.52it/s]Padding data:  83%|████████▎ | 1693/2042 [00:12<00:02, 146.56it/s]Padding data:  84%|████████▎ | 1709/2042 [00:12<00:02, 148.98it/s]Padding data:  84%|████████▍ | 1724/2042 [00:12<00:02, 146.34it/s]Padding data:  85%|████████▌ | 1739/2042 [00:12<00:02, 141.60it/s]Padding data:  86%|████████▌ | 1754/2042 [00:12<00:02, 143.06it/s]Padding data:  87%|████████▋ | 1769/2042 [00:12<00:01, 141.35it/s]Padding data:  87%|████████▋ | 1784/2042 [00:13<00:01, 138.99it/s]Padding data:  88%|████████▊ | 1798/2042 [00:13<00:01, 136.49it/s]Padding data:  89%|████████▊ | 1812/2042 [00:13<00:01, 136.23it/s]Padding data:  89%|████████▉ | 1826/2042 [00:13<00:01, 136.18it/s]Padding data:  90%|█████████ | 1840/2042 [00:13<00:01, 133.35it/s]Padding data:  91%|█████████ | 1855/2042 [00:13<00:01, 136.14it/s]Padding data:  92%|█████████▏| 1871/2042 [00:13<00:01, 140.44it/s]Padding data:  92%|█████████▏| 1886/2042 [00:13<00:01, 139.05it/s]Padding data:  93%|█████████▎| 1901/2042 [00:13<00:01, 140.64it/s]Padding data:  94%|█████████▍| 1916/2042 [00:13<00:00, 142.89it/s]Padding data:  95%|█████████▍| 1931/2042 [00:14<00:00, 142.97it/s]Padding data:  95%|█████████▌| 1946/2042 [00:14<00:00, 142.99it/s]Padding data:  96%|█████████▌| 1961/2042 [00:14<00:00, 144.12it/s]Padding data:  97%|█████████▋| 1976/2042 [00:14<00:00, 142.07it/s]Padding data:  98%|█████████▊| 1991/2042 [00:14<00:00, 140.69it/s]Padding data:  98%|█████████▊| 2006/2042 [00:14<00:00, 136.82it/s]Padding data:  99%|█████████▉| 2021/2042 [00:14<00:00, 139.23it/s]Padding data: 100%|█████████▉| 2035/2042 [00:14<00:00, 139.25it/s]Padding data: 100%|██████████| 2042/2042 [00:14<00:00, 137.08it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 400, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 400, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 400, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 400, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 400, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 400, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 400, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 400, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 400, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 400, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 400, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 400, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 400, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 400, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 400, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 400, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 400, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 400, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 400, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 400, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 400, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 400, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 400, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 400, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 400, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 400, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 400, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 400, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 400, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 400, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 1021s - loss: 0.6262
Epoch 2/100
4382/4382 - 980s - loss: 0.6101
Epoch 3/100
4382/4382 - 985s - loss: 0.6077
Epoch 4/100
4382/4382 - 983s - loss: 0.6031
Epoch 5/100
4382/4382 - 983s - loss: 0.6008
Epoch 6/100
4382/4382 - 982s - loss: 0.5921
Epoch 7/100
4382/4382 - 983s - loss: 0.5863
Epoch 8/100
4382/4382 - 985s - loss: 0.5796
Epoch 9/100
4382/4382 - 982s - loss: 0.5726
Epoch 10/100
4382/4382 - 985s - loss: 0.5696
Epoch 11/100
4382/4382 - 983s - loss: 0.5669
Epoch 12/100
4382/4382 - 984s - loss: 0.5600
Epoch 13/100
4382/4382 - 992s - loss: 0.5560
Epoch 14/100
4382/4382 - 991s - loss: 0.5548
Epoch 15/100
4382/4382 - 991s - loss: 0.5453
Epoch 16/100
4382/4382 - 990s - loss: 0.5421
Epoch 17/100
4382/4382 - 989s - loss: 0.5373
Epoch 18/100
4382/4382 - 994s - loss: 0.5318
Epoch 19/100
4382/4382 - 991s - loss: 0.5281
Epoch 20/100
4382/4382 - 990s - loss: 0.5247
Epoch 21/100
4382/4382 - 989s - loss: 0.5166
Epoch 22/100
4382/4382 - 992s - loss: 0.5149
Epoch 23/100
4382/4382 - 993s - loss: 0.5084
Epoch 24/100
4382/4382 - 994s - loss: 0.5000
Epoch 25/100
4382/4382 - 993s - loss: 0.4941
Epoch 26/100
4382/4382 - 994s - loss: 0.4873
Epoch 27/100
4382/4382 - 994s - loss: 0.4843
Epoch 28/100
4382/4382 - 994s - loss: 0.4769
Epoch 29/100
4382/4382 - 993s - loss: 0.4680
Epoch 30/100
4382/4382 - 993s - loss: 0.4639
Epoch 31/100
4382/4382 - 993s - loss: 0.4590
Epoch 32/100
4382/4382 - 994s - loss: 0.4474
Epoch 33/100
4382/4382 - 993s - loss: 0.4419
Epoch 34/100
4382/4382 - 993s - loss: 0.4408
Epoch 35/100
4382/4382 - 992s - loss: 0.4337
Epoch 36/100
4382/4382 - 995s - loss: 0.4267
Epoch 37/100
4382/4382 - 994s - loss: 0.4184
Epoch 38/100
4382/4382 - 994s - loss: 0.4159
Epoch 39/100
4382/4382 - 993s - loss: 0.4084
Epoch 40/100
4382/4382 - 994s - loss: 0.4075
Epoch 41/100
4382/4382 - 994s - loss: 0.3988
Epoch 42/100
4382/4382 - 993s - loss: 0.3931
Epoch 43/100
4382/4382 - 994s - loss: 0.3893
Epoch 44/100
4382/4382 - 991s - loss: 0.3930
Epoch 45/100
4382/4382 - 990s - loss: 0.3800
Epoch 46/100
4382/4382 - 990s - loss: 0.3800
Epoch 47/100
4382/4382 - 990s - loss: 0.3770
Epoch 48/100
4382/4382 - 991s - loss: 0.3755
Epoch 49/100
4382/4382 - 991s - loss: 0.3652
Epoch 50/100
4382/4382 - 990s - loss: 0.3672
Epoch 51/100
4382/4382 - 993s - loss: 0.3629
Epoch 52/100
4382/4382 - 992s - loss: 0.3589
Epoch 53/100
4382/4382 - 992s - loss: 0.3583
Epoch 54/100
4382/4382 - 991s - loss: 0.3546
Epoch 55/100
4382/4382 - 991s - loss: 0.3515
Epoch 56/100
4382/4382 - 991s - loss: 0.3449
Epoch 57/100
4382/4382 - 991s - loss: 0.3407
Epoch 58/100
4382/4382 - 992s - loss: 0.3376
Epoch 59/100
4382/4382 - 991s - loss: 0.3397
Epoch 60/100
4382/4382 - 992s - loss: 0.3323
Epoch 61/100
4382/4382 - 992s - loss: 0.3298
Epoch 62/100
4382/4382 - 992s - loss: 0.3224
Epoch 63/100
4382/4382 - 991s - loss: 0.3263
Epoch 64/100
4382/4382 - 991s - loss: 0.3194
Epoch 65/100
4382/4382 - 991s - loss: 0.3209
Epoch 66/100
4382/4382 - 992s - loss: 0.3129
Epoch 67/100
4382/4382 - 990s - loss: 0.3117
Epoch 68/100
4382/4382 - 991s - loss: 0.3123
Epoch 69/100
4382/4382 - 991s - loss: 0.3108
Epoch 70/100
4382/4382 - 993s - loss: 0.3169
Epoch 71/100
4382/4382 - 993s - loss: 0.3047
Epoch 72/100
4382/4382 - 991s - loss: 0.3113
Epoch 73/100
4382/4382 - 993s - loss: 0.3077
Epoch 74/100
4382/4382 - 991s - loss: 0.3030
Epoch 75/100
4382/4382 - 991s - loss: 0.2985
Epoch 76/100
4382/4382 - 992s - loss: 0.2969
Epoch 77/100
4382/4382 - 993s - loss: 0.2936
Epoch 78/100
4382/4382 - 993s - loss: 0.2889
Epoch 79/100
4382/4382 - 992s - loss: 0.2914
Epoch 80/100
4382/4382 - 993s - loss: 0.2867
Epoch 81/100
4382/4382 - 992s - loss: 0.2887
Epoch 82/100
4382/4382 - 990s - loss: 0.2873
Epoch 83/100
4382/4382 - 997s - loss: 0.2802
Epoch 84/100
4382/4382 - 998s - loss: 0.2830
Epoch 85/100
4382/4382 - 997s - loss: 0.2763
Epoch 86/100
4382/4382 - 998s - loss: 0.2735
Epoch 87/100
4382/4382 - 997s - loss: 0.2734
Epoch 88/100
4382/4382 - 999s - loss: 0.2675
Epoch 89/100
4382/4382 - 998s - loss: 0.2709
Epoch 90/100
4382/4382 - 999s - loss: 0.2637
Epoch 91/100
4382/4382 - 997s - loss: 0.2715
Epoch 92/100
4382/4382 - 999s - loss: 0.2549
Epoch 93/100
4382/4382 - 997s - loss: 0.2549
Epoch 94/100
4382/4382 - 995s - loss: 0.2563
Epoch 95/100
4382/4382 - 1002s - loss: 0.2546
Epoch 96/100
4382/4382 - 995s - loss: 0.2482
Epoch 97/100
4382/4382 - 997s - loss: 0.2449
Epoch 98/100
4382/4382 - 995s - loss: 0.2560
Epoch 99/100
4382/4382 - 994s - loss: 0.2456
Epoch 100/100
4382/4382 - 990s - loss: 0.2451
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.49531576036635705
Test f1_avg: 0.4817223883390382
