INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 138.30it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:15, 128.76it/s]Padding data:   2%|▏         | 41/2042 [00:00<00:15, 126.85it/s]Padding data:   3%|▎         | 54/2042 [00:00<00:16, 123.99it/s]Padding data:   3%|▎         | 67/2042 [00:00<00:15, 124.80it/s]Padding data:   4%|▍         | 80/2042 [00:00<00:15, 125.01it/s]Padding data:   5%|▍         | 94/2042 [00:00<00:15, 129.20it/s]Padding data:   5%|▌         | 108/2042 [00:00<00:14, 131.35it/s]Padding data:   6%|▌         | 122/2042 [00:00<00:14, 129.16it/s]Padding data:   7%|▋         | 135/2042 [00:01<00:14, 127.62it/s]Padding data:   7%|▋         | 149/2042 [00:01<00:14, 129.68it/s]Padding data:   8%|▊         | 162/2042 [00:01<00:14, 128.40it/s]Padding data:   9%|▊         | 177/2042 [00:01<00:14, 132.16it/s]Padding data:   9%|▉         | 191/2042 [00:01<00:14, 129.21it/s]Padding data:  10%|█         | 205/2042 [00:01<00:14, 130.23it/s]Padding data:  11%|█         | 219/2042 [00:01<00:14, 127.71it/s]Padding data:  11%|█▏        | 233/2042 [00:01<00:14, 129.16it/s]Padding data:  12%|█▏        | 248/2042 [00:01<00:13, 132.95it/s]Padding data:  13%|█▎        | 263/2042 [00:02<00:13, 135.52it/s]Padding data:  14%|█▎        | 278/2042 [00:02<00:12, 138.08it/s]Padding data:  14%|█▍        | 293/2042 [00:02<00:12, 139.68it/s]Padding data:  15%|█▌        | 309/2042 [00:02<00:12, 142.61it/s]Padding data:  16%|█▌        | 324/2042 [00:02<00:11, 143.35it/s]Padding data:  17%|█▋        | 339/2042 [00:02<00:11, 142.26it/s]Padding data:  17%|█▋        | 354/2042 [00:02<00:11, 141.04it/s]Padding data:  18%|█▊        | 369/2042 [00:02<00:11, 139.84it/s]Padding data:  19%|█▉        | 384/2042 [00:02<00:11, 140.51it/s]Padding data:  20%|█▉        | 399/2042 [00:02<00:11, 140.67it/s]Padding data:  20%|██        | 414/2042 [00:03<00:11, 141.33it/s]Padding data:  21%|██        | 429/2042 [00:03<00:11, 135.45it/s]Padding data:  22%|██▏       | 443/2042 [00:03<00:11, 135.89it/s]Padding data:  22%|██▏       | 457/2042 [00:03<00:11, 132.72it/s]Padding data:  23%|██▎       | 471/2042 [00:03<00:11, 132.89it/s]Padding data:  24%|██▍       | 486/2042 [00:03<00:11, 135.24it/s]Padding data:  25%|██▍       | 501/2042 [00:03<00:11, 137.08it/s]Padding data:  25%|██▌       | 516/2042 [00:03<00:11, 135.69it/s]Padding data:  26%|██▌       | 530/2042 [00:03<00:11, 136.17it/s]Padding data:  27%|██▋       | 545/2042 [00:04<00:10, 138.89it/s]Padding data:  27%|██▋       | 560/2042 [00:04<00:10, 141.33it/s]Padding data:  28%|██▊       | 575/2042 [00:04<00:10, 136.09it/s]Padding data:  29%|██▉       | 589/2042 [00:04<00:10, 135.88it/s]Padding data:  30%|██▉       | 603/2042 [00:04<00:10, 133.78it/s]Padding data:  30%|███       | 617/2042 [00:04<00:10, 133.38it/s]Padding data:  31%|███       | 631/2042 [00:04<00:10, 129.81it/s]Padding data:  32%|███▏      | 645/2042 [00:04<00:10, 130.24it/s]Padding data:  32%|███▏      | 659/2042 [00:04<00:10, 131.30it/s]Padding data:  33%|███▎      | 673/2042 [00:05<00:10, 129.80it/s]Padding data:  34%|███▎      | 687/2042 [00:05<00:10, 132.05it/s]Padding data:  34%|███▍      | 701/2042 [00:05<00:10, 130.93it/s]Padding data:  35%|███▌      | 715/2042 [00:05<00:10, 128.00it/s]Padding data:  36%|███▌      | 728/2042 [00:05<00:10, 126.58it/s]Padding data:  36%|███▋      | 742/2042 [00:05<00:09, 130.26it/s]Padding data:  37%|███▋      | 756/2042 [00:05<00:09, 132.48it/s]Padding data:  38%|███▊      | 770/2042 [00:05<00:09, 132.82it/s]Padding data:  38%|███▊      | 784/2042 [00:05<00:09, 134.83it/s]Padding data:  39%|███▉      | 799/2042 [00:05<00:09, 137.76it/s]Padding data:  40%|███▉      | 814/2042 [00:06<00:08, 140.31it/s]Padding data:  41%|████      | 829/2042 [00:06<00:08, 141.30it/s]Padding data:  41%|████▏     | 844/2042 [00:06<00:08, 141.65it/s]Padding data:  42%|████▏     | 859/2042 [00:06<00:08, 140.51it/s]Padding data:  43%|████▎     | 874/2042 [00:06<00:08, 140.99it/s]Padding data:  44%|████▎     | 889/2042 [00:06<00:08, 140.73it/s]Padding data:  44%|████▍     | 904/2042 [00:06<00:08, 140.31it/s]Padding data:  45%|████▌     | 919/2042 [00:06<00:08, 140.36it/s]Padding data:  46%|████▌     | 934/2042 [00:06<00:08, 137.96it/s]Padding data:  46%|████▋     | 949/2042 [00:07<00:07, 139.95it/s]Padding data:  47%|████▋     | 964/2042 [00:07<00:07, 139.67it/s]Padding data:  48%|████▊     | 979/2042 [00:07<00:07, 140.87it/s]Padding data:  49%|████▊     | 994/2042 [00:07<00:07, 142.66it/s]Padding data:  49%|████▉     | 1009/2042 [00:07<00:07, 141.33it/s]Padding data:  50%|█████     | 1024/2042 [00:07<00:07, 142.51it/s]Padding data:  51%|█████     | 1039/2042 [00:07<00:07, 138.54it/s]Padding data:  52%|█████▏    | 1053/2042 [00:07<00:07, 138.15it/s]Padding data:  52%|█████▏    | 1067/2042 [00:07<00:07, 134.45it/s]Padding data:  53%|█████▎    | 1082/2042 [00:07<00:06, 137.37it/s]Padding data:  54%|█████▎    | 1096/2042 [00:08<00:06, 138.02it/s]Padding data:  54%|█████▍    | 1111/2042 [00:08<00:06, 140.39it/s]Padding data:  55%|█████▌    | 1126/2042 [00:08<00:06, 140.66it/s]Padding data:  56%|█████▌    | 1141/2042 [00:08<00:06, 141.09it/s]Padding data:  57%|█████▋    | 1156/2042 [00:08<00:06, 140.00it/s]Padding data:  57%|█████▋    | 1171/2042 [00:08<00:06, 142.00it/s]Padding data:  58%|█████▊    | 1186/2042 [00:08<00:06, 139.61it/s]Padding data:  59%|█████▉    | 1200/2042 [00:08<00:06, 139.23it/s]Padding data:  60%|█████▉    | 1215/2042 [00:08<00:05, 139.73it/s]Padding data:  60%|██████    | 1230/2042 [00:09<00:05, 141.10it/s]Padding data:  61%|██████    | 1245/2042 [00:09<00:05, 140.45it/s]Padding data:  62%|██████▏   | 1260/2042 [00:09<00:05, 141.21it/s]Padding data:  62%|██████▏   | 1275/2042 [00:09<00:05, 142.55it/s]Padding data:  63%|██████▎   | 1290/2042 [00:09<00:05, 142.79it/s]Padding data:  64%|██████▍   | 1305/2042 [00:09<00:05, 143.04it/s]Padding data:  65%|██████▍   | 1320/2042 [00:09<00:05, 143.20it/s]Padding data:  65%|██████▌   | 1335/2042 [00:09<00:05, 141.00it/s]Padding data:  66%|██████▌   | 1351/2042 [00:09<00:04, 143.93it/s]Padding data:  67%|██████▋   | 1366/2042 [00:09<00:04, 142.96it/s]Padding data:  68%|██████▊   | 1381/2042 [00:10<00:04, 143.27it/s]Padding data:  68%|██████▊   | 1396/2042 [00:10<00:04, 144.07it/s]Padding data:  69%|██████▉   | 1411/2042 [00:10<00:04, 143.96it/s]Padding data:  70%|██████▉   | 1426/2042 [00:10<00:04, 142.21it/s]Padding data:  71%|███████   | 1441/2042 [00:10<00:04, 142.82it/s]Padding data:  71%|███████▏  | 1456/2042 [00:10<00:04, 139.88it/s]Padding data:  72%|███████▏  | 1471/2042 [00:10<00:04, 136.12it/s]Padding data:  73%|███████▎  | 1485/2042 [00:10<00:04, 136.34it/s]Padding data:  73%|███████▎  | 1500/2042 [00:10<00:03, 137.40it/s]Padding data:  74%|███████▍  | 1514/2042 [00:11<00:03, 134.62it/s]Padding data:  75%|███████▍  | 1528/2042 [00:11<00:03, 132.86it/s]Padding data:  76%|███████▌  | 1543/2042 [00:11<00:03, 136.53it/s]Padding data:  76%|███████▌  | 1557/2042 [00:11<00:03, 134.01it/s]Padding data:  77%|███████▋  | 1573/2042 [00:11<00:03, 139.25it/s]Padding data:  78%|███████▊  | 1588/2042 [00:11<00:03, 141.07it/s]Padding data:  79%|███████▊  | 1603/2042 [00:11<00:03, 139.31it/s]Padding data:  79%|███████▉  | 1617/2042 [00:11<00:03, 137.77it/s]Padding data:  80%|███████▉  | 1633/2042 [00:11<00:02, 141.87it/s]Padding data:  81%|████████  | 1648/2042 [00:12<00:02, 142.93it/s]Padding data:  81%|████████▏ | 1664/2042 [00:12<00:02, 145.46it/s]Padding data:  82%|████████▏ | 1679/2042 [00:12<00:02, 145.27it/s]Padding data:  83%|████████▎ | 1694/2042 [00:12<00:02, 145.34it/s]Padding data:  84%|████████▎ | 1710/2042 [00:12<00:02, 147.38it/s]Padding data:  84%|████████▍ | 1725/2042 [00:12<00:02, 143.09it/s]Padding data:  85%|████████▌ | 1740/2042 [00:12<00:02, 137.46it/s]Padding data:  86%|████████▌ | 1755/2042 [00:12<00:02, 138.56it/s]Padding data:  87%|████████▋ | 1769/2042 [00:12<00:01, 138.39it/s]Padding data:  87%|████████▋ | 1783/2042 [00:12<00:01, 136.48it/s]Padding data:  88%|████████▊ | 1797/2042 [00:13<00:01, 134.66it/s]Padding data:  89%|████████▊ | 1811/2042 [00:13<00:01, 134.87it/s]Padding data:  89%|████████▉ | 1825/2042 [00:13<00:01, 134.65it/s]Padding data:  90%|█████████ | 1839/2042 [00:13<00:01, 133.04it/s]Padding data:  91%|█████████ | 1853/2042 [00:13<00:01, 134.53it/s]Padding data:  91%|█████████▏| 1868/2042 [00:13<00:01, 138.25it/s]Padding data:  92%|█████████▏| 1882/2042 [00:13<00:01, 136.74it/s]Padding data:  93%|█████████▎| 1897/2042 [00:13<00:01, 139.15it/s]Padding data:  94%|█████████▎| 1912/2042 [00:13<00:00, 139.81it/s]Padding data:  94%|█████████▍| 1927/2042 [00:14<00:00, 140.94it/s]Padding data:  95%|█████████▌| 1942/2042 [00:14<00:00, 142.21it/s]Padding data:  96%|█████████▌| 1957/2042 [00:14<00:00, 142.93it/s]Padding data:  97%|█████████▋| 1972/2042 [00:14<00:00, 142.80it/s]Padding data:  97%|█████████▋| 1987/2042 [00:14<00:00, 141.58it/s]Padding data:  98%|█████████▊| 2002/2042 [00:14<00:00, 138.59it/s]Padding data:  99%|█████████▊| 2016/2042 [00:14<00:00, 138.97it/s]Padding data:  99%|█████████▉| 2030/2042 [00:14<00:00, 137.45it/s]Padding data: 100%|██████████| 2042/2042 [00:14<00:00, 137.43it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 500, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 500, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 500, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 500, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 500, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 500, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 500, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 500, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 500, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 500, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 500, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 500, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 500, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 500, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 500, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 500, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 500, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 500, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 500, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 500, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 500, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 500, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 500, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 500, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 500, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 500, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 500, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 500, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 500, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 500, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 500, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 500, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 500, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 500, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 500, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 500, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 1243s - loss: 0.6245
Epoch 2/100
4382/4382 - 1205s - loss: 0.6100
Epoch 3/100
4382/4382 - 1207s - loss: 0.6050
Epoch 4/100
4382/4382 - 1209s - loss: 0.6036
Epoch 5/100
4382/4382 - 1209s - loss: 0.5948
Epoch 6/100
4382/4382 - 1210s - loss: 0.5907
Epoch 7/100
4382/4382 - 1209s - loss: 0.5846
Epoch 8/100
4382/4382 - 1209s - loss: 0.5776
Epoch 9/100
4382/4382 - 1216s - loss: 0.5739
Epoch 10/100
4382/4382 - 1211s - loss: 0.5692
Epoch 11/100
4382/4382 - 1202s - loss: 0.5631
Epoch 12/100
4382/4382 - 1206s - loss: 0.5608
Epoch 13/100
4382/4382 - 1205s - loss: 0.5536
Epoch 14/100
4382/4382 - 1201s - loss: 0.5479
Epoch 15/100
4382/4382 - 1204s - loss: 0.5447
Epoch 16/100
4382/4382 - 1201s - loss: 0.5360
Epoch 17/100
4382/4382 - 1212s - loss: 0.5333
Epoch 18/100
4382/4382 - 1214s - loss: 0.5248
Epoch 19/100
4382/4382 - 1209s - loss: 0.5189
Epoch 20/100
4382/4382 - 1209s - loss: 0.5174
Epoch 21/100
4382/4382 - 1205s - loss: 0.5072
Epoch 22/100
4382/4382 - 1211s - loss: 0.5063
Epoch 23/100
4382/4382 - 1205s - loss: 0.4950
Epoch 24/100
4382/4382 - 1210s - loss: 0.4846
Epoch 25/100
4382/4382 - 1209s - loss: 0.4813
Epoch 26/100
4382/4382 - 1215s - loss: 0.4771
Epoch 27/100
4382/4382 - 1213s - loss: 0.4711
Epoch 28/100
4382/4382 - 1215s - loss: 0.4608
Epoch 29/100
4382/4382 - 1215s - loss: 0.4615
Epoch 30/100
4382/4382 - 1213s - loss: 0.4506
Epoch 31/100
4382/4382 - 1215s - loss: 0.4417
Epoch 32/100
4382/4382 - 1213s - loss: 0.4316
Epoch 33/100
4382/4382 - 1212s - loss: 0.4262
Epoch 34/100
4382/4382 - 1211s - loss: 0.4261
Epoch 35/100
4382/4382 - 1213s - loss: 0.4161
Epoch 36/100
4382/4382 - 1211s - loss: 0.4112
Epoch 37/100
4382/4382 - 1212s - loss: 0.4101
Epoch 38/100
4382/4382 - 1213s - loss: 0.4017
Epoch 39/100
4382/4382 - 1214s - loss: 0.3924
Epoch 40/100
4382/4382 - 1212s - loss: 0.3813
Epoch 41/100
4382/4382 - 1214s - loss: 0.3830
Epoch 42/100
4382/4382 - 1213s - loss: 0.3766
Epoch 43/100
4382/4382 - 1212s - loss: 0.3771
Epoch 44/100
4382/4382 - 1213s - loss: 0.3616
Epoch 45/100
4382/4382 - 1212s - loss: 0.3661
Epoch 46/100
4382/4382 - 1215s - loss: 0.3613
Epoch 47/100
4382/4382 - 1214s - loss: 0.3517
Epoch 48/100
4382/4382 - 1214s - loss: 0.3459
Epoch 49/100
4382/4382 - 1215s - loss: 0.3410
Epoch 50/100
4382/4382 - 1215s - loss: 0.3342
Epoch 51/100
4382/4382 - 1215s - loss: 0.3361
Epoch 52/100
4382/4382 - 1215s - loss: 0.3319
Epoch 53/100
4382/4382 - 1215s - loss: 0.3243
Epoch 54/100
4382/4382 - 1216s - loss: 0.3314
Epoch 55/100
4382/4382 - 1214s - loss: 0.3197
Epoch 56/100
4382/4382 - 1212s - loss: 0.3105
Epoch 57/100
4382/4382 - 1213s - loss: 0.3131
Epoch 58/100
4382/4382 - 1213s - loss: 0.3074
Epoch 59/100
4382/4382 - 1213s - loss: 0.3037
Epoch 60/100
4382/4382 - 1212s - loss: 0.3043
Epoch 61/100
4382/4382 - 1213s - loss: 0.2979
Epoch 62/100
4382/4382 - 1213s - loss: 0.2965
Epoch 63/100
4382/4382 - 1213s - loss: 0.2925
Epoch 64/100
4382/4382 - 1212s - loss: 0.2925
Epoch 65/100
4382/4382 - 1214s - loss: 0.2955
Epoch 66/100
4382/4382 - 1212s - loss: 0.2795
Epoch 67/100
4382/4382 - 1214s - loss: 0.2760
Epoch 68/100
4382/4382 - 1215s - loss: 0.2779
Epoch 69/100
4382/4382 - 1213s - loss: 0.2729
Epoch 70/100
4382/4382 - 1213s - loss: 0.2770
Epoch 71/100
4382/4382 - 1213s - loss: 0.2713
Epoch 72/100
4382/4382 - 1213s - loss: 0.2616
Epoch 73/100
4382/4382 - 1220s - loss: 0.2620
Epoch 74/100
4382/4382 - 1210s - loss: 0.2545
Epoch 75/100
4382/4382 - 1210s - loss: 0.2550
Epoch 76/100
4382/4382 - 1214s - loss: 0.2567
Epoch 77/100
4382/4382 - 1217s - loss: 0.2524
Epoch 78/100
4382/4382 - 1217s - loss: 0.2456
Epoch 79/100
4382/4382 - 1215s - loss: 0.2418
Epoch 80/100
4382/4382 - 1216s - loss: 0.2485
Epoch 81/100
4382/4382 - 1213s - loss: 0.2354
Epoch 82/100
4382/4382 - 1216s - loss: 0.2424
Epoch 83/100
4382/4382 - 1214s - loss: 0.2300
Epoch 84/100
4382/4382 - 1218s - loss: 0.2246
Epoch 85/100
4382/4382 - 1215s - loss: 0.2226
Epoch 86/100
4382/4382 - 1216s - loss: 0.2151
Epoch 87/100
4382/4382 - 1215s - loss: 0.2209
Epoch 88/100
4382/4382 - 1215s - loss: 0.2151
Epoch 89/100
4382/4382 - 1215s - loss: 0.2156
Epoch 90/100
4382/4382 - 1212s - loss: 0.2110
Epoch 91/100
4382/4382 - 1208s - loss: 0.2031
Epoch 92/100
4382/4382 - 1213s - loss: 0.1978
Epoch 93/100
4382/4382 - 1213s - loss: 0.2003
Epoch 94/100
4382/4382 - 1215s - loss: 0.2129
Epoch 95/100
4382/4382 - 1214s - loss: 0.1878
Epoch 96/100
4382/4382 - 1214s - loss: 0.1919
Epoch 97/100
4382/4382 - 1212s - loss: 0.1927
Epoch 98/100
4382/4382 - 1214s - loss: 0.1831
Epoch 99/100
4382/4382 - 1214s - loss: 0.1840
Epoch 100/100
4382/4382 - 1215s - loss: 0.1895
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.429453812696108
Test f1_avg: 0.44257508922363437
