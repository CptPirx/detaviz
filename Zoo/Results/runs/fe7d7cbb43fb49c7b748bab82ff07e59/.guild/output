INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 13/2042 [00:00<00:15, 128.39it/s]Padding data:   1%|▏         | 26/2042 [00:00<00:16, 122.09it/s]Padding data:   2%|▏         | 39/2042 [00:00<00:17, 116.61it/s]Padding data:   2%|▏         | 51/2042 [00:00<00:17, 112.16it/s]Padding data:   3%|▎         | 63/2042 [00:00<00:17, 111.26it/s]Padding data:   4%|▎         | 75/2042 [00:00<00:17, 111.74it/s]Padding data:   4%|▍         | 88/2042 [00:00<00:16, 116.03it/s]Padding data:   5%|▍         | 100/2042 [00:00<00:16, 114.31it/s]Padding data:   6%|▌         | 113/2042 [00:00<00:16, 116.12it/s]Padding data:   6%|▌         | 125/2042 [00:01<00:17, 108.80it/s]Padding data:   7%|▋         | 136/2042 [00:01<00:18, 102.56it/s]Padding data:   7%|▋         | 147/2042 [00:01<00:19, 99.62it/s] Padding data:   8%|▊         | 158/2042 [00:01<00:19, 97.92it/s]Padding data:   8%|▊         | 169/2042 [00:01<00:18, 100.82it/s]Padding data:   9%|▉         | 181/2042 [00:01<00:17, 105.81it/s]Padding data:   9%|▉         | 192/2042 [00:01<00:17, 106.27it/s]Padding data:  10%|▉         | 204/2042 [00:01<00:16, 108.20it/s]Padding data:  11%|█         | 215/2042 [00:01<00:17, 106.07it/s]Padding data:  11%|█         | 226/2042 [00:02<00:17, 102.14it/s]Padding data:  12%|█▏        | 237/2042 [00:02<00:17, 103.18it/s]Padding data:  12%|█▏        | 248/2042 [00:02<00:17, 103.11it/s]Padding data:  13%|█▎        | 259/2042 [00:02<00:17, 104.35it/s]Padding data:  13%|█▎        | 272/2042 [00:02<00:16, 109.38it/s]Padding data:  14%|█▍        | 285/2042 [00:02<00:15, 114.09it/s]Padding data:  15%|█▍        | 299/2042 [00:02<00:14, 119.41it/s]Padding data:  15%|█▌        | 313/2042 [00:02<00:14, 122.83it/s]Padding data:  16%|█▌        | 327/2042 [00:02<00:13, 125.67it/s]Padding data:  17%|█▋        | 340/2042 [00:03<00:13, 124.75it/s]Padding data:  17%|█▋        | 353/2042 [00:03<00:13, 121.97it/s]Padding data:  18%|█▊        | 366/2042 [00:03<00:14, 116.25it/s]Padding data:  19%|█▊        | 378/2042 [00:03<00:14, 112.49it/s]Padding data:  19%|█▉        | 390/2042 [00:03<00:14, 113.41it/s]Padding data:  20%|█▉        | 403/2042 [00:03<00:13, 117.60it/s]Padding data:  20%|██        | 415/2042 [00:03<00:14, 114.11it/s]Padding data:  21%|██        | 427/2042 [00:03<00:15, 105.19it/s]Padding data:  21%|██▏       | 438/2042 [00:03<00:15, 101.79it/s]Padding data:  22%|██▏       | 450/2042 [00:04<00:14, 106.45it/s]Padding data:  23%|██▎       | 461/2042 [00:04<00:15, 103.10it/s]Padding data:  23%|██▎       | 474/2042 [00:04<00:14, 108.05it/s]Padding data:  24%|██▍       | 486/2042 [00:04<00:14, 110.75it/s]Padding data:  24%|██▍       | 499/2042 [00:04<00:13, 113.04it/s]Padding data:  25%|██▌       | 511/2042 [00:04<00:13, 110.44it/s]Padding data:  26%|██▌       | 523/2042 [00:04<00:14, 105.64it/s]Padding data:  26%|██▌       | 534/2042 [00:04<00:14, 106.43it/s]Padding data:  27%|██▋       | 547/2042 [00:04<00:13, 112.58it/s]Padding data:  27%|██▋       | 561/2042 [00:05<00:12, 117.57it/s]Padding data:  28%|██▊       | 573/2042 [00:05<00:12, 116.71it/s]Padding data:  29%|██▊       | 585/2042 [00:05<00:12, 116.21it/s]Padding data:  29%|██▉       | 597/2042 [00:05<00:12, 111.18it/s]Padding data:  30%|██▉       | 609/2042 [00:05<00:14, 101.25it/s]Padding data:  30%|███       | 620/2042 [00:05<00:14, 99.59it/s] Padding data:  31%|███       | 631/2042 [00:05<00:14, 97.67it/s]Padding data:  31%|███▏      | 641/2042 [00:05<00:15, 93.33it/s]Padding data:  32%|███▏      | 652/2042 [00:05<00:14, 95.32it/s]Padding data:  32%|███▏      | 662/2042 [00:06<00:14, 92.81it/s]Padding data:  33%|███▎      | 674/2042 [00:06<00:13, 99.76it/s]Padding data:  34%|███▎      | 685/2042 [00:06<00:13, 100.29it/s]Padding data:  34%|███▍      | 696/2042 [00:06<00:14, 95.78it/s] Padding data:  35%|███▍      | 706/2042 [00:06<00:13, 96.42it/s]Padding data:  35%|███▌      | 716/2042 [00:06<00:14, 92.72it/s]Padding data:  36%|███▌      | 726/2042 [00:06<00:14, 92.33it/s]Padding data:  36%|███▌      | 736/2042 [00:06<00:13, 93.67it/s]Padding data:  37%|███▋      | 747/2042 [00:06<00:13, 96.98it/s]Padding data:  37%|███▋      | 758/2042 [00:07<00:12, 98.87it/s]Padding data:  38%|███▊      | 769/2042 [00:07<00:12, 101.32it/s]Padding data:  38%|███▊      | 780/2042 [00:07<00:12, 102.12it/s]Padding data:  39%|███▉      | 793/2042 [00:07<00:11, 108.99it/s]Padding data:  40%|███▉      | 807/2042 [00:07<00:10, 116.06it/s]Padding data:  40%|████      | 820/2042 [00:07<00:10, 119.28it/s]Padding data:  41%|████      | 833/2042 [00:07<00:09, 122.22it/s]Padding data:  41%|████▏     | 846/2042 [00:07<00:10, 119.32it/s]Padding data:  42%|████▏     | 859/2042 [00:07<00:09, 120.59it/s]Padding data:  43%|████▎     | 872/2042 [00:08<00:09, 121.18it/s]Padding data:  43%|████▎     | 885/2042 [00:08<00:09, 123.05it/s]Padding data:  44%|████▍     | 898/2042 [00:08<00:09, 123.88it/s]Padding data:  45%|████▍     | 911/2042 [00:08<00:09, 125.26it/s]Padding data:  45%|████▌     | 924/2042 [00:08<00:08, 125.96it/s]Padding data:  46%|████▌     | 937/2042 [00:08<00:08, 123.57it/s]Padding data:  47%|████▋     | 951/2042 [00:08<00:08, 127.19it/s]Padding data:  47%|████▋     | 964/2042 [00:08<00:08, 126.06it/s]Padding data:  48%|████▊     | 978/2042 [00:08<00:08, 127.40it/s]Padding data:  49%|████▊     | 992/2042 [00:08<00:08, 130.02it/s]Padding data:  49%|████▉     | 1006/2042 [00:09<00:07, 130.30it/s]Padding data:  50%|████▉     | 1020/2042 [00:09<00:07, 129.12it/s]Padding data:  51%|█████     | 1033/2042 [00:09<00:08, 125.14it/s]Padding data:  51%|█████     | 1046/2042 [00:09<00:08, 124.07it/s]Padding data:  52%|█████▏    | 1059/2042 [00:09<00:08, 121.23it/s]Padding data:  52%|█████▏    | 1072/2042 [00:09<00:08, 118.38it/s]Padding data:  53%|█████▎    | 1086/2042 [00:09<00:07, 123.77it/s]Padding data:  54%|█████▍    | 1099/2042 [00:09<00:07, 124.08it/s]Padding data:  55%|█████▍    | 1113/2042 [00:09<00:07, 127.57it/s]Padding data:  55%|█████▌    | 1126/2042 [00:10<00:07, 126.04it/s]Padding data:  56%|█████▌    | 1139/2042 [00:10<00:07, 127.08it/s]Padding data:  56%|█████▋    | 1153/2042 [00:10<00:06, 129.42it/s]Padding data:  57%|█████▋    | 1167/2042 [00:10<00:06, 131.18it/s]Padding data:  58%|█████▊    | 1181/2042 [00:10<00:06, 131.94it/s]Padding data:  59%|█████▊    | 1195/2042 [00:10<00:06, 128.83it/s]Padding data:  59%|█████▉    | 1208/2042 [00:10<00:06, 128.47it/s]Padding data:  60%|█████▉    | 1221/2042 [00:10<00:06, 128.17it/s]Padding data:  60%|██████    | 1235/2042 [00:10<00:06, 128.56it/s]Padding data:  61%|██████    | 1249/2042 [00:10<00:06, 130.11it/s]Padding data:  62%|██████▏   | 1263/2042 [00:11<00:05, 130.34it/s]Padding data:  63%|██████▎   | 1277/2042 [00:11<00:05, 131.10it/s]Padding data:  63%|██████▎   | 1291/2042 [00:11<00:05, 130.73it/s]Padding data:  64%|██████▍   | 1305/2042 [00:11<00:05, 132.16it/s]Padding data:  65%|██████▍   | 1319/2042 [00:11<00:05, 132.05it/s]Padding data:  65%|██████▌   | 1333/2042 [00:11<00:05, 131.09it/s]Padding data:  66%|██████▌   | 1347/2042 [00:11<00:05, 132.22it/s]Padding data:  67%|██████▋   | 1362/2042 [00:11<00:04, 136.08it/s]Padding data:  67%|██████▋   | 1376/2042 [00:11<00:05, 131.26it/s]Padding data:  68%|██████▊   | 1391/2042 [00:12<00:04, 133.86it/s]Padding data:  69%|██████▉   | 1405/2042 [00:12<00:04, 131.10it/s]Padding data:  69%|██████▉   | 1419/2042 [00:12<00:04, 129.55it/s]Padding data:  70%|███████   | 1432/2042 [00:12<00:04, 126.44it/s]Padding data:  71%|███████   | 1447/2042 [00:12<00:04, 130.05it/s]Padding data:  72%|███████▏  | 1461/2042 [00:12<00:04, 127.41it/s]Padding data:  72%|███████▏  | 1474/2042 [00:12<00:04, 126.96it/s]Padding data:  73%|███████▎  | 1487/2042 [00:12<00:04, 123.23it/s]Padding data:  73%|███████▎  | 1500/2042 [00:12<00:04, 124.46it/s]Padding data:  74%|███████▍  | 1513/2042 [00:13<00:04, 122.36it/s]Padding data:  75%|███████▍  | 1526/2042 [00:13<00:04, 120.71it/s]Padding data:  75%|███████▌  | 1541/2042 [00:13<00:03, 126.66it/s]Padding data:  76%|███████▌  | 1554/2042 [00:13<00:03, 125.06it/s]Padding data:  77%|███████▋  | 1569/2042 [00:13<00:03, 129.03it/s]Padding data:  77%|███████▋  | 1582/2042 [00:13<00:03, 127.06it/s]Padding data:  78%|███████▊  | 1596/2042 [00:13<00:03, 129.06it/s]Padding data:  79%|███████▉  | 1609/2042 [00:13<00:03, 127.32it/s]Padding data:  79%|███████▉  | 1622/2042 [00:13<00:03, 118.73it/s]Padding data:  80%|████████  | 1634/2042 [00:14<00:03, 116.72it/s]Padding data:  81%|████████  | 1646/2042 [00:14<00:03, 117.22it/s]Padding data:  81%|████████▏ | 1661/2042 [00:14<00:03, 124.00it/s]Padding data:  82%|████████▏ | 1675/2042 [00:14<00:02, 126.38it/s]Padding data:  83%|████████▎ | 1688/2042 [00:14<00:02, 127.41it/s]Padding data:  83%|████████▎ | 1701/2042 [00:14<00:02, 127.31it/s]Padding data:  84%|████████▍ | 1714/2042 [00:14<00:02, 127.60it/s]Padding data:  85%|████████▍ | 1727/2042 [00:14<00:02, 124.99it/s]Padding data:  85%|████████▌ | 1740/2042 [00:14<00:02, 121.34it/s]Padding data:  86%|████████▌ | 1753/2042 [00:14<00:02, 123.15it/s]Padding data:  86%|████████▋ | 1766/2042 [00:15<00:02, 122.20it/s]Padding data:  87%|████████▋ | 1779/2042 [00:15<00:02, 122.60it/s]Padding data:  88%|████████▊ | 1792/2042 [00:15<00:02, 121.89it/s]Padding data:  88%|████████▊ | 1805/2042 [00:15<00:02, 116.48it/s]Padding data:  89%|████████▉ | 1817/2042 [00:15<00:02, 110.63it/s]Padding data:  90%|████████▉ | 1829/2042 [00:15<00:01, 107.35it/s]Padding data:  90%|█████████ | 1841/2042 [00:15<00:01, 108.29it/s]Padding data:  91%|█████████ | 1855/2042 [00:15<00:01, 115.36it/s]Padding data:  92%|█████████▏| 1870/2042 [00:15<00:01, 122.90it/s]Padding data:  92%|█████████▏| 1883/2042 [00:16<00:01, 121.74it/s]Padding data:  93%|█████████▎| 1897/2042 [00:16<00:01, 124.92it/s]Padding data:  94%|█████████▎| 1911/2042 [00:16<00:01, 127.80it/s]Padding data:  94%|█████████▍| 1925/2042 [00:16<00:00, 130.02it/s]Padding data:  95%|█████████▍| 1939/2042 [00:16<00:00, 130.24it/s]Padding data:  96%|█████████▌| 1953/2042 [00:16<00:00, 131.90it/s]Padding data:  96%|█████████▋| 1967/2042 [00:16<00:00, 132.45it/s]Padding data:  97%|█████████▋| 1981/2042 [00:16<00:00, 127.02it/s]Padding data:  98%|█████████▊| 1994/2042 [00:16<00:00, 125.09it/s]Padding data:  98%|█████████▊| 2007/2042 [00:17<00:00, 119.12it/s]Padding data:  99%|█████████▉| 2021/2042 [00:17<00:00, 123.64it/s]Padding data: 100%|█████████▉| 2035/2042 [00:17<00:00, 125.17it/s]Padding data: 100%|██████████| 2042/2042 [00:17<00:00, 117.72it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 200, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 200, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 200, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 200, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 200, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 200, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 200, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 200, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 200, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 200, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 200, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 200, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 200, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 200, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 200, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 200, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 200, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 200, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 200, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 200, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 200, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 200, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 200, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 200, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 200, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 200, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 200, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 200, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 200, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 200, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 200, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 200, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 200, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 200, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 200, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4383/4383 - 448s - loss: 0.6307
Epoch 2/100
4383/4383 - 415s - loss: 0.6215
Epoch 3/100
4383/4383 - 414s - loss: 0.6121
Epoch 4/100
4383/4383 - 417s - loss: 0.6077
Epoch 5/100
4383/4383 - 415s - loss: 0.6034
Epoch 6/100
4383/4383 - 411s - loss: 0.6006
Epoch 7/100
4383/4383 - 400s - loss: 0.5955
Epoch 8/100
4383/4383 - 398s - loss: 0.5884
Epoch 9/100
4383/4383 - 402s - loss: 0.5860
Epoch 10/100
4383/4383 - 402s - loss: 0.5788
Epoch 11/100
4383/4383 - 399s - loss: 0.5746
Epoch 12/100
4383/4383 - 398s - loss: 0.5657
Epoch 13/100
4383/4383 - 405s - loss: 0.5587
Epoch 14/100
4383/4383 - 407s - loss: 0.5545
Epoch 15/100
4383/4383 - 398s - loss: 0.5496
Epoch 16/100
4383/4383 - 390s - loss: 0.5411
Epoch 17/100
4383/4383 - 397s - loss: 0.5375
Epoch 18/100
4383/4383 - 400s - loss: 0.5297
Epoch 19/100
4383/4383 - 397s - loss: 0.5270
Epoch 20/100
4383/4383 - 393s - loss: 0.5195
Epoch 21/100
4383/4383 - 393s - loss: 0.5182
Epoch 22/100
4383/4383 - 396s - loss: 0.5096
Epoch 23/100
4383/4383 - 396s - loss: 0.5031
Epoch 24/100
4383/4383 - 394s - loss: 0.4978
Epoch 25/100
4383/4383 - 402s - loss: 0.4915
Epoch 26/100
4383/4383 - 395s - loss: 0.4886
Epoch 27/100
4383/4383 - 399s - loss: 0.4811
Epoch 28/100
4383/4383 - 399s - loss: 0.4760
Epoch 29/100
4383/4383 - 403s - loss: 0.4696
Epoch 30/100
4383/4383 - 401s - loss: 0.4629
Epoch 31/100
4383/4383 - 397s - loss: 0.4603
Epoch 32/100
4383/4383 - 396s - loss: 0.4546
Epoch 33/100
4383/4383 - 398s - loss: 0.4466
Epoch 34/100
4383/4383 - 403s - loss: 0.4423
Epoch 35/100
4383/4383 - 404s - loss: 0.4338
Epoch 36/100
4383/4383 - 390s - loss: 0.4269
Epoch 37/100
4383/4383 - 392s - loss: 0.4232
Epoch 38/100
4383/4383 - 400s - loss: 0.4170
Epoch 39/100
4383/4383 - 401s - loss: 0.4111
Epoch 40/100
4383/4383 - 401s - loss: 0.4058
Epoch 41/100
4383/4383 - 400s - loss: 0.3962
Epoch 42/100
4383/4383 - 404s - loss: 0.3935
Epoch 43/100
4383/4383 - 401s - loss: 0.3837
Epoch 44/100
4383/4383 - 404s - loss: 0.3758
Epoch 45/100
4383/4383 - 407s - loss: 0.3772
Epoch 46/100
4383/4383 - 406s - loss: 0.3710
Epoch 47/100
4383/4383 - 407s - loss: 0.3606
Epoch 48/100
4383/4383 - 404s - loss: 0.3615
Epoch 49/100
4383/4383 - 407s - loss: 0.3549
Epoch 50/100
4383/4383 - 408s - loss: 0.3464
Epoch 51/100
4383/4383 - 404s - loss: 0.3466
Epoch 52/100
4383/4383 - 404s - loss: 0.3436
Epoch 53/100
4383/4383 - 408s - loss: 0.3346
Epoch 54/100
4383/4383 - 406s - loss: 0.3261
Epoch 55/100
4383/4383 - 407s - loss: 0.3298
Epoch 56/100
4383/4383 - 407s - loss: 0.3257
Epoch 57/100
4383/4383 - 404s - loss: 0.3104
Epoch 58/100
4383/4383 - 407s - loss: 0.3140
Epoch 59/100
4383/4383 - 404s - loss: 0.3055
Epoch 60/100
4383/4383 - 408s - loss: 0.3085
Epoch 61/100
4383/4383 - 401s - loss: 0.2989
Epoch 62/100
4383/4383 - 403s - loss: 0.2964
Epoch 63/100
4383/4383 - 405s - loss: 0.2920
Epoch 64/100
4383/4383 - 403s - loss: 0.2889
Epoch 65/100
4383/4383 - 404s - loss: 0.2802
Epoch 66/100
4383/4383 - 400s - loss: 0.2849
Epoch 67/100
4383/4383 - 396s - loss: 0.2752
Epoch 68/100
4383/4383 - 406s - loss: 0.2729
Epoch 69/100
4383/4383 - 401s - loss: 0.2727
Epoch 70/100
4383/4383 - 396s - loss: 0.2738
Epoch 71/100
4383/4383 - 406s - loss: 0.2694
Epoch 72/100
4383/4383 - 405s - loss: 0.2720
Epoch 73/100
4383/4383 - 402s - loss: 0.2619
Epoch 74/100
4383/4383 - 403s - loss: 0.2661
Epoch 75/100
4383/4383 - 404s - loss: 0.2584
Epoch 76/100
4383/4383 - 404s - loss: 0.2667
Epoch 77/100
4383/4383 - 399s - loss: 0.2502
Epoch 78/100
4383/4383 - 397s - loss: 0.2555
Epoch 79/100
4383/4383 - 393s - loss: 0.2495
Epoch 80/100
4383/4383 - 395s - loss: 0.2451
Epoch 81/100
4383/4383 - 399s - loss: 0.2421
Epoch 82/100
4383/4383 - 399s - loss: 0.2520
Epoch 83/100
4383/4383 - 396s - loss: 0.2424
Epoch 84/100
4383/4383 - 400s - loss: 0.2450
Epoch 85/100
4383/4383 - 405s - loss: 0.2407
Epoch 86/100
4383/4383 - 398s - loss: 0.2389
Epoch 87/100
4383/4383 - 404s - loss: 0.2374
Epoch 88/100
4383/4383 - 401s - loss: 0.2436
Epoch 89/100
4383/4383 - 407s - loss: 0.2376
Epoch 90/100
4383/4383 - 407s - loss: 0.2322
Epoch 91/100
4383/4383 - 408s - loss: 0.2314
Epoch 92/100
4383/4383 - 413s - loss: 0.2355
Epoch 93/100
4383/4383 - 410s - loss: 0.2303
Epoch 94/100
4383/4383 - 409s - loss: 0.2297
Epoch 95/100
4383/4383 - 404s - loss: 0.2282
Epoch 96/100
4383/4383 - 400s - loss: 0.2257
Epoch 97/100
4383/4383 - 405s - loss: 0.2250
Epoch 98/100
4383/4383 - 404s - loss: 0.2227
Epoch 99/100
4383/4383 - 408s - loss: 0.2220
Epoch 100/100
4383/4383 - 409s - loss: 0.2145
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.5099955512664653
Test f1_avg: 0.5085260865233749
