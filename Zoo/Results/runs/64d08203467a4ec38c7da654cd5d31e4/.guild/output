INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 12/2042 [00:00<00:17, 114.94it/s]Padding data:   1%|          | 24/2042 [00:00<00:19, 101.21it/s]Padding data:   2%|▏         | 35/2042 [00:00<00:20, 98.42it/s] Padding data:   2%|▏         | 45/2042 [00:00<00:21, 91.47it/s]Padding data:   3%|▎         | 55/2042 [00:00<00:23, 84.65it/s]Padding data:   3%|▎         | 65/2042 [00:00<00:22, 88.02it/s]Padding data:   4%|▎         | 76/2042 [00:00<00:21, 92.57it/s]Padding data:   4%|▍         | 88/2042 [00:00<00:19, 99.69it/s]Padding data:   5%|▍         | 99/2042 [00:01<00:19, 97.94it/s]Padding data:   5%|▌         | 111/2042 [00:01<00:18, 102.12it/s]Padding data:   6%|▌         | 122/2042 [00:01<00:19, 99.48it/s] Padding data:   7%|▋         | 133/2042 [00:01<00:19, 99.48it/s]Padding data:   7%|▋         | 143/2042 [00:01<00:19, 99.36it/s]Padding data:   7%|▋         | 153/2042 [00:01<00:19, 94.78it/s]Padding data:   8%|▊         | 163/2042 [00:01<00:20, 92.42it/s]Padding data:   8%|▊         | 173/2042 [00:01<00:19, 93.75it/s]Padding data:   9%|▉         | 184/2042 [00:01<00:19, 96.38it/s]Padding data:  10%|▉         | 195/2042 [00:02<00:18, 98.91it/s]Padding data:  10%|█         | 206/2042 [00:02<00:18, 101.73it/s]Padding data:  11%|█         | 217/2042 [00:02<00:17, 101.53it/s]Padding data:  11%|█         | 228/2042 [00:02<00:17, 102.60it/s]Padding data:  12%|█▏        | 241/2042 [00:02<00:16, 109.07it/s]Padding data:  12%|█▏        | 253/2042 [00:02<00:16, 111.49it/s]Padding data:  13%|█▎        | 266/2042 [00:02<00:15, 114.56it/s]Padding data:  14%|█▎        | 278/2042 [00:02<00:15, 115.35it/s]Padding data:  14%|█▍        | 291/2042 [00:02<00:14, 118.43it/s]Padding data:  15%|█▍        | 304/2042 [00:02<00:14, 119.10it/s]Padding data:  16%|█▌        | 318/2042 [00:03<00:14, 122.29it/s]Padding data:  16%|█▌        | 331/2042 [00:03<00:13, 122.35it/s]Padding data:  17%|█▋        | 344/2042 [00:03<00:14, 118.98it/s]Padding data:  17%|█▋        | 357/2042 [00:03<00:14, 119.56it/s]Padding data:  18%|█▊        | 369/2042 [00:03<00:14, 118.20it/s]Padding data:  19%|█▊        | 381/2042 [00:03<00:14, 113.64it/s]Padding data:  19%|█▉        | 393/2042 [00:03<00:15, 105.18it/s]Padding data:  20%|█▉        | 404/2042 [00:03<00:16, 101.54it/s]Padding data:  20%|██        | 416/2042 [00:03<00:15, 104.48it/s]Padding data:  21%|██        | 427/2042 [00:04<00:15, 102.70it/s]Padding data:  21%|██▏       | 438/2042 [00:04<00:15, 102.44it/s]Padding data:  22%|██▏       | 450/2042 [00:04<00:15, 105.03it/s]Padding data:  23%|██▎       | 461/2042 [00:04<00:15, 101.90it/s]Padding data:  23%|██▎       | 473/2042 [00:04<00:14, 105.43it/s]Padding data:  24%|██▍       | 485/2042 [00:04<00:14, 108.20it/s]Padding data:  24%|██▍       | 497/2042 [00:04<00:14, 110.23it/s]Padding data:  25%|██▍       | 509/2042 [00:04<00:13, 111.03it/s]Padding data:  26%|██▌       | 521/2042 [00:04<00:13, 109.74it/s]Padding data:  26%|██▌       | 533/2042 [00:05<00:13, 111.81it/s]Padding data:  27%|██▋       | 545/2042 [00:05<00:13, 113.43it/s]Padding data:  27%|██▋       | 557/2042 [00:05<00:13, 112.81it/s]Padding data:  28%|██▊       | 569/2042 [00:05<00:13, 111.31it/s]Padding data:  28%|██▊       | 581/2042 [00:05<00:13, 106.86it/s]Padding data:  29%|██▉       | 593/2042 [00:05<00:13, 109.83it/s]Padding data:  30%|██▉       | 605/2042 [00:05<00:13, 105.47it/s]Padding data:  30%|███       | 616/2042 [00:05<00:13, 106.53it/s]Padding data:  31%|███       | 627/2042 [00:05<00:14, 100.84it/s]Padding data:  31%|███       | 638/2042 [00:06<00:13, 101.14it/s]Padding data:  32%|███▏      | 650/2042 [00:06<00:13, 105.58it/s]Padding data:  32%|███▏      | 661/2042 [00:06<00:13, 104.41it/s]Padding data:  33%|███▎      | 672/2042 [00:06<00:13, 104.48it/s]Padding data:  33%|███▎      | 684/2042 [00:06<00:12, 108.71it/s]Padding data:  34%|███▍      | 695/2042 [00:06<00:13, 103.32it/s]Padding data:  35%|███▍      | 707/2042 [00:06<00:12, 105.02it/s]Padding data:  35%|███▌      | 718/2042 [00:06<00:13, 101.75it/s]Padding data:  36%|███▌      | 729/2042 [00:06<00:12, 102.71it/s]Padding data:  36%|███▌      | 740/2042 [00:07<00:12, 104.05it/s]Padding data:  37%|███▋      | 752/2042 [00:07<00:11, 107.96it/s]Padding data:  37%|███▋      | 763/2042 [00:07<00:11, 107.70it/s]Padding data:  38%|███▊      | 775/2042 [00:07<00:11, 110.01it/s]Padding data:  39%|███▊      | 787/2042 [00:07<00:11, 107.71it/s]Padding data:  39%|███▉      | 799/2042 [00:07<00:11, 108.49it/s]Padding data:  40%|███▉      | 810/2042 [00:07<00:11, 104.44it/s]Padding data:  40%|████      | 822/2042 [00:07<00:11, 106.78it/s]Padding data:  41%|████      | 834/2042 [00:07<00:11, 109.08it/s]Padding data:  41%|████▏     | 845/2042 [00:07<00:11, 108.24it/s]Padding data:  42%|████▏     | 857/2042 [00:08<00:10, 109.27it/s]Padding data:  43%|████▎     | 868/2042 [00:08<00:11, 105.19it/s]Padding data:  43%|████▎     | 879/2042 [00:08<00:11, 100.09it/s]Padding data:  44%|████▎     | 890/2042 [00:08<00:11, 97.35it/s] Padding data:  44%|████▍     | 901/2042 [00:08<00:11, 99.65it/s]Padding data:  45%|████▍     | 912/2042 [00:08<00:11, 96.92it/s]Padding data:  45%|████▌     | 923/2042 [00:08<00:11, 100.08it/s]Padding data:  46%|████▌     | 934/2042 [00:08<00:11, 99.14it/s] Padding data:  46%|████▋     | 945/2042 [00:09<00:10, 100.31it/s]Padding data:  47%|████▋     | 958/2042 [00:09<00:10, 106.33it/s]Padding data:  48%|████▊     | 970/2042 [00:09<00:09, 109.78it/s]Padding data:  48%|████▊     | 983/2042 [00:09<00:09, 112.38it/s]Padding data:  49%|████▊     | 995/2042 [00:09<00:09, 114.42it/s]Padding data:  49%|████▉     | 1007/2042 [00:09<00:09, 114.41it/s]Padding data:  50%|████▉     | 1020/2042 [00:09<00:08, 116.33it/s]Padding data:  51%|█████     | 1032/2042 [00:09<00:08, 114.21it/s]Padding data:  51%|█████     | 1044/2042 [00:09<00:08, 113.73it/s]Padding data:  52%|█████▏    | 1056/2042 [00:09<00:08, 111.95it/s]Padding data:  52%|█████▏    | 1068/2042 [00:10<00:09, 107.81it/s]Padding data:  53%|█████▎    | 1080/2042 [00:10<00:08, 111.12it/s]Padding data:  54%|█████▎    | 1093/2042 [00:10<00:08, 114.12it/s]Padding data:  54%|█████▍    | 1105/2042 [00:10<00:08, 114.65it/s]Padding data:  55%|█████▍    | 1118/2042 [00:10<00:07, 116.53it/s]Padding data:  55%|█████▌    | 1130/2042 [00:10<00:07, 117.43it/s]Padding data:  56%|█████▌    | 1143/2042 [00:10<00:07, 119.16it/s]Padding data:  57%|█████▋    | 1156/2042 [00:10<00:07, 119.55it/s]Padding data:  57%|█████▋    | 1168/2042 [00:10<00:07, 118.85it/s]Padding data:  58%|█████▊    | 1181/2042 [00:11<00:07, 119.75it/s]Padding data:  58%|█████▊    | 1193/2042 [00:11<00:07, 118.36it/s]Padding data:  59%|█████▉    | 1206/2042 [00:11<00:06, 120.60it/s]Padding data:  60%|█████▉    | 1219/2042 [00:11<00:06, 118.10it/s]Padding data:  60%|██████    | 1232/2042 [00:11<00:06, 118.70it/s]Padding data:  61%|██████    | 1244/2042 [00:11<00:06, 116.65it/s]Padding data:  62%|██████▏   | 1256/2042 [00:11<00:06, 116.81it/s]Padding data:  62%|██████▏   | 1268/2042 [00:11<00:06, 117.09it/s]Padding data:  63%|██████▎   | 1280/2042 [00:11<00:06, 116.69it/s]Padding data:  63%|██████▎   | 1293/2042 [00:11<00:06, 117.98it/s]Padding data:  64%|██████▍   | 1306/2042 [00:12<00:06, 119.37it/s]Padding data:  65%|██████▍   | 1318/2042 [00:12<00:06, 118.38it/s]Padding data:  65%|██████▌   | 1330/2042 [00:12<00:06, 116.10it/s]Padding data:  66%|██████▌   | 1343/2042 [00:12<00:05, 117.61it/s]Padding data:  66%|██████▋   | 1357/2042 [00:12<00:05, 122.53it/s]Padding data:  67%|██████▋   | 1370/2042 [00:12<00:05, 118.83it/s]Padding data:  68%|██████▊   | 1383/2042 [00:12<00:05, 120.91it/s]Padding data:  68%|██████▊   | 1396/2042 [00:12<00:05, 119.07it/s]Padding data:  69%|██████▉   | 1408/2042 [00:12<00:05, 117.53it/s]Padding data:  70%|██████▉   | 1420/2042 [00:13<00:05, 115.75it/s]Padding data:  70%|███████   | 1432/2042 [00:13<00:05, 115.05it/s]Padding data:  71%|███████   | 1446/2042 [00:13<00:04, 119.80it/s]Padding data:  71%|███████▏  | 1458/2042 [00:13<00:05, 116.71it/s]Padding data:  72%|███████▏  | 1470/2042 [00:13<00:04, 115.91it/s]Padding data:  73%|███████▎  | 1483/2042 [00:13<00:04, 117.87it/s]Padding data:  73%|███████▎  | 1495/2042 [00:13<00:04, 117.63it/s]Padding data:  74%|███████▍  | 1508/2042 [00:13<00:04, 118.26it/s]Padding data:  74%|███████▍  | 1520/2042 [00:13<00:04, 106.41it/s]Padding data:  75%|███████▍  | 1531/2042 [00:14<00:05, 100.02it/s]Padding data:  76%|███████▌  | 1542/2042 [00:14<00:05, 99.36it/s] Padding data:  76%|███████▌  | 1553/2042 [00:14<00:04, 98.46it/s]Padding data:  77%|███████▋  | 1563/2042 [00:14<00:04, 98.72it/s]Padding data:  77%|███████▋  | 1575/2042 [00:14<00:04, 101.71it/s]Padding data:  78%|███████▊  | 1586/2042 [00:14<00:04, 101.60it/s]Padding data:  78%|███████▊  | 1598/2042 [00:14<00:04, 105.72it/s]Padding data:  79%|███████▉  | 1609/2042 [00:14<00:04, 102.20it/s]Padding data:  79%|███████▉  | 1620/2042 [00:14<00:04, 99.17it/s] Padding data:  80%|███████▉  | 1631/2042 [00:15<00:04, 100.61it/s]Padding data:  80%|████████  | 1642/2042 [00:15<00:04, 98.49it/s] Padding data:  81%|████████  | 1653/2042 [00:15<00:03, 99.92it/s]Padding data:  82%|████████▏ | 1666/2042 [00:15<00:03, 107.17it/s]Padding data:  82%|████████▏ | 1677/2042 [00:15<00:03, 107.56it/s]Padding data:  83%|████████▎ | 1688/2042 [00:15<00:03, 106.16it/s]Padding data:  83%|████████▎ | 1699/2042 [00:15<00:03, 102.72it/s]Padding data:  84%|████████▎ | 1710/2042 [00:15<00:03, 101.40it/s]Padding data:  84%|████████▍ | 1722/2042 [00:15<00:03, 106.26it/s]Padding data:  85%|████████▍ | 1733/2042 [00:16<00:02, 104.55it/s]Padding data:  86%|████████▌ | 1746/2042 [00:16<00:02, 111.02it/s]Padding data:  86%|████████▌ | 1758/2042 [00:16<00:02, 110.18it/s]Padding data:  87%|████████▋ | 1770/2042 [00:16<00:02, 110.31it/s]Padding data:  87%|████████▋ | 1782/2042 [00:16<00:02, 107.14it/s]Padding data:  88%|████████▊ | 1793/2042 [00:16<00:02, 106.75it/s]Padding data:  88%|████████▊ | 1805/2042 [00:16<00:02, 107.89it/s]Padding data:  89%|████████▉ | 1816/2042 [00:16<00:02, 107.15it/s]Padding data:  89%|████████▉ | 1827/2042 [00:16<00:02, 106.97it/s]Padding data:  90%|█████████ | 1839/2042 [00:17<00:01, 107.84it/s]Padding data:  91%|█████████ | 1851/2042 [00:17<00:01, 108.74it/s]Padding data:  91%|█████████▏| 1864/2042 [00:17<00:01, 112.68it/s]Padding data:  92%|█████████▏| 1876/2042 [00:17<00:01, 112.06it/s]Padding data:  92%|█████████▏| 1888/2042 [00:17<00:01, 113.86it/s]Padding data:  93%|█████████▎| 1900/2042 [00:17<00:01, 112.42it/s]Padding data:  94%|█████████▎| 1912/2042 [00:17<00:01, 111.29it/s]Padding data:  94%|█████████▍| 1924/2042 [00:17<00:01, 112.94it/s]Padding data:  95%|█████████▍| 1936/2042 [00:17<00:00, 110.19it/s]Padding data:  95%|█████████▌| 1948/2042 [00:17<00:00, 111.06it/s]Padding data:  96%|█████████▌| 1960/2042 [00:18<00:00, 107.85it/s]Padding data:  97%|█████████▋| 1971/2042 [00:18<00:00, 103.35it/s]Padding data:  97%|█████████▋| 1982/2042 [00:18<00:00, 100.15it/s]Padding data:  98%|█████████▊| 1993/2042 [00:18<00:00, 100.86it/s]Padding data:  98%|█████████▊| 2004/2042 [00:18<00:00, 98.83it/s] Padding data:  99%|█████████▊| 2016/2042 [00:18<00:00, 101.98it/s]Padding data:  99%|█████████▉| 2028/2042 [00:18<00:00, 105.89it/s]Padding data: 100%|█████████▉| 2040/2042 [00:18<00:00, 107.35it/s]Padding data: 100%|██████████| 2042/2042 [00:18<00:00, 108.09it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 500, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 500, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 500, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 500, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 500, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 500, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 500, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 500, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 500, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 500, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 500, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 500, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 500, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 500, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 500, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 500, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 500, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 500, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 500, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 500, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 500, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 500, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 500, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 500, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 500, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 500, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 500, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 500, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 500, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 500, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 500, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 500, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 500, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 500, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 500, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 500, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 1242s - loss: 0.6215
Epoch 2/100
4382/4382 - 1216s - loss: 0.6065
Epoch 3/100
4382/4382 - 1218s - loss: 0.6063
Epoch 4/100
4382/4382 - 1217s - loss: 0.6015
Epoch 5/100
4382/4382 - 1221s - loss: 0.5989
Epoch 6/100
4382/4382 - 1222s - loss: 0.5924
Epoch 7/100
4382/4382 - 1215s - loss: 0.5877
Epoch 8/100
4382/4382 - 1219s - loss: 0.5817
Epoch 9/100
4382/4382 - 1221s - loss: 0.5734
Epoch 10/100
4382/4382 - 1220s - loss: 0.5690
Epoch 11/100
4382/4382 - 1220s - loss: 0.5628
Epoch 12/100
4382/4382 - 1219s - loss: 0.5587
Epoch 13/100
4382/4382 - 1220s - loss: 0.5479
Epoch 14/100
4382/4382 - 1220s - loss: 0.5402
Epoch 15/100
4382/4382 - 1220s - loss: 0.5337
Epoch 16/100
4382/4382 - 1221s - loss: 0.5211
Epoch 17/100
4382/4382 - 1220s - loss: 0.5168
Epoch 18/100
4382/4382 - 1219s - loss: 0.5075
Epoch 19/100
4382/4382 - 1218s - loss: 0.5038
Epoch 20/100
4382/4382 - 1211s - loss: 0.4953
Epoch 21/100
4382/4382 - 1211s - loss: 0.4948
Epoch 22/100
4382/4382 - 1211s - loss: 0.4880
Epoch 23/100
4382/4382 - 1212s - loss: 0.4807
Epoch 24/100
4382/4382 - 1212s - loss: 0.4704
Epoch 25/100
4382/4382 - 1213s - loss: 0.4691
Epoch 26/100
4382/4382 - 1214s - loss: 0.4584
Epoch 27/100
4382/4382 - 1216s - loss: 0.4519
Epoch 28/100
4382/4382 - 1214s - loss: 0.4472
Epoch 29/100
4382/4382 - 1212s - loss: 0.4432
Epoch 30/100
4382/4382 - 1213s - loss: 0.4383
Epoch 31/100
4382/4382 - 1215s - loss: 0.4309
Epoch 32/100
4382/4382 - 1214s - loss: 0.4227
Epoch 33/100
4382/4382 - 1213s - loss: 0.4167
Epoch 34/100
4382/4382 - 1216s - loss: 0.4099
Epoch 35/100
4382/4382 - 1222s - loss: 0.4022
Epoch 36/100
4382/4382 - 1222s - loss: 0.3966
Epoch 37/100
4382/4382 - 1221s - loss: 0.3951
Epoch 38/100
4382/4382 - 1221s - loss: 0.3937
Epoch 39/100
4382/4382 - 1220s - loss: 0.3817
Epoch 40/100
4382/4382 - 1220s - loss: 0.3841
Epoch 41/100
4382/4382 - 1221s - loss: 0.3759
Epoch 42/100
4382/4382 - 1219s - loss: 0.3717
Epoch 43/100
4382/4382 - 1221s - loss: 0.3688
Epoch 44/100
4382/4382 - 1220s - loss: 0.3630
Epoch 45/100
4382/4382 - 1221s - loss: 0.3569
Epoch 46/100
4382/4382 - 1221s - loss: 0.3565
Epoch 47/100
4382/4382 - 1219s - loss: 0.3521
Epoch 48/100
4382/4382 - 1221s - loss: 0.3448
Epoch 49/100
4382/4382 - 1221s - loss: 0.3422
Epoch 50/100
4382/4382 - 1221s - loss: 0.3363
Epoch 51/100
4382/4382 - 1221s - loss: 0.3306
Epoch 52/100
4382/4382 - 1222s - loss: 0.3343
Epoch 53/100
4382/4382 - 1218s - loss: 0.3319
Epoch 54/100
4382/4382 - 1206s - loss: 0.3300
Epoch 55/100
4382/4382 - 1206s - loss: 0.3245
Epoch 56/100
4382/4382 - 1206s - loss: 0.3198
Epoch 57/100
4382/4382 - 1205s - loss: 0.3212
Epoch 58/100
4382/4382 - 1200s - loss: 0.3103
Epoch 59/100
4382/4382 - 1198s - loss: 0.3165
Epoch 60/100
4382/4382 - 1199s - loss: 0.3198
Epoch 61/100
4382/4382 - 1199s - loss: 0.3130
Epoch 62/100
4382/4382 - 1196s - loss: 0.3078
Epoch 63/100
4382/4382 - 1195s - loss: 0.3046
Epoch 64/100
4382/4382 - 1205s - loss: 0.2985
Epoch 65/100
4382/4382 - 1203s - loss: 0.3005
Epoch 66/100
4382/4382 - 1198s - loss: 0.2971
Epoch 67/100
4382/4382 - 1199s - loss: 0.2985
Epoch 68/100
4382/4382 - 1199s - loss: 0.2901
Epoch 69/100
4382/4382 - 1200s - loss: 0.2913
Epoch 70/100
4382/4382 - 1199s - loss: 0.2878
Epoch 71/100
4382/4382 - 1200s - loss: 0.2815
Epoch 72/100
4382/4382 - 1199s - loss: 0.2796
Epoch 73/100
4382/4382 - 1199s - loss: 0.2806
Epoch 74/100
4382/4382 - 1200s - loss: 0.2722
Epoch 75/100
4382/4382 - 1200s - loss: 0.2759
Epoch 76/100
4382/4382 - 1200s - loss: 0.2698
Epoch 77/100
4382/4382 - 1200s - loss: 0.2648
Epoch 78/100
4382/4382 - 1203s - loss: 0.2592
Epoch 79/100
4382/4382 - 1201s - loss: 0.2621
Epoch 80/100
4382/4382 - 1200s - loss: 0.2664
Epoch 81/100
4382/4382 - 1200s - loss: 0.2545
Epoch 82/100
4382/4382 - 1200s - loss: 0.2639
Epoch 83/100
4382/4382 - 1200s - loss: 0.2548
Epoch 84/100
4382/4382 - 1200s - loss: 0.2568
Epoch 85/100
4382/4382 - 1200s - loss: 0.2441
Epoch 86/100
4382/4382 - 1200s - loss: 0.2561
Epoch 87/100
4382/4382 - 1197s - loss: 0.2358
Epoch 88/100
4382/4382 - 1199s - loss: 0.2397
Epoch 89/100
4382/4382 - 1198s - loss: 0.2499
Epoch 90/100
4382/4382 - 1195s - loss: 0.2318
Epoch 91/100
4382/4382 - 1197s - loss: 0.2375
Epoch 92/100
4382/4382 - 1198s - loss: 0.2296
Epoch 93/100
4382/4382 - 1198s - loss: 0.2303
Epoch 94/100
4382/4382 - 1197s - loss: 0.2255
Epoch 95/100
4382/4382 - 1198s - loss: 0.2247
Epoch 96/100
4382/4382 - 1198s - loss: 0.2210
Epoch 97/100
4382/4382 - 1198s - loss: 0.2153
Epoch 98/100
4382/4382 - 1198s - loss: 0.2172
Epoch 99/100
4382/4382 - 1198s - loss: 0.2126
Epoch 100/100
4382/4382 - 1201s - loss: 0.2098
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.46170750619073314
Test f1_avg: 0.4540147481047989
