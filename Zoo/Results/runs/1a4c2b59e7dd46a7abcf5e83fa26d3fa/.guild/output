INFO: [guild] Running trial 3953b00be2ed44b7a72747fff615a0bd: gpkg.anonymous-f8a06c26/ResNet:train (binarize=yes, dev=no, dimensionality=125, horizon=1, learning_rate=0.001, n_feature_maps=64, optimizer=adam, remote=yes, window=300)
INFO: [guild] Resolving file:ResNet/resnet_model.py dependency
INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 135.51it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:17, 116.22it/s]Padding data:   2%|▏         | 40/2042 [00:00<00:19, 103.49it/s]Padding data:   2%|▏         | 51/2042 [00:00<00:19, 103.85it/s]Padding data:   3%|▎         | 63/2042 [00:00<00:18, 107.40it/s]Padding data:   4%|▎         | 75/2042 [00:00<00:17, 110.00it/s]Padding data:   4%|▍         | 89/2042 [00:00<00:16, 116.72it/s]Padding data:   5%|▍         | 101/2042 [00:00<00:16, 117.45it/s]Padding data:   6%|▌         | 115/2042 [00:01<00:15, 120.88it/s]Padding data:   6%|▋         | 128/2042 [00:01<00:16, 119.55it/s]Padding data:   7%|▋         | 140/2042 [00:01<00:16, 118.76it/s]Padding data:   7%|▋         | 152/2042 [00:01<00:15, 118.33it/s]Padding data:   8%|▊         | 165/2042 [00:01<00:15, 119.23it/s]Padding data:   9%|▉         | 179/2042 [00:01<00:15, 123.55it/s]Padding data:   9%|▉         | 192/2042 [00:01<00:15, 119.76it/s]Padding data:  10%|█         | 205/2042 [00:01<00:15, 119.86it/s]Padding data:  11%|█         | 218/2042 [00:01<00:15, 119.03it/s]Padding data:  11%|█▏        | 231/2042 [00:01<00:15, 120.45it/s]Padding data:  12%|█▏        | 245/2042 [00:02<00:14, 125.23it/s]Padding data:  13%|█▎        | 259/2042 [00:02<00:13, 127.68it/s]Padding data:  13%|█▎        | 273/2042 [00:02<00:13, 131.18it/s]Padding data:  14%|█▍        | 287/2042 [00:02<00:13, 132.94it/s]Padding data:  15%|█▍        | 301/2042 [00:02<00:13, 132.99it/s]Padding data:  15%|█▌        | 316/2042 [00:02<00:12, 135.56it/s]Padding data:  16%|█▌        | 331/2042 [00:02<00:12, 137.43it/s]Padding data:  17%|█▋        | 345/2042 [00:02<00:12, 135.39it/s]Padding data:  18%|█▊        | 359/2042 [00:02<00:12, 133.15it/s]Padding data:  18%|█▊        | 373/2042 [00:03<00:12, 131.98it/s]Padding data:  19%|█▉        | 387/2042 [00:03<00:12, 129.75it/s]Padding data:  20%|█▉        | 401/2042 [00:03<00:12, 131.29it/s]Padding data:  20%|██        | 415/2042 [00:03<00:12, 133.72it/s]Padding data:  21%|██        | 429/2042 [00:03<00:12, 126.70it/s]Padding data:  22%|██▏       | 443/2042 [00:03<00:12, 128.50it/s]Padding data:  22%|██▏       | 456/2042 [00:03<00:12, 126.37it/s]Padding data:  23%|██▎       | 469/2042 [00:03<00:12, 125.80it/s]Padding data:  24%|██▎       | 483/2042 [00:03<00:12, 128.30it/s]Padding data:  24%|██▍       | 497/2042 [00:03<00:11, 129.83it/s]Padding data:  25%|██▌       | 511/2042 [00:04<00:11, 130.35it/s]Padding data:  26%|██▌       | 525/2042 [00:04<00:11, 129.42it/s]Padding data:  26%|██▋       | 539/2042 [00:04<00:11, 131.16it/s]Padding data:  27%|██▋       | 553/2042 [00:04<00:11, 133.70it/s]Padding data:  28%|██▊       | 567/2042 [00:04<00:11, 132.29it/s]Padding data:  28%|██▊       | 581/2042 [00:04<00:11, 128.11it/s]Padding data:  29%|██▉       | 594/2042 [00:04<00:11, 123.62it/s]Padding data:  30%|██▉       | 607/2042 [00:04<00:12, 114.54it/s]Padding data:  30%|███       | 620/2042 [00:04<00:12, 117.10it/s]Padding data:  31%|███       | 633/2042 [00:05<00:11, 118.24it/s]Padding data:  32%|███▏      | 647/2042 [00:05<00:11, 122.64it/s]Padding data:  32%|███▏      | 660/2042 [00:05<00:11, 124.22it/s]Padding data:  33%|███▎      | 673/2042 [00:05<00:11, 122.20it/s]Padding data:  34%|███▎      | 687/2042 [00:05<00:10, 126.64it/s]Padding data:  34%|███▍      | 700/2042 [00:05<00:10, 123.90it/s]Padding data:  35%|███▍      | 713/2042 [00:05<00:10, 125.55it/s]Padding data:  36%|███▌      | 726/2042 [00:05<00:10, 121.94it/s]Padding data:  36%|███▌      | 740/2042 [00:05<00:10, 126.14it/s]Padding data:  37%|███▋      | 754/2042 [00:06<00:09, 128.95it/s]Padding data:  38%|███▊      | 768/2042 [00:06<00:09, 131.69it/s]Padding data:  38%|███▊      | 783/2042 [00:06<00:09, 134.78it/s]Padding data:  39%|███▉      | 798/2042 [00:06<00:09, 138.05it/s]Padding data:  40%|███▉      | 813/2042 [00:06<00:08, 139.18it/s]Padding data:  40%|████      | 827/2042 [00:06<00:08, 138.60it/s]Padding data:  41%|████      | 841/2042 [00:06<00:08, 138.75it/s]Padding data:  42%|████▏     | 855/2042 [00:06<00:08, 135.58it/s]Padding data:  43%|████▎     | 869/2042 [00:06<00:08, 136.34it/s]Padding data:  43%|████▎     | 883/2042 [00:06<00:08, 136.22it/s]Padding data:  44%|████▍     | 897/2042 [00:07<00:08, 135.85it/s]Padding data:  45%|████▍     | 911/2042 [00:07<00:08, 133.84it/s]Padding data:  45%|████▌     | 926/2042 [00:07<00:08, 135.92it/s]Padding data:  46%|████▌     | 940/2042 [00:07<00:08, 134.59it/s]Padding data:  47%|████▋     | 954/2042 [00:07<00:08, 135.50it/s]Padding data:  47%|████▋     | 968/2042 [00:07<00:07, 135.02it/s]Padding data:  48%|████▊     | 982/2042 [00:07<00:07, 135.01it/s]Padding data:  49%|████▉     | 997/2042 [00:07<00:07, 137.23it/s]Padding data:  50%|████▉     | 1011/2042 [00:07<00:07, 133.74it/s]Padding data:  50%|█████     | 1025/2042 [00:08<00:07, 135.43it/s]Padding data:  51%|█████     | 1039/2042 [00:08<00:07, 129.74it/s]Padding data:  52%|█████▏    | 1053/2042 [00:08<00:07, 129.13it/s]Padding data:  52%|█████▏    | 1066/2042 [00:08<00:07, 123.35it/s]Padding data:  53%|█████▎    | 1079/2042 [00:08<00:07, 124.98it/s]Padding data:  54%|█████▎    | 1093/2042 [00:08<00:07, 128.95it/s]Padding data:  54%|█████▍    | 1108/2042 [00:08<00:07, 132.82it/s]Padding data:  55%|█████▍    | 1122/2042 [00:08<00:06, 133.12it/s]Padding data:  56%|█████▌    | 1137/2042 [00:08<00:06, 135.58it/s]Padding data:  56%|█████▋    | 1151/2042 [00:08<00:06, 136.18it/s]Padding data:  57%|█████▋    | 1166/2042 [00:09<00:06, 137.77it/s]Padding data:  58%|█████▊    | 1180/2042 [00:09<00:06, 137.98it/s]Padding data:  58%|█████▊    | 1194/2042 [00:09<00:06, 135.14it/s]Padding data:  59%|█████▉    | 1208/2042 [00:09<00:06, 135.39it/s]Padding data:  60%|█████▉    | 1222/2042 [00:09<00:06, 131.51it/s]Padding data:  61%|██████    | 1236/2042 [00:09<00:06, 131.14it/s]Padding data:  61%|██████    | 1250/2042 [00:09<00:06, 129.92it/s]Padding data:  62%|██████▏   | 1264/2042 [00:09<00:06, 129.63it/s]Padding data:  63%|██████▎   | 1277/2042 [00:09<00:06, 126.60it/s]Padding data:  63%|██████▎   | 1290/2042 [00:10<00:05, 127.55it/s]Padding data:  64%|██████▍   | 1304/2042 [00:10<00:05, 128.24it/s]Padding data:  64%|██████▍   | 1317/2042 [00:10<00:05, 128.73it/s]Padding data:  65%|██████▌   | 1331/2042 [00:10<00:05, 130.15it/s]Padding data:  66%|██████▌   | 1345/2042 [00:10<00:05, 127.28it/s]Padding data:  67%|██████▋   | 1358/2042 [00:10<00:05, 123.27it/s]Padding data:  67%|██████▋   | 1371/2042 [00:10<00:05, 117.93it/s]Padding data:  68%|██████▊   | 1384/2042 [00:10<00:05, 119.09it/s]Padding data:  68%|██████▊   | 1396/2042 [00:10<00:05, 111.50it/s]Padding data:  69%|██████▉   | 1408/2042 [00:11<00:05, 109.71it/s]Padding data:  70%|██████▉   | 1420/2042 [00:11<00:05, 107.54it/s]Padding data:  70%|███████   | 1433/2042 [00:11<00:05, 110.80it/s]Padding data:  71%|███████   | 1448/2042 [00:11<00:04, 120.24it/s]Padding data:  72%|███████▏  | 1461/2042 [00:11<00:04, 121.88it/s]Padding data:  72%|███████▏  | 1475/2042 [00:11<00:04, 126.78it/s]Padding data:  73%|███████▎  | 1489/2042 [00:11<00:04, 129.57it/s]Padding data:  74%|███████▎  | 1503/2042 [00:11<00:04, 131.77it/s]Padding data:  74%|███████▍  | 1517/2042 [00:11<00:04, 131.00it/s]Padding data:  75%|███████▍  | 1531/2042 [00:12<00:03, 131.45it/s]Padding data:  76%|███████▌  | 1546/2042 [00:12<00:03, 136.05it/s]Padding data:  76%|███████▋  | 1560/2042 [00:12<00:03, 133.23it/s]Padding data:  77%|███████▋  | 1575/2042 [00:12<00:03, 137.80it/s]Padding data:  78%|███████▊  | 1590/2042 [00:12<00:03, 140.68it/s]Padding data:  79%|███████▊  | 1605/2042 [00:12<00:03, 137.63it/s]Padding data:  79%|███████▉  | 1619/2042 [00:12<00:03, 134.74it/s]Padding data:  80%|████████  | 1634/2042 [00:12<00:02, 136.14it/s]Padding data:  81%|████████  | 1648/2042 [00:12<00:02, 136.50it/s]Padding data:  81%|████████▏ | 1663/2042 [00:12<00:02, 138.20it/s]Padding data:  82%|████████▏ | 1677/2042 [00:13<00:02, 136.39it/s]Padding data:  83%|████████▎ | 1691/2042 [00:13<00:02, 135.65it/s]Padding data:  83%|████████▎ | 1705/2042 [00:13<00:02, 126.25it/s]Padding data:  84%|████████▍ | 1718/2042 [00:13<00:02, 120.20it/s]Padding data:  85%|████████▍ | 1731/2042 [00:13<00:02, 111.93it/s]Padding data:  85%|████████▌ | 1744/2042 [00:13<00:02, 115.97it/s]Padding data:  86%|████████▌ | 1757/2042 [00:13<00:02, 119.07it/s]Padding data:  87%|████████▋ | 1771/2042 [00:13<00:02, 122.01it/s]Padding data:  87%|████████▋ | 1784/2042 [00:13<00:02, 122.60it/s]Padding data:  88%|████████▊ | 1797/2042 [00:14<00:02, 121.39it/s]Padding data:  89%|████████▊ | 1810/2042 [00:14<00:01, 122.96it/s]Padding data:  89%|████████▉ | 1824/2042 [00:14<00:01, 125.23it/s]Padding data:  90%|████████▉ | 1837/2042 [00:14<00:01, 123.73it/s]Padding data:  91%|█████████ | 1850/2042 [00:14<00:01, 124.16it/s]Padding data:  91%|█████████▏| 1864/2042 [00:14<00:01, 126.66it/s]Padding data:  92%|█████████▏| 1878/2042 [00:14<00:01, 128.06it/s]Padding data:  93%|█████████▎| 1892/2042 [00:14<00:01, 129.39it/s]Padding data:  93%|█████████▎| 1905/2042 [00:14<00:01, 128.35it/s]Padding data:  94%|█████████▍| 1919/2042 [00:15<00:00, 131.01it/s]Padding data:  95%|█████████▍| 1933/2042 [00:15<00:00, 129.43it/s]Padding data:  95%|█████████▌| 1947/2042 [00:15<00:00, 129.93it/s]Padding data:  96%|█████████▌| 1961/2042 [00:15<00:00, 132.26it/s]Padding data:  97%|█████████▋| 1975/2042 [00:15<00:00, 130.60it/s]Padding data:  97%|█████████▋| 1989/2042 [00:15<00:00, 129.74it/s]Padding data:  98%|█████████▊| 2002/2042 [00:15<00:00, 127.91it/s]Padding data:  99%|█████████▊| 2015/2042 [00:15<00:00, 122.83it/s]Padding data:  99%|█████████▉| 2028/2042 [00:15<00:00, 115.35it/s]Padding data: 100%|█████████▉| 2040/2042 [00:16<00:00, 110.25it/s]Padding data: 100%|██████████| 2042/2042 [00:16<00:00, 127.07it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 300, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 300, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 300, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 300, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 300, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 300, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 300, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 300, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 300, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 300, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 300, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 300, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 300, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 300, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 300, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 300, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 300, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 300, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 300, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 300, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 300, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 300, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 300, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 300, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 300, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 300, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 300, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 300, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 300, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 300, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 300, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 300, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 300, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 300, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 300, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 300, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 789s - loss: 0.6320
Epoch 2/100
4382/4382 - 768s - loss: 0.6149
Epoch 3/100
4382/4382 - 769s - loss: 0.6120
Epoch 4/100
4382/4382 - 770s - loss: 0.6085
Epoch 5/100
4382/4382 - 768s - loss: 0.6029
Epoch 6/100
4382/4382 - 769s - loss: 0.5965
Epoch 7/100
4382/4382 - 771s - loss: 0.5916
Epoch 8/100
4382/4382 - 763s - loss: 0.5868
Epoch 9/100
4382/4382 - 762s - loss: 0.5815
Epoch 10/100
4382/4382 - 766s - loss: 0.5770
Epoch 11/100
4382/4382 - 768s - loss: 0.5696
Epoch 12/100
4382/4382 - 768s - loss: 0.5627
Epoch 13/100
4382/4382 - 765s - loss: 0.5621
Epoch 14/100
4382/4382 - 763s - loss: 0.5552
Epoch 15/100
4382/4382 - 758s - loss: 0.5518
Epoch 16/100
4382/4382 - 748s - loss: 0.5446
Epoch 17/100
4382/4382 - 726s - loss: 0.5411
Epoch 18/100
4382/4382 - 724s - loss: 0.5352
Epoch 19/100
4382/4382 - 728s - loss: 0.5292
Epoch 20/100
4382/4382 - 729s - loss: 0.5266
Epoch 21/100
4382/4382 - 729s - loss: 0.5183
Epoch 22/100
4382/4382 - 730s - loss: 0.5128
Epoch 23/100
4382/4382 - 727s - loss: 0.5107
Epoch 24/100
4382/4382 - 728s - loss: 0.5067
Epoch 25/100
4382/4382 - 729s - loss: 0.4989
Epoch 26/100
4382/4382 - 733s - loss: 0.4934
Epoch 27/100
4382/4382 - 727s - loss: 0.4896
Epoch 28/100
4382/4382 - 726s - loss: 0.4836
Epoch 29/100
4382/4382 - 733s - loss: 0.4816
Epoch 30/100
4382/4382 - 734s - loss: 0.4744
Epoch 31/100
4382/4382 - 735s - loss: 0.4682
Epoch 32/100
4382/4382 - 734s - loss: 0.4674
Epoch 33/100
4382/4382 - 737s - loss: 0.4597
Epoch 34/100
4382/4382 - 734s - loss: 0.4553
Epoch 35/100
4382/4382 - 725s - loss: 0.4455
Epoch 36/100
4382/4382 - 731s - loss: 0.4438
Epoch 37/100
4382/4382 - 738s - loss: 0.4361
Epoch 38/100
4382/4382 - 734s - loss: 0.4340
Epoch 39/100
4382/4382 - 727s - loss: 0.4299
Epoch 40/100
4382/4382 - 725s - loss: 0.4205
Epoch 41/100
4382/4382 - 727s - loss: 0.4136
Epoch 42/100
4382/4382 - 726s - loss: 0.4152
Epoch 43/100
4382/4382 - 729s - loss: 0.4089
Epoch 44/100
4382/4382 - 728s - loss: 0.4037
Epoch 45/100
4382/4382 - 752s - loss: 0.3990
Epoch 46/100
4382/4382 - 754s - loss: 0.3914
Epoch 47/100
4382/4382 - 753s - loss: 0.3907
Epoch 48/100
4382/4382 - 752s - loss: 0.3830
Epoch 49/100
4382/4382 - 749s - loss: 0.3775
Epoch 50/100
4382/4382 - 745s - loss: 0.3712
Epoch 51/100
4382/4382 - 745s - loss: 0.3662
Epoch 52/100
4382/4382 - 746s - loss: 0.3636
Epoch 53/100
4382/4382 - 754s - loss: 0.3535
Epoch 54/100
4382/4382 - 754s - loss: 0.3520
Epoch 55/100
4382/4382 - 754s - loss: 0.3424
Epoch 56/100
4382/4382 - 759s - loss: 0.3468
Epoch 57/100
4382/4382 - 760s - loss: 0.3489
Epoch 58/100
4382/4382 - 764s - loss: 0.3437
Epoch 59/100
4382/4382 - 761s - loss: 0.3332
Epoch 60/100
4382/4382 - 760s - loss: 0.3309
Epoch 61/100
4382/4382 - 756s - loss: 0.3253
Epoch 62/100
4382/4382 - 757s - loss: 0.3255
Epoch 63/100
4382/4382 - 757s - loss: 0.3249
Epoch 64/100
4382/4382 - 763s - loss: 0.3119
Epoch 65/100
4382/4382 - 762s - loss: 0.3099
Epoch 66/100
4382/4382 - 762s - loss: 0.3180
Epoch 67/100
4382/4382 - 762s - loss: 0.2994
Epoch 68/100
4382/4382 - 762s - loss: 0.2951
Epoch 69/100
4382/4382 - 762s - loss: 0.2922
Epoch 70/100
4382/4382 - 761s - loss: 0.2959
Epoch 71/100
4382/4382 - 762s - loss: 0.2975
Epoch 72/100
4382/4382 - 763s - loss: 0.2866
Epoch 73/100
4382/4382 - 762s - loss: 0.2868
Epoch 74/100
4382/4382 - 760s - loss: 0.2862
Epoch 75/100
4382/4382 - 762s - loss: 0.2859
Epoch 76/100
4382/4382 - 761s - loss: 0.2856
Epoch 77/100
4382/4382 - 762s - loss: 0.2753
Epoch 78/100
4382/4382 - 762s - loss: 0.2791
Epoch 79/100
4382/4382 - 763s - loss: 0.2765
Epoch 80/100
4382/4382 - 767s - loss: 0.2638
Epoch 81/100
4382/4382 - 768s - loss: 0.2714
Epoch 82/100
4382/4382 - 769s - loss: 0.2721
Epoch 83/100
4382/4382 - 762s - loss: 0.2660
Epoch 84/100
4382/4382 - 761s - loss: 0.2718

Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 85/100
4382/4382 - 762s - loss: 0.2361
Epoch 86/100
4382/4382 - 761s - loss: 0.2266
Epoch 87/100
4382/4382 - 763s - loss: 0.2151
Epoch 88/100
4382/4382 - 765s - loss: 0.2152
Epoch 89/100
4382/4382 - 765s - loss: 0.2108
Epoch 90/100
4382/4382 - 766s - loss: 0.2040
Epoch 91/100
4382/4382 - 764s - loss: 0.2049
Epoch 92/100
4382/4382 - 764s - loss: 0.2002
Epoch 93/100
4382/4382 - 763s - loss: 0.1959
Epoch 94/100
4382/4382 - 766s - loss: 0.1902
Epoch 95/100
4382/4382 - 772s - loss: 0.1896
Epoch 96/100
4382/4382 - 776s - loss: 0.1862
Epoch 97/100
4382/4382 - 767s - loss: 0.1808
Epoch 98/100
4382/4382 - 769s - loss: 0.1774
Epoch 99/100
4382/4382 - 769s - loss: 0.1753
Epoch 100/100
4382/4382 - 769s - loss: 0.1752
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.5274006478065327
Test f1_avg: 0.5459441470520194
INFO: [guild] Running trial ba31e08068b84011aa6b497354f3ea31: gpkg.anonymous-f8a06c26/ResNet:train (binarize=yes, dev=no, dimensionality=125, horizon=1, learning_rate=0.001, n_feature_maps=64, optimizer=adam, remote=yes, window=400)
INFO: [guild] Resolving file:ResNet/resnet_model.py dependency
INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 14/2042 [00:00<00:14, 136.42it/s]Padding data:   1%|▏         | 28/2042 [00:00<00:15, 126.42it/s]Padding data:   2%|▏         | 41/2042 [00:00<00:16, 124.35it/s]Padding data:   3%|▎         | 54/2042 [00:00<00:16, 120.68it/s]Padding data:   3%|▎         | 67/2042 [00:00<00:16, 121.25it/s]Padding data:   4%|▍         | 80/2042 [00:00<00:16, 118.26it/s]Padding data:   5%|▍         | 93/2042 [00:00<00:16, 121.48it/s]Padding data:   5%|▌         | 106/2042 [00:00<00:15, 121.72it/s]Padding data:   6%|▌         | 119/2042 [00:00<00:15, 120.59it/s]Padding data:   6%|▋         | 132/2042 [00:01<00:16, 118.43it/s]Padding data:   7%|▋         | 145/2042 [00:01<00:15, 121.17it/s]Padding data:   8%|▊         | 158/2042 [00:01<00:15, 121.45it/s]Padding data:   8%|▊         | 171/2042 [00:01<00:15, 121.87it/s]Padding data:   9%|▉         | 184/2042 [00:01<00:15, 123.25it/s]Padding data:  10%|▉         | 197/2042 [00:01<00:15, 122.97it/s]Padding data:  10%|█         | 210/2042 [00:01<00:14, 123.18it/s]Padding data:  11%|█         | 223/2042 [00:01<00:15, 120.50it/s]Padding data:  12%|█▏        | 237/2042 [00:01<00:14, 125.24it/s]Padding data:  12%|█▏        | 251/2042 [00:02<00:13, 128.35it/s]Padding data:  13%|█▎        | 265/2042 [00:02<00:13, 131.07it/s]Padding data:  14%|█▎        | 280/2042 [00:02<00:13, 133.87it/s]Padding data:  14%|█▍        | 295/2042 [00:02<00:12, 137.57it/s]Padding data:  15%|█▌        | 310/2042 [00:02<00:12, 140.92it/s]Padding data:  16%|█▌        | 325/2042 [00:02<00:12, 140.07it/s]Padding data:  17%|█▋        | 340/2042 [00:02<00:12, 136.92it/s]Padding data:  17%|█▋        | 354/2042 [00:02<00:12, 135.39it/s]Padding data:  18%|█▊        | 368/2042 [00:02<00:12, 135.86it/s]Padding data:  19%|█▊        | 382/2042 [00:02<00:12, 134.14it/s]Padding data:  19%|█▉        | 396/2042 [00:03<00:12, 135.36it/s]Padding data:  20%|██        | 410/2042 [00:03<00:12, 135.87it/s]Padding data:  21%|██        | 424/2042 [00:03<00:12, 132.24it/s]Padding data:  21%|██▏       | 438/2042 [00:03<00:12, 130.64it/s]Padding data:  22%|██▏       | 452/2042 [00:03<00:12, 131.78it/s]Padding data:  23%|██▎       | 466/2042 [00:03<00:12, 129.85it/s]Padding data:  24%|██▎       | 481/2042 [00:03<00:11, 134.09it/s]Padding data:  24%|██▍       | 496/2042 [00:03<00:11, 136.66it/s]Padding data:  25%|██▌       | 511/2042 [00:03<00:11, 138.86it/s]Padding data:  26%|██▌       | 525/2042 [00:04<00:11, 137.54it/s]Padding data:  26%|██▋       | 539/2042 [00:04<00:11, 135.05it/s]Padding data:  27%|██▋       | 553/2042 [00:04<00:10, 135.72it/s]Padding data:  28%|██▊       | 567/2042 [00:04<00:10, 134.48it/s]Padding data:  28%|██▊       | 581/2042 [00:04<00:11, 130.82it/s]Padding data:  29%|██▉       | 595/2042 [00:04<00:10, 132.95it/s]Padding data:  30%|██▉       | 609/2042 [00:04<00:11, 127.91it/s]Padding data:  31%|███       | 623/2042 [00:04<00:11, 128.78it/s]Padding data:  31%|███       | 636/2042 [00:04<00:11, 127.00it/s]Padding data:  32%|███▏      | 650/2042 [00:05<00:10, 129.78it/s]Padding data:  33%|███▎      | 664/2042 [00:05<00:11, 125.25it/s]Padding data:  33%|███▎      | 678/2042 [00:05<00:10, 127.39it/s]Padding data:  34%|███▍      | 691/2042 [00:05<00:10, 125.25it/s]Padding data:  35%|███▍      | 705/2042 [00:05<00:10, 126.80it/s]Padding data:  35%|███▌      | 718/2042 [00:05<00:10, 121.39it/s]Padding data:  36%|███▌      | 731/2042 [00:05<00:10, 123.06it/s]Padding data:  37%|███▋      | 746/2042 [00:05<00:10, 128.70it/s]Padding data:  37%|███▋      | 761/2042 [00:05<00:09, 132.37it/s]Padding data:  38%|███▊      | 775/2042 [00:05<00:09, 133.67it/s]Padding data:  39%|███▊      | 789/2042 [00:06<00:09, 134.20it/s]Padding data:  39%|███▉      | 804/2042 [00:06<00:09, 137.26it/s]Padding data:  40%|████      | 818/2042 [00:06<00:08, 137.94it/s]Padding data:  41%|████      | 833/2042 [00:06<00:08, 140.79it/s]Padding data:  42%|████▏     | 848/2042 [00:06<00:08, 136.94it/s]Padding data:  42%|████▏     | 863/2042 [00:06<00:08, 138.44it/s]Padding data:  43%|████▎     | 877/2042 [00:06<00:08, 137.96it/s]Padding data:  44%|████▎     | 891/2042 [00:06<00:08, 137.49it/s]Padding data:  44%|████▍     | 905/2042 [00:06<00:08, 137.87it/s]Padding data:  45%|████▌     | 920/2042 [00:07<00:08, 139.13it/s]Padding data:  46%|████▌     | 934/2042 [00:07<00:07, 138.68it/s]Padding data:  46%|████▋     | 948/2042 [00:07<00:07, 138.12it/s]Padding data:  47%|████▋     | 962/2042 [00:07<00:07, 137.88it/s]Padding data:  48%|████▊     | 977/2042 [00:07<00:07, 138.20it/s]Padding data:  49%|████▊     | 992/2042 [00:07<00:07, 140.21it/s]Padding data:  49%|████▉     | 1007/2042 [00:07<00:07, 136.82it/s]Padding data:  50%|█████     | 1021/2042 [00:07<00:07, 136.97it/s]Padding data:  51%|█████     | 1035/2042 [00:07<00:07, 133.92it/s]Padding data:  51%|█████▏    | 1049/2042 [00:07<00:07, 134.75it/s]Padding data:  52%|█████▏    | 1063/2042 [00:08<00:07, 132.42it/s]Padding data:  53%|█████▎    | 1077/2042 [00:08<00:07, 131.97it/s]Padding data:  53%|█████▎    | 1092/2042 [00:08<00:06, 136.22it/s]Padding data:  54%|█████▍    | 1107/2042 [00:08<00:06, 138.44it/s]Padding data:  55%|█████▍    | 1122/2042 [00:08<00:06, 140.04it/s]Padding data:  56%|█████▌    | 1137/2042 [00:08<00:06, 141.47it/s]Padding data:  56%|█████▋    | 1152/2042 [00:08<00:06, 142.60it/s]Padding data:  57%|█████▋    | 1167/2042 [00:08<00:06, 143.28it/s]Padding data:  58%|█████▊    | 1182/2042 [00:08<00:06, 143.28it/s]Padding data:  59%|█████▊    | 1197/2042 [00:09<00:06, 140.29it/s]Padding data:  59%|█████▉    | 1212/2042 [00:09<00:05, 139.41it/s]Padding data:  60%|██████    | 1227/2042 [00:09<00:05, 140.23it/s]Padding data:  61%|██████    | 1242/2042 [00:09<00:05, 140.15it/s]Padding data:  62%|██████▏   | 1257/2042 [00:09<00:05, 140.95it/s]Padding data:  62%|██████▏   | 1272/2042 [00:09<00:05, 142.46it/s]Padding data:  63%|██████▎   | 1287/2042 [00:09<00:05, 142.47it/s]Padding data:  64%|██████▍   | 1302/2042 [00:09<00:05, 143.87it/s]Padding data:  64%|██████▍   | 1317/2042 [00:09<00:05, 140.33it/s]Padding data:  65%|██████▌   | 1332/2042 [00:09<00:05, 141.21it/s]Padding data:  66%|██████▌   | 1347/2042 [00:10<00:04, 140.52it/s]Padding data:  67%|██████▋   | 1363/2042 [00:10<00:04, 142.86it/s]Padding data:  67%|██████▋   | 1378/2042 [00:10<00:04, 139.03it/s]Padding data:  68%|██████▊   | 1393/2042 [00:10<00:04, 140.77it/s]Padding data:  69%|██████▉   | 1408/2042 [00:10<00:04, 141.70it/s]Padding data:  70%|██████▉   | 1423/2042 [00:10<00:04, 140.06it/s]Padding data:  70%|███████   | 1438/2042 [00:10<00:04, 139.94it/s]Padding data:  71%|███████   | 1454/2042 [00:10<00:04, 145.52it/s]Padding data:  72%|███████▏  | 1469/2042 [00:10<00:04, 141.10it/s]Padding data:  73%|███████▎  | 1485/2042 [00:11<00:03, 144.64it/s]Padding data:  73%|███████▎  | 1500/2042 [00:11<00:03, 145.63it/s]Padding data:  74%|███████▍  | 1515/2042 [00:11<00:03, 138.73it/s]Padding data:  75%|███████▍  | 1529/2042 [00:11<00:03, 138.69it/s]Padding data:  76%|███████▌  | 1544/2042 [00:11<00:03, 141.31it/s]Padding data:  76%|███████▋  | 1559/2042 [00:11<00:03, 138.62it/s]Padding data:  77%|███████▋  | 1575/2042 [00:11<00:03, 141.32it/s]Padding data:  78%|███████▊  | 1590/2042 [00:11<00:03, 142.60it/s]Padding data:  79%|███████▊  | 1605/2042 [00:11<00:03, 139.16it/s]Padding data:  79%|███████▉  | 1619/2042 [00:12<00:03, 135.43it/s]Padding data:  80%|████████  | 1635/2042 [00:12<00:02, 140.52it/s]Padding data:  81%|████████  | 1650/2042 [00:12<00:02, 141.77it/s]Padding data:  82%|████████▏ | 1666/2042 [00:12<00:02, 145.48it/s]Padding data:  82%|████████▏ | 1681/2042 [00:12<00:02, 143.72it/s]Padding data:  83%|████████▎ | 1696/2042 [00:12<00:02, 144.30it/s]Padding data:  84%|████████▍ | 1711/2042 [00:12<00:02, 144.60it/s]Padding data:  85%|████████▍ | 1726/2042 [00:12<00:02, 142.92it/s]Padding data:  85%|████████▌ | 1741/2042 [00:12<00:02, 138.38it/s]Padding data:  86%|████████▌ | 1755/2042 [00:12<00:02, 138.68it/s]Padding data:  87%|████████▋ | 1769/2042 [00:13<00:01, 137.66it/s]Padding data:  87%|████████▋ | 1783/2042 [00:13<00:01, 135.41it/s]Padding data:  88%|████████▊ | 1797/2042 [00:13<00:01, 134.35it/s]Padding data:  89%|████████▊ | 1811/2042 [00:13<00:01, 134.44it/s]Padding data:  89%|████████▉ | 1825/2042 [00:13<00:01, 135.29it/s]Padding data:  90%|█████████ | 1839/2042 [00:13<00:01, 133.41it/s]Padding data:  91%|█████████ | 1854/2042 [00:13<00:01, 136.21it/s]Padding data:  92%|█████████▏| 1869/2042 [00:13<00:01, 139.27it/s]Padding data:  92%|█████████▏| 1883/2042 [00:13<00:01, 137.14it/s]Padding data:  93%|█████████▎| 1898/2042 [00:14<00:01, 140.49it/s]Padding data:  94%|█████████▎| 1913/2042 [00:14<00:00, 142.43it/s]Padding data:  94%|█████████▍| 1928/2042 [00:14<00:00, 143.37it/s]Padding data:  95%|█████████▌| 1943/2042 [00:14<00:00, 144.89it/s]Padding data:  96%|█████████▌| 1958/2042 [00:14<00:00, 145.45it/s]Padding data:  97%|█████████▋| 1973/2042 [00:14<00:00, 144.44it/s]Padding data:  97%|█████████▋| 1988/2042 [00:14<00:00, 141.51it/s]Padding data:  98%|█████████▊| 2003/2042 [00:14<00:00, 137.86it/s]Padding data:  99%|█████████▉| 2018/2042 [00:14<00:00, 139.53it/s]Padding data: 100%|█████████▉| 2032/2042 [00:14<00:00, 139.07it/s]Padding data: 100%|██████████| 2042/2042 [00:15<00:00, 135.60it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 400, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 400, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 400, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 400, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 400, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 400, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 400, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 400, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 400, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 400, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 400, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 400, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 400, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 400, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 400, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 400, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 400, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 400, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 400, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 400, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 400, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 400, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 400, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 400, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 400, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 400, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 400, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 400, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 400, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 400, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 400, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 400, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 400, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 400, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 400, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 400, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4382/4382 - 1014s - loss: 0.6259
Epoch 2/100
4382/4382 - 978s - loss: 0.6125
Epoch 3/100
4382/4382 - 983s - loss: 0.6055
Epoch 4/100
4382/4382 - 987s - loss: 0.6015
Epoch 5/100
4382/4382 - 988s - loss: 0.5948
Epoch 6/100
4382/4382 - 985s - loss: 0.5894
Epoch 7/100
4382/4382 - 986s - loss: 0.5850
Epoch 8/100
4382/4382 - 984s - loss: 0.5795
Epoch 9/100
4382/4382 - 985s - loss: 0.5756
Epoch 10/100
4382/4382 - 985s - loss: 0.5692
Epoch 11/100
4382/4382 - 985s - loss: 0.5629
Epoch 12/100
4382/4382 - 985s - loss: 0.5592
Epoch 13/100
4382/4382 - 984s - loss: 0.5565
Epoch 14/100
4382/4382 - 985s - loss: 0.5470
Epoch 15/100
4382/4382 - 985s - loss: 0.5442
Epoch 16/100
4382/4382 - 986s - loss: 0.5422
Epoch 17/100
4382/4382 - 985s - loss: 0.5371
Epoch 18/100
4382/4382 - 984s - loss: 0.5327
Epoch 19/100
4382/4382 - 984s - loss: 0.5250
Epoch 20/100
4382/4382 - 986s - loss: 0.5188
Epoch 21/100
4382/4382 - 984s - loss: 0.5159
Epoch 22/100
4382/4382 - 986s - loss: 0.5128
Epoch 23/100
4382/4382 - 986s - loss: 0.5032
Epoch 24/100
4382/4382 - 986s - loss: 0.4973
Epoch 25/100
4382/4382 - 985s - loss: 0.4934
Epoch 26/100
4382/4382 - 986s - loss: 0.4874
Epoch 27/100
4382/4382 - 986s - loss: 0.4813
Epoch 28/100
4382/4382 - 987s - loss: 0.4840
Epoch 29/100
4382/4382 - 986s - loss: 0.4730
Epoch 30/100
4382/4382 - 987s - loss: 0.4667
Epoch 31/100
4382/4382 - 986s - loss: 0.4635
Epoch 32/100
4382/4382 - 986s - loss: 0.4563
Epoch 33/100
4382/4382 - 987s - loss: 0.4510
Epoch 34/100
4382/4382 - 988s - loss: 0.4435
Epoch 35/100
4382/4382 - 989s - loss: 0.4368
Epoch 36/100
4382/4382 - 989s - loss: 0.4274
Epoch 37/100
4382/4382 - 990s - loss: 0.4284
Epoch 38/100
4382/4382 - 990s - loss: 0.4211
Epoch 39/100
4382/4382 - 990s - loss: 0.4113
Epoch 40/100
4382/4382 - 989s - loss: 0.4070
Epoch 41/100
4382/4382 - 989s - loss: 0.3998
Epoch 42/100
4382/4382 - 990s - loss: 0.3958
Epoch 43/100
4382/4382 - 990s - loss: 0.3928
Epoch 44/100
4382/4382 - 988s - loss: 0.3887
Epoch 45/100
4382/4382 - 990s - loss: 0.3868
Epoch 46/100
4382/4382 - 988s - loss: 0.3778
Epoch 47/100
4382/4382 - 981s - loss: 0.3774
Epoch 48/100
4382/4382 - 1002s - loss: 0.3740
Epoch 49/100
4382/4382 - 1000s - loss: 0.3660
Epoch 50/100
4382/4382 - 999s - loss: 0.3657
Epoch 51/100
4382/4382 - 1001s - loss: 0.3618
Epoch 52/100
4382/4382 - 1001s - loss: 0.3556
Epoch 53/100
4382/4382 - 1001s - loss: 0.3530
Epoch 54/100
4382/4382 - 1000s - loss: 0.3530
Epoch 55/100
4382/4382 - 1002s - loss: 0.3457
Epoch 56/100
4382/4382 - 1001s - loss: 0.3414
Epoch 57/100
4382/4382 - 1002s - loss: 0.3366
Epoch 58/100
4382/4382 - 1002s - loss: 0.3279
Epoch 59/100
4382/4382 - 1000s - loss: 0.3282
Epoch 60/100
4382/4382 - 1001s - loss: 0.3232
Epoch 61/100
4382/4382 - 1000s - loss: 0.3234
Epoch 62/100
4382/4382 - 1001s - loss: 0.3150
Epoch 63/100
4382/4382 - 1000s - loss: 0.3211
Epoch 64/100
4382/4382 - 999s - loss: 0.3083
Epoch 65/100
4382/4382 - 1000s - loss: 0.3082
Epoch 66/100
4382/4382 - 1000s - loss: 0.2995
Epoch 67/100
4382/4382 - 998s - loss: 0.2958
Epoch 68/100
4382/4382 - 1000s - loss: 0.2971
Epoch 69/100
4382/4382 - 999s - loss: 0.2922
Epoch 70/100
4382/4382 - 1000s - loss: 0.2853
Epoch 71/100
4382/4382 - 999s - loss: 0.2873
Epoch 72/100
4382/4382 - 1000s - loss: 0.2796
Epoch 73/100
4382/4382 - 1001s - loss: 0.2829
Epoch 74/100
4382/4382 - 1002s - loss: 0.2721
Epoch 75/100
4382/4382 - 1000s - loss: 0.2675
Epoch 76/100
4382/4382 - 1000s - loss: 0.2678
Epoch 77/100
4382/4382 - 1001s - loss: 0.2647
Epoch 78/100
4382/4382 - 1002s - loss: 0.2641
Epoch 79/100
4382/4382 - 1000s - loss: 0.2582
Epoch 80/100
4382/4382 - 1000s - loss: 0.2622
Epoch 81/100
4382/4382 - 1000s - loss: 0.2672
Epoch 82/100
4382/4382 - 1004s - loss: 0.2551
Epoch 83/100
4382/4382 - 1001s - loss: 0.2534
Epoch 84/100
4382/4382 - 1000s - loss: 0.2485
Epoch 85/100
4382/4382 - 998s - loss: 0.2522
Epoch 86/100
4382/4382 - 997s - loss: 0.2421
Epoch 87/100
4382/4382 - 998s - loss: 0.2403
Epoch 88/100
4382/4382 - 995s - loss: 0.2346
Epoch 89/100
4382/4382 - 998s - loss: 0.2382
Epoch 90/100
4382/4382 - 1000s - loss: 0.2297
Epoch 91/100
4382/4382 - 1000s - loss: 0.2282
Epoch 92/100
4382/4382 - 995s - loss: 0.2207
Epoch 93/100
4382/4382 - 996s - loss: 0.2124
Epoch 94/100
4382/4382 - 997s - loss: 0.2194
Epoch 95/100
4382/4382 - 999s - loss: 0.2198
Epoch 96/100
4382/4382 - 997s - loss: 0.2093
Epoch 97/100
4382/4382 - 1000s - loss: 0.2104
Epoch 98/100
4382/4382 - 997s - loss: 0.2019
Epoch 99/100
4382/4382 - 998s - loss: 0.2030
Epoch 100/100
4382/4382 - 999s - loss: 0.2057
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.48902553903846524
Test f1_avg: 0.4787151563387155
