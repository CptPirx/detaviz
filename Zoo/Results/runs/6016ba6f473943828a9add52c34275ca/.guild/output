INFO: [numexpr.utils] Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
Loaded data
Filtering samples
There are 2042 samples in total.
The types and counts of different labels : 
 {0: 1420, 1: 221, 2: 183, 3: 218}
The types and counts of different labels as percentage of the total data : 
 {0: 0.7, 1: 0.11, 2: 0.09, 3: 0.11}
Padding data:   0%|          | 0/2042 [00:00<?, ?it/s]Padding data:   1%|          | 15/2042 [00:00<00:14, 138.47it/s]Padding data:   1%|▏         | 29/2042 [00:00<00:16, 124.91it/s]Padding data:   2%|▏         | 42/2042 [00:00<00:16, 123.38it/s]Padding data:   3%|▎         | 55/2042 [00:00<00:16, 118.95it/s]Padding data:   3%|▎         | 68/2042 [00:00<00:16, 121.80it/s]Padding data:   4%|▍         | 81/2042 [00:00<00:15, 123.24it/s]Padding data:   5%|▍         | 96/2042 [00:00<00:15, 129.01it/s]Padding data:   5%|▌         | 110/2042 [00:00<00:14, 130.82it/s]Padding data:   6%|▌         | 124/2042 [00:00<00:14, 131.01it/s]Padding data:   7%|▋         | 138/2042 [00:01<00:14, 129.84it/s]Padding data:   7%|▋         | 153/2042 [00:01<00:14, 132.83it/s]Padding data:   8%|▊         | 167/2042 [00:01<00:14, 132.36it/s]Padding data:   9%|▉         | 182/2042 [00:01<00:13, 135.81it/s]Padding data:  10%|▉         | 196/2042 [00:01<00:13, 135.12it/s]Padding data:  10%|█         | 210/2042 [00:01<00:13, 131.85it/s]Padding data:  11%|█         | 224/2042 [00:01<00:14, 128.10it/s]Padding data:  12%|█▏        | 239/2042 [00:01<00:13, 132.38it/s]Padding data:  12%|█▏        | 253/2042 [00:01<00:13, 134.22it/s]Padding data:  13%|█▎        | 268/2042 [00:02<00:12, 138.25it/s]Padding data:  14%|█▍        | 282/2042 [00:02<00:12, 138.50it/s]Padding data:  15%|█▍        | 297/2042 [00:02<00:12, 140.80it/s]Padding data:  15%|█▌        | 312/2042 [00:02<00:12, 140.98it/s]Padding data:  16%|█▌        | 327/2042 [00:02<00:12, 142.62it/s]Padding data:  17%|█▋        | 342/2042 [00:02<00:12, 136.47it/s]Padding data:  17%|█▋        | 357/2042 [00:02<00:12, 138.22it/s]Padding data:  18%|█▊        | 371/2042 [00:02<00:12, 138.11it/s]Padding data:  19%|█▉        | 385/2042 [00:02<00:12, 137.01it/s]Padding data:  20%|█▉        | 400/2042 [00:02<00:11, 137.78it/s]Padding data:  20%|██        | 415/2042 [00:03<00:11, 138.55it/s]Padding data:  21%|██        | 429/2042 [00:03<00:12, 131.18it/s]Padding data:  22%|██▏       | 443/2042 [00:03<00:12, 132.80it/s]Padding data:  22%|██▏       | 457/2042 [00:03<00:12, 129.97it/s]Padding data:  23%|██▎       | 471/2042 [00:03<00:12, 129.90it/s]Padding data:  24%|██▍       | 485/2042 [00:03<00:11, 129.81it/s]Padding data:  24%|██▍       | 499/2042 [00:03<00:11, 130.08it/s]Padding data:  25%|██▌       | 513/2042 [00:03<00:11, 129.54it/s]Padding data:  26%|██▌       | 527/2042 [00:03<00:11, 130.97it/s]Padding data:  27%|██▋       | 542/2042 [00:04<00:11, 134.12it/s]Padding data:  27%|██▋       | 556/2042 [00:04<00:10, 135.16it/s]Padding data:  28%|██▊       | 570/2042 [00:04<00:11, 132.51it/s]Padding data:  29%|██▊       | 584/2042 [00:04<00:11, 127.78it/s]Padding data:  29%|██▉       | 599/2042 [00:04<00:10, 131.25it/s]Padding data:  30%|███       | 613/2042 [00:04<00:10, 131.59it/s]Padding data:  31%|███       | 627/2042 [00:04<00:10, 129.58it/s]Padding data:  31%|███▏      | 640/2042 [00:04<00:10, 127.54it/s]Padding data:  32%|███▏      | 654/2042 [00:04<00:10, 130.34it/s]Padding data:  33%|███▎      | 668/2042 [00:05<00:11, 120.83it/s]Padding data:  33%|███▎      | 681/2042 [00:05<00:11, 115.55it/s]Padding data:  34%|███▍      | 693/2042 [00:05<00:11, 113.45it/s]Padding data:  35%|███▍      | 707/2042 [00:05<00:11, 118.83it/s]Padding data:  35%|███▌      | 719/2042 [00:05<00:11, 118.96it/s]Padding data:  36%|███▌      | 731/2042 [00:05<00:11, 117.88it/s]Padding data:  37%|███▋      | 746/2042 [00:05<00:10, 125.57it/s]Padding data:  37%|███▋      | 760/2042 [00:05<00:09, 129.54it/s]Padding data:  38%|███▊      | 775/2042 [00:05<00:09, 133.03it/s]Padding data:  39%|███▊      | 789/2042 [00:06<00:09, 133.94it/s]Padding data:  39%|███▉      | 804/2042 [00:06<00:09, 137.19it/s]Padding data:  40%|████      | 819/2042 [00:06<00:08, 137.68it/s]Padding data:  41%|████      | 834/2042 [00:06<00:08, 138.38it/s]Padding data:  42%|████▏     | 848/2042 [00:06<00:08, 137.51it/s]Padding data:  42%|████▏     | 863/2042 [00:06<00:08, 138.39it/s]Padding data:  43%|████▎     | 877/2042 [00:06<00:08, 138.56it/s]Padding data:  44%|████▎     | 891/2042 [00:06<00:08, 138.07it/s]Padding data:  44%|████▍     | 906/2042 [00:06<00:08, 139.23it/s]Padding data:  45%|████▌     | 920/2042 [00:06<00:08, 139.16it/s]Padding data:  46%|████▌     | 934/2042 [00:07<00:07, 138.70it/s]Padding data:  46%|████▋     | 949/2042 [00:07<00:07, 140.71it/s]Padding data:  47%|████▋     | 964/2042 [00:07<00:07, 140.66it/s]Padding data:  48%|████▊     | 979/2042 [00:07<00:07, 142.22it/s]Padding data:  49%|████▊     | 995/2042 [00:07<00:07, 145.60it/s]Padding data:  49%|████▉     | 1010/2042 [00:07<00:07, 141.25it/s]Padding data:  50%|█████     | 1025/2042 [00:07<00:07, 142.59it/s]Padding data:  51%|█████     | 1040/2042 [00:07<00:07, 136.49it/s]Padding data:  52%|█████▏    | 1054/2042 [00:07<00:07, 124.78it/s]Padding data:  52%|█████▏    | 1067/2042 [00:08<00:08, 117.15it/s]Padding data:  53%|█████▎    | 1081/2042 [00:08<00:07, 122.56it/s]Padding data:  54%|█████▎    | 1096/2042 [00:08<00:07, 127.88it/s]Padding data:  54%|█████▍    | 1111/2042 [00:08<00:07, 132.55it/s]Padding data:  55%|█████▌    | 1126/2042 [00:08<00:06, 136.66it/s]Padding data:  56%|█████▌    | 1141/2042 [00:08<00:06, 138.42it/s]Padding data:  57%|█████▋    | 1155/2042 [00:08<00:06, 136.28it/s]Padding data:  57%|█████▋    | 1170/2042 [00:08<00:06, 138.94it/s]Padding data:  58%|█████▊    | 1185/2042 [00:08<00:06, 138.32it/s]Padding data:  59%|█████▉    | 1200/2042 [00:09<00:06, 139.69it/s]Padding data:  60%|█████▉    | 1215/2042 [00:09<00:05, 141.35it/s]Padding data:  60%|██████    | 1230/2042 [00:09<00:05, 143.66it/s]Padding data:  61%|██████    | 1245/2042 [00:09<00:05, 144.46it/s]Padding data:  62%|██████▏   | 1260/2042 [00:09<00:05, 144.86it/s]Padding data:  62%|██████▏   | 1275/2042 [00:09<00:05, 144.85it/s]Padding data:  63%|██████▎   | 1290/2042 [00:09<00:05, 143.76it/s]Padding data:  64%|██████▍   | 1305/2042 [00:09<00:05, 143.94it/s]Padding data:  65%|██████▍   | 1320/2042 [00:09<00:04, 145.17it/s]Padding data:  65%|██████▌   | 1335/2042 [00:09<00:04, 144.47it/s]Padding data:  66%|██████▌   | 1351/2042 [00:10<00:04, 147.59it/s]Padding data:  67%|██████▋   | 1366/2042 [00:10<00:04, 145.15it/s]Padding data:  68%|██████▊   | 1381/2042 [00:10<00:04, 145.55it/s]Padding data:  68%|██████▊   | 1396/2042 [00:10<00:04, 144.62it/s]Padding data:  69%|██████▉   | 1411/2042 [00:10<00:04, 144.86it/s]Padding data:  70%|██████▉   | 1426/2042 [00:10<00:04, 143.38it/s]Padding data:  71%|███████   | 1442/2042 [00:10<00:04, 146.36it/s]Padding data:  71%|███████▏  | 1457/2042 [00:10<00:04, 145.76it/s]Padding data:  72%|███████▏  | 1472/2042 [00:10<00:03, 144.52it/s]Padding data:  73%|███████▎  | 1487/2042 [00:11<00:03, 142.17it/s]Padding data:  74%|███████▎  | 1502/2042 [00:11<00:03, 144.37it/s]Padding data:  74%|███████▍  | 1517/2042 [00:11<00:03, 138.80it/s]Padding data:  75%|███████▌  | 1532/2042 [00:11<00:03, 141.41it/s]Padding data:  76%|███████▌  | 1547/2042 [00:11<00:03, 143.85it/s]Padding data:  76%|███████▋  | 1562/2042 [00:11<00:03, 143.54it/s]Padding data:  77%|███████▋  | 1577/2042 [00:11<00:03, 144.77it/s]Padding data:  78%|███████▊  | 1593/2042 [00:11<00:03, 146.44it/s]Padding data:  79%|███████▊  | 1608/2042 [00:11<00:03, 141.95it/s]Padding data:  79%|███████▉  | 1623/2042 [00:11<00:02, 140.92it/s]Padding data:  80%|████████  | 1638/2042 [00:12<00:02, 142.58it/s]Padding data:  81%|████████  | 1653/2042 [00:12<00:02, 144.39it/s]Padding data:  82%|████████▏ | 1668/2042 [00:12<00:02, 143.92it/s]Padding data:  82%|████████▏ | 1684/2042 [00:12<00:02, 145.28it/s]Padding data:  83%|████████▎ | 1699/2042 [00:12<00:02, 144.78it/s]Padding data:  84%|████████▍ | 1715/2042 [00:12<00:02, 147.14it/s]Padding data:  85%|████████▍ | 1730/2042 [00:12<00:02, 141.96it/s]Padding data:  85%|████████▌ | 1745/2042 [00:12<00:02, 141.12it/s]Padding data:  86%|████████▌ | 1760/2042 [00:12<00:02, 136.17it/s]Padding data:  87%|████████▋ | 1774/2042 [00:13<00:01, 135.24it/s]Padding data:  88%|████████▊ | 1788/2042 [00:13<00:02, 122.13it/s]Padding data:  88%|████████▊ | 1802/2042 [00:13<00:01, 125.43it/s]Padding data:  89%|████████▉ | 1815/2042 [00:13<00:01, 126.44it/s]Padding data:  90%|████████▉ | 1828/2042 [00:13<00:01, 127.36it/s]Padding data:  90%|█████████ | 1841/2042 [00:13<00:01, 127.99it/s]Padding data:  91%|█████████ | 1856/2042 [00:13<00:01, 132.44it/s]Padding data:  92%|█████████▏| 1872/2042 [00:13<00:01, 138.28it/s]Padding data:  92%|█████████▏| 1887/2042 [00:13<00:01, 139.45it/s]Padding data:  93%|█████████▎| 1902/2042 [00:14<00:00, 142.19it/s]Padding data:  94%|█████████▍| 1918/2042 [00:14<00:00, 145.07it/s]Padding data:  95%|█████████▍| 1933/2042 [00:14<00:00, 143.55it/s]Padding data:  95%|█████████▌| 1948/2042 [00:14<00:00, 143.63it/s]Padding data:  96%|█████████▌| 1963/2042 [00:14<00:00, 144.59it/s]Padding data:  97%|█████████▋| 1978/2042 [00:14<00:00, 140.99it/s]Padding data:  98%|█████████▊| 1993/2042 [00:14<00:00, 141.44it/s]Padding data:  98%|█████████▊| 2008/2042 [00:14<00:00, 137.16it/s]Padding data:  99%|█████████▉| 2023/2042 [00:14<00:00, 139.84it/s]Padding data: 100%|█████████▉| 2038/2042 [00:14<00:00, 138.53it/s]Padding data: 100%|██████████| 2042/2042 [00:15<00:00, 136.00it/s]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 100, 125)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 100, 64)      64064       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 100, 64)      256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 100, 64)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 100, 64)      20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 100, 64)      256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 100, 64)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 100, 64)      8064        input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 100, 64)      12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 100, 64)      256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 100, 64)      256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 100, 64)      0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 100, 64)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 100, 128)     65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 100, 128)     512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 100, 128)     0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 100, 128)     82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 100, 128)     512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 100, 128)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 100, 128)     8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 100, 128)     49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 100, 128)     512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 100, 128)     512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 100, 128)     0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 100, 128)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 100, 128)     131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 100, 128)     512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 128)     0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 100, 128)     82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 100, 128)     512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 100, 128)     0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 100, 128)     49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 128)     512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 128)     512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 100, 128)     0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 100, 128)     0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 578,242
Trainable params: 575,682
Non-trainable params: 2,560
__________________________________________________________________________________________________
Epoch 1/100
4383/4383 - 262s - loss: 0.6315
Epoch 2/100
4383/4383 - 225s - loss: 0.6162
Epoch 3/100
4383/4383 - 234s - loss: 0.6176
Epoch 4/100
4383/4383 - 233s - loss: 0.6105
Epoch 5/100
4383/4383 - 234s - loss: 0.6046
Epoch 6/100
4383/4383 - 232s - loss: 0.6016
Epoch 7/100
4383/4383 - 233s - loss: 0.5959
Epoch 8/100
4383/4383 - 233s - loss: 0.5878
Epoch 9/100
4383/4383 - 230s - loss: 0.5826
Epoch 10/100
4383/4383 - 231s - loss: 0.5757
Epoch 11/100
4383/4383 - 233s - loss: 0.5718
Epoch 12/100
4383/4383 - 233s - loss: 0.5660
Epoch 13/100
4383/4383 - 232s - loss: 0.5619
Epoch 14/100
4383/4383 - 232s - loss: 0.5536
Epoch 15/100
4383/4383 - 232s - loss: 0.5477
Epoch 16/100
4383/4383 - 233s - loss: 0.5448
Epoch 17/100
4383/4383 - 232s - loss: 0.5392
Epoch 18/100
4383/4383 - 232s - loss: 0.5339
Epoch 19/100
4383/4383 - 232s - loss: 0.5248
Epoch 20/100
4383/4383 - 231s - loss: 0.5195
Epoch 21/100
4383/4383 - 232s - loss: 0.5138
Epoch 22/100
4383/4383 - 232s - loss: 0.5075
Epoch 23/100
4383/4383 - 234s - loss: 0.4979
Epoch 24/100
4383/4383 - 234s - loss: 0.4919
Epoch 25/100
4383/4383 - 236s - loss: 0.4862
Epoch 26/100
4383/4383 - 233s - loss: 0.4782
Epoch 27/100
4383/4383 - 232s - loss: 0.4662
Epoch 28/100
4383/4383 - 233s - loss: 0.4613
Epoch 29/100
4383/4383 - 234s - loss: 0.4526
Epoch 30/100
4383/4383 - 235s - loss: 0.4436
Epoch 31/100
4383/4383 - 235s - loss: 0.4329
Epoch 32/100
4383/4383 - 233s - loss: 0.4252
Epoch 33/100
4383/4383 - 236s - loss: 0.4159
Epoch 34/100
4383/4383 - 232s - loss: 0.4106
Epoch 35/100
4383/4383 - 232s - loss: 0.4031
Epoch 36/100
4383/4383 - 231s - loss: 0.3880
Epoch 37/100
4383/4383 - 233s - loss: 0.3842
Epoch 38/100
4383/4383 - 234s - loss: 0.3754
Epoch 39/100
4383/4383 - 234s - loss: 0.3665
Epoch 40/100
4383/4383 - 232s - loss: 0.3622
Epoch 41/100
4383/4383 - 233s - loss: 0.3507
Epoch 42/100
4383/4383 - 232s - loss: 0.3477
Epoch 43/100
4383/4383 - 234s - loss: 0.3384
Epoch 44/100
4383/4383 - 234s - loss: 0.3365
Epoch 45/100
4383/4383 - 236s - loss: 0.3308
Epoch 46/100
4383/4383 - 232s - loss: 0.3151
Epoch 47/100
4383/4383 - 233s - loss: 0.3211
Epoch 48/100
4383/4383 - 233s - loss: 0.3064
Epoch 49/100
4383/4383 - 231s - loss: 0.2986
Epoch 50/100
4383/4383 - 232s - loss: 0.3079
Epoch 51/100
4383/4383 - 232s - loss: 0.2935
Epoch 52/100
4383/4383 - 231s - loss: 0.2943
Epoch 53/100
4383/4383 - 230s - loss: 0.2853
Epoch 54/100
4383/4383 - 231s - loss: 0.2822
Epoch 55/100
4383/4383 - 230s - loss: 0.2795
Epoch 56/100
4383/4383 - 231s - loss: 0.2829
Epoch 57/100
4383/4383 - 232s - loss: 0.2737
Epoch 58/100
4383/4383 - 231s - loss: 0.2744
Epoch 59/100
4383/4383 - 230s - loss: 0.2715
Epoch 60/100
4383/4383 - 232s - loss: 0.2654
Epoch 61/100
4383/4383 - 233s - loss: 0.2592
Epoch 62/100
4383/4383 - 233s - loss: 0.2581
Epoch 63/100
4383/4383 - 232s - loss: 0.2518
Epoch 64/100
4383/4383 - 233s - loss: 0.2611
Epoch 65/100
4383/4383 - 233s - loss: 0.2548
Epoch 66/100
4383/4383 - 233s - loss: 0.2573
Epoch 67/100
4383/4383 - 232s - loss: 0.2551

Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 68/100
4383/4383 - 232s - loss: 0.2175
Epoch 69/100
4383/4383 - 232s - loss: 0.2046
Epoch 70/100
4383/4383 - 231s - loss: 0.2024
Epoch 71/100
4383/4383 - 230s - loss: 0.2000
Epoch 72/100
4383/4383 - 231s - loss: 0.1979
Epoch 73/100
4383/4383 - 233s - loss: 0.1929
Epoch 74/100
4383/4383 - 234s - loss: 0.1937
Epoch 75/100
4383/4383 - 233s - loss: 0.1930
Epoch 76/100
4383/4383 - 232s - loss: 0.1983
Epoch 77/100
4383/4383 - 232s - loss: 0.1884
Epoch 78/100
4383/4383 - 233s - loss: 0.1902
Epoch 79/100
4383/4383 - 233s - loss: 0.1874
Epoch 80/100
4383/4383 - 233s - loss: 0.1948
Epoch 81/100
4383/4383 - 233s - loss: 0.1829
Epoch 82/100
4383/4383 - 233s - loss: 0.1849
Epoch 83/100
4383/4383 - 232s - loss: 0.1833
Epoch 84/100
4383/4383 - 232s - loss: 0.1821
Epoch 85/100
4383/4383 - 234s - loss: 0.1817
Epoch 86/100
4383/4383 - 234s - loss: 0.1789
Epoch 87/100
4383/4383 - 235s - loss: 0.1805
Epoch 88/100
4383/4383 - 234s - loss: 0.1779
Epoch 89/100
4383/4383 - 231s - loss: 0.1772
Epoch 90/100
4383/4383 - 232s - loss: 0.1757
Epoch 91/100
4383/4383 - 234s - loss: 0.1745
Epoch 92/100
4383/4383 - 233s - loss: 0.1722
Epoch 93/100
4383/4383 - 234s - loss: 0.1691
Epoch 94/100
4383/4383 - 233s - loss: 0.1678
Epoch 95/100
4383/4383 - 232s - loss: 0.1667
Epoch 96/100
4383/4383 - 232s - loss: 0.1656
Epoch 97/100
4383/4383 - 232s - loss: 0.1623
Epoch 98/100
4383/4383 - 233s - loss: 0.1668
Epoch 99/100
4383/4383 - 234s - loss: 0.1626
Epoch 100/100
4383/4383 - 230s - loss: 0.1668
INFO: [tensorflow] Assets written to: model/assets
Train f1_avg: 0.5147132091088871
Test f1_avg: 0.5159751422929216
